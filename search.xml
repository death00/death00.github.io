<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Java 线程池讲解——针对 IO 密集型任务]]></title>
    <url>%2F2020%2F05%2F20%2FJava%20%E7%BA%BF%E7%A8%8B%E6%B1%A0%E8%AE%B2%E8%A7%A3%E2%80%94%E2%80%94%E9%92%88%E5%AF%B9%20IO%20%E5%AF%86%E9%9B%86%E5%9E%8B%E4%BB%BB%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[针对 IO 密集型的任务，我们可以针对原本的线程池做一些改造，从而可以提高任务的处理效率。 基本在阿里巴巴泰山版java开发手册中有这么一条：12线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。 那么如果要使用 ThreadPoolExecutor ，那就先来看看构造方法中的所有入参：1234567corePoolSize : 核心线程数，当线程池中的线程数量为 corePoolSize 时，即使这些线程处于空闲状态，也不会销毁（除非设置 allowCoreThreadTimeOut）。maximumPoolSize : 最大线程数，线程池中允许的线程数量的最大值。keepAliveTime : 线程空闲时间，当线程池中的线程数大于 corePoolSize 时，多余的空闲线程将在销毁之前等待新任务的最长时间。workQueue : 任务队列unit ： 线程空闲时间的单位。threadFactory ： 线程工厂，线程池创建线程时使用的工厂。handler : 拒绝策略，因达到线程边界和任务队列满时，针对新任务的处理方法。 这么说可能有些难以理解，你可以结合下图进行参考： 那么由此我们可以知道，当大量任务被放入线程池之后，先是被核心线程执行，多余的会被放进队列里，当队列满了之后才会创建额外的线程进行处理，再多就会采取拒绝策略。 但这样真的能满足我们的所有需求吗？ 任务的分类正常来说，我们可以把需要处理的任务按照消耗资源的不同，分为两种：CPU 密集型和IO 密集型。 CPU 密集型既然名字里带有CPU了，说明其消耗的主要资源就是 CPU 了。 具体是指那种包含大量运算、在持有的 CPU 分配的时间片上一直在执行任务、几乎不需要依赖或等待其他任何东西。 这样的任务，在我的理解中，处理起来其实没有多少优化空间，因为处理时几乎没有等待时间，所以一直占有 CPU 进行执行，才是最好的方式。 唯一能想到优化的地方，就是当单个线程累计较多任务时，其他线程能进行分担，类似fork/join框架的概念。 设置线程数时，针对单台机器，最好就是有几个 CPU ，就创建几个线程，然后每个线程都在执行这种任务，永不停歇。 IO 密集型和上面一样，既然名字里带有IO了，说明其消耗的主要资源就是 IO 了。 我们所接触到的 IO ，大致可以分成两种：磁盘 IO和网络 IO。 磁盘 IO ，大多都是一些针对磁盘的读写操作，最常见的就是文件的读写，假如你的数据库、 Redis 也是在本地的话，那么这个也属于磁盘 IO。 网络 IO ，这个应该是大家更加熟悉的，我们会遇到各种网络请求，比如 http 请求、远程数据库读写、远程 Redis 读写等等。 IO 操作的特点就是需要等待，我们请求一些数据，由对方将数据写入缓冲区，在这段时间中，需要读取数据的线程根本无事可做，因此可以把 CPU 时间片让出去，直到缓冲区写满。 既然这样，IO 密集型任务其实就有很大的优化空间了（毕竟存在等待），那现有的线程池可以很好的满足我们的需求吗？ 线程池的优化还记得上面说的， ThreadPoolExecutor 针对多余任务的处理，是先放到等待队列中，当队列塞满后，再创建额外的线程进行处理。 假设我们的任务基本都是 IO 密集型，我们希望程序可以有更高的吞吐量，可以在更短的时间内处理更多的任务，那么上面的 ThreadPoolExecutor 明显是不满足我们的需求，那该如何解决呢？ 也许再来看看 ThreadPoolExecutor 的 execute 方法，会让我们有一些思路：123456789101112131415161718192021222324public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); // 如果当前活跃线程数，小于核心线程数 if (workerCountOf(c) &lt; corePoolSize) &#123; // 则优先创建线程 if (addWorker(command, true)) return; c = ctl.get(); &#125; // 如果任务可以成功放入队列中 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; // 如果不可以成功放入队列，则创建线程 else if (!addWorker(command, false)) // 如果无法继续创建线程，则拒绝任务 reject(command);&#125; 针对放入队列的操作，如果队列放入失败，线程池就会选择去创建线程了。因此，我们或许可以尝试自定义线程池，针对 offer 操作，做一些自定义处理。 也就是将任务放入队列时，先检查线程池的线程数是否小于最大线程数，如果是，则拒绝放入队列，否则，再尝试放入队列中。 如果你有看过 dubbo 或者 tomcat 的线程池，你会发现他们就有这样的实现方法。 比如 dubbo 中的 TaskQueue，我们来看看它的 offer 方法：1234567891011121314151617181920@Overridepublic boolean offer(Runnable runnable) &#123; if (executor == null) &#123; throw new RejectedExecutionException("The task queue does not have executor!"); &#125; int currentPoolThreadSize = executor.getPoolSize(); // 如果有空闲等待的线程，则将任务放入队列中，让线程去处理任务 if (executor.getSubmittedTaskCount() &lt; currentPoolThreadSize) &#123; return super.offer(runnable); &#125; // 如果当前线程数小于最大线程数，则返回 false ，让线程池去创建新的线程 if (currentPoolThreadSize &lt; executor.getMaximumPoolSize()) &#123; return false; &#125; // 否则，就将任务放入队列中 return super.offer(runnable);&#125; 这样就可以让线程池优先新建线程了。需要注意的时，此时的队列因为需要根据线程池中的线程数决定是否放入任务成功，所以需要持有executor对象，这点不要忘记奥。 总结通过本篇文章，主要是让大家重新了解了一下 ThreadPoolExecutor ，并针对高吞吐场景下如何进行局部优化。 有兴趣的话可以访问我的博客或者关注我的公众号、头条号，说不定会有意外的惊喜。 https://death00.github.io/ 公众号：健程之道]]></content>
      <tags>
        <tag>Java</tag>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadLocal的进化——TransmittableThreadLocal]]></title>
    <url>%2F2019%2F12%2F15%2FThreadLocal%E7%9A%84%E8%BF%9B%E5%8C%96%E2%80%94%E2%80%94TransmittableThreadLocal%2F</url>
    <content type="text"><![CDATA[上一篇文章中，我们谈到了 InheritableThreadLocal，它解决了 ThreadLocal 针对父子线程无法共享上下文的问题。但我们可能听说过阿里的开源产品TransmittableThreadLocal，那么它又是做什么的呢？ 线程池中的共享我们在多线程中，很少会直接 new 一个线程，更多的可能是利用线程池处理任务，那么利用 InheritableThreadLocal 可以将生成任务线程的上下文传递给执行任务的线程吗？废话不多说，直接上代码测试一下：123456789101112131415161718192021222324252627282930313233343536373839public class InheritableThreadLocalContext &#123; private static InheritableThreadLocal&lt;Context&gt; context = new InheritableThreadLocal&lt;&gt;(); static class Context &#123; String name; int value; &#125; public static void main(String[] args) &#123; // 固定线程池 ExecutorService executorService = Executors.newFixedThreadPool(4); for (int i = 1; i &lt;= 10; i++) &#123; int finalI = i; new Thread( () -&gt; &#123; // 生成任务的线程对context进行赋值 Context contextMain = new Context(); contextMain.name = String.format("Thread%s name", finalI); contextMain.value = finalI * 20; InheritableThreadLocalContext.context.set(contextMain); // 提交任务 for (int j = 1; j &lt;= 10; j++) &#123; System.out.println("Thread" + finalI + " produce task " + (finalI * 20 + j)); executorService.execute(() -&gt; &#123; // 执行任务的子线程 Context contextChild = InheritableThreadLocalContext.context.get(); System.out.println(Thread.currentThread().getName() + " execute task, name : " + contextChild.name + " value : " + contextChild.value); &#125;); &#125; &#125; ).start(); &#125; &#125;&#125; 我们希望的结果是，子线程输出的内容能够和父线程对应上。然而，实际的结果却出乎所料，我将结果整理一下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950Thread1 produce task 21// 省略8行Thread1 produce task 30Thread2 produce task 41// 省略8行Thread2 produce task 50pool-1-thread-1 execute task, name : Thread2 name value : 40// 省略47行pool-1-thread-1 execute task, name : Thread2 name value : 40Thread3 produce task 61// 省略8行Thread3 produce task 70Thread4 produce task 81// 省略8行Thread4 produce task 90Thread5 produce task 101// 省略8行Thread5 produce task 110Thread6 produce task 121// 省略8行Thread6 produce task 130Thread7 produce task 141// 省略8行Thread7 produce task 150pool-1-thread-2 execute task, name : Thread7 name value : 140// 省略6行pool-1-thread-2 execute task, name : Thread7 name value : 140Thread8 produce task 161// 省略8行Thread8 produce task 170Thread9 produce task 181// 省略8行Thread9 produce task 190pool-1-thread-4 execute task, name : Thread9 name value : 180pool-1-thread-4 execute task, name : Thread9 name value : 180Thread10 produce task 201// 省略8行Thread10 produce task 210pool-1-thread-3 execute task, name : Thread10 name value : 200// 省略39行pool-1-thread-3 execute task, name : Thread10 name value : 200 虽然生产总数和消费总数都是100，但是明显有的消费多了，有的消费少了。合理推测一下，应该是在主线程放进任务后，子线程才生成。为了验证这个猜想，将线程池用 ThreadPoolExecutor 生成，并在用子线程生成任务之前，先赋值 context 并开启所有线程：123456789101112131415161718192021222324252627282930313233343536373839public static void main(String[] args) &#123; // 固定线程池 ThreadPoolExecutor executorService = new ThreadPoolExecutor( 4, 4, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;&gt;() ); // 在main线程中赋值 Context context = new Context(); context.name = "Thread0 name"; context.value = 0; InheritableThreadLocalContext.context.set(context); // 开启所有线程 executorService.prestartAllCoreThreads(); for (int i = 1; i &lt;= 10; i++) &#123; int finalI = i; new Thread( () -&gt; &#123; // 生成任务的线程对context进行赋值 Context contextMain = new Context(); contextMain.name = String.format("Thread%s name", finalI); contextMain.value = finalI * 20; InheritableThreadLocalContext.context.set(contextMain); // 提交任务 for (int j = 1; j &lt;= 10; j++) &#123; System.out.println("Thread" + finalI + " produce task " + (finalI * 20 + j)); executorService.execute(() -&gt; &#123; // 执行任务的子线程 Context contextChild = InheritableThreadLocalContext.context.get(); System.out.println(Thread.currentThread().getName() + " execute task, name : " + contextChild.name + " value : " + contextChild.value); &#125;); &#125; &#125; ).start(); &#125;&#125; 结果不出所料，执行任务的线程输出的，都是最外面主线程设置的值。 那么我们该如何才能达到最初想要的效果呢？就是利用线程池执行任务时，如何能够让执行者线程能够获取调用者线程的 context 呢？ 使用 TransmittableThreadLocal 解决上面的问题主要是因为执行任务的线程是被线程池管理，可以被复用（可以称为池化复用）。那复用了之后，如果还是依赖于父线程的 context，自然是有问题的，因为我们想要的效果是执行线程获取调用线程的 context，这时候就是TransmittableThreadLocal出场了。 TransmittableThreadLocal 是阿里提供的工具类，其主要解决的就是上面遇到的问题。那么该如何使用呢？ 首先，你需要引入相应的依赖：12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;transmittable-thread-local&lt;/artifactId&gt; &lt;version&gt;2.11.0&lt;/version&gt;&lt;/dependency&gt; 具体代码，就拿上文提到的情况，我们用 TransmittableThreadLocal 做一个改造：1234567891011121314151617181920212223242526272829303132333435363738394041public class TransmittableThreadLocalTest &#123; private static TransmittableThreadLocal&lt;Context&gt; context = new TransmittableThreadLocal&lt;&gt;(); static class Context &#123; String name; int value; &#125; public static void main(String[] args) &#123; // 固定线程池 ExecutorService executorService = Executors.newFixedThreadPool(4); for (int i = 1; i &lt;= 10; i++) &#123; int finalI = i; new Thread( () -&gt; &#123; // 生成任务的线程对context进行赋值 Context contextMain = new Context(); contextMain.name = String.format("Thread%s name", finalI); contextMain.value = finalI * 20; TransmittableThreadLocalTest.context.set(contextMain); // 提交任务 for (int j = 1; j &lt;= 10; j++) &#123; System.out.println("Thread" + finalI + " produce task " + (finalI * 20 + j)); Runnable task = () -&gt; &#123; // 执行任务的子线程 Context contextChild = TransmittableThreadLocalTest.context.get(); System.out.println(Thread.currentThread().getName() + " execute task, name : " + contextChild.name + " value : " + contextChild.value); &#125;; // 额外的处理，生成修饰了的对象ttlRunnable Runnable ttlRunnable = TtlRunnable.get(task); executorService.execute(ttlRunnable); &#125; &#125; ).start(); &#125; &#125;&#125; 此时再次运行，就会发现执行线程运行时的输出内容是完全可以和调用线程对应上的了。当然了，我这种方式是修改了 Runnable 的写法，阿里也提供了线程池的写法，简单如下：12345678910111213141516171819202122232425262728293031public static void main(String[] args) &#123; // 固定线程池 ExecutorService executorService = Executors.newFixedThreadPool(4); // 额外的处理，生成修饰了的对象executorService executorService = TtlExecutors.getTtlExecutorService(executorService); ExecutorService finalExecutorService = executorService; for (int i = 1; i &lt;= 10; i++) &#123; int finalI = i; new Thread( () -&gt; &#123; // 生成任务的线程对context进行赋值 Context contextMain = new Context(); contextMain.name = String.format("Thread%s name", finalI); contextMain.value = finalI * 20; TransmittableThreadLocalTest.context.set(contextMain); // 提交任务 for (int j = 1; j &lt;= 10; j++) &#123; System.out.println("Thread" + finalI + " produce task " + (finalI * 20 + j)); Runnable task = () -&gt; &#123; // 执行任务的子线程 Context contextChild = TransmittableThreadLocalTest.context.get(); System.out.println(Thread.currentThread().getName() + " execute task, name : " + contextChild.name + " value : " + contextChild.value); &#125;; finalExecutorService.execute(task); &#125; &#125; ).start(); &#125;&#125; 其实还有更加简单的写法，具体可以参考其github:https://github.com/alibaba/transmittable-thread-local 总结其实两篇 ThreadLocal 升级文章的出现，都是因为周三听了一个部门关于 TTL 的分享会，也是介绍了 TransmittableThreadLocal，但因为携程商旅面临国际化的改动，当前的语种信息肯定是存储在线程的 context 中最方便，但涉及到线程传递的问题（因为会调用异步接口等等），所以自然就需要考虑这个了。性能方面的话，他们有做过测试，但我也只是一个听者，并没有具体使用过，大家也可以一起交流。 有兴趣的话可以访问我的博客或者关注我的公众号、头条号，说不定会有意外的惊喜。 https://jjcoder.top/ 公众号：健程之道]]></content>
      <tags>
        <tag>Java</tag>
        <tag>ThreadLocal</tag>
        <tag>TransmittableThreadLocal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadLocal的进化——InheritableThreadLocal]]></title>
    <url>%2F2019%2F12%2F13%2FThreadLocal%E7%9A%84%E8%BF%9B%E5%8C%96%E2%80%94%E2%80%94InheritableThreadLocal%2F</url>
    <content type="text"><![CDATA[之前有介绍过 ThreadLocal，JDK 后来针对此做了一个升级版本 InheritableThreadLocal，今天就来好好介绍下。 为什么要升级首先我们来想想，为什么要升级？这就要说起 ThreadLocal 的功能了。 我们知道，ThreadLocal 设计初衷是为了在多线程环境下，针对每一个线程能有一个自己的副本，这样可以在一定程度上解决多线程并发修改的问题。但是，我们可以在此基础上做一个拓展，比如context，我们可以利用 ThreadLocal 针对每一个线程都有一个自己的上下文，一般都是写成ThreadLocal&lt;Context&gt;，这样在这个线程上做的所有修改都可以被大家利用到。 此时设想一下，假如我们新建一个子线程，那这个子线程可以获取到父线程的context吗？理论上希望可以达成这样的效果，实际上呢？让我们看看：123456789101112131415161718192021222324252627282930public class ThreadLocalContext &#123; private static ThreadLocal&lt;Context&gt; context = new ThreadLocal&lt;&gt;(); static class Context &#123; String name; int value; &#125; public static void main(String[] args) &#123; Context context = new Context(); context.name = "mainName"; context.value = 10; ThreadLocalContext.context.set(context); Thread childThread = new Thread( new Runnable() &#123; @Override public void run() &#123; Context childContext = ThreadLocalContext.context.get(); System.out.println(childContext.name); System.out.println(childContext.value); &#125; &#125; ); childThread.start(); &#125;&#125; 运行 main 方法之后，直接在子线程中抛错，这样确实符合我们的预期，但如果我们想达到子线程可以获取到父线程的 context这样的效果该如何做呢？ 首先想到的就是在生成子线程的时候，将父线程 ThreadLocal 里的值传给子线程。这样做虽然能达到效果，但过程比较繁杂，且代码侵入性强。 这个时候就可以用InheritableThreadLocal了。 什么是 InheritableThreadLocal看源码先让我们看看它的源码，大家不要怕，它的源码很少：1234567891011121314public class InheritableThreadLocal&lt;T&gt; extends ThreadLocal&lt;T&gt; &#123; protected T childValue(T parentValue) &#123; return parentValue; &#125; ThreadLocalMap getMap(Thread t) &#123; return t.inheritableThreadLocals; &#125; void createMap(Thread t, T firstValue) &#123; t.inheritableThreadLocals = new ThreadLocalMap(this, firstValue); &#125;&#125; 首先它继承自 ThreadLocal，那么它其实就是 ThreadLocal 的一个拓展版本，接下来就是这三个方法，其实这三个方法在 ThreadLocal 都是有的，我们来看看：1234567891011T childValue(T parentValue) &#123; throw new UnsupportedOperationException();&#125;ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125;void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125; 除了childValue方法在 ThreadLocal 中是抛出异常的，其余两个方法在两个类中都几乎是一样，只是针对的对象不同而已，但threadLocals和inheritableThreadLocals都是ThreadLocal.ThreadLocalMap类型，这个在之前的文章中有说过，就是一个 key 为弱引用的 Entry，这个倒不是重点。 我们再来看看 inheritableThreadLocals 是在何时被初始化的，从源码可以得知：12345678910111213private void init(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc) &#123; // 省略无关代码 ... Thread parent = currentThread(); ... // 省略无关代码 ... if (parent.inheritableThreadLocals != null) this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals); ... &#125; 当我们通过父线程调用 Thread 的构造方法生成一个子线程时，其构造方法最终会调用这个 init 方法。从这儿可以看出， inheritableThreadLocals 是来自于父线程的 inheritableThreadLocals，那这样也就解释了为什么 inheritableThreadLocals 支持在子线程中使用父线程中存储的变量。 如何使用让我们还是回到上文提到的 context 的例子，用 InheritableThreadLocal 进行改造：123456789101112131415161718192021222324252627282930public class ThreadLocalContext &#123; private static InheritableThreadLocal&lt;Context&gt; context = new InheritableThreadLocal&lt;&gt;(); static class Context &#123; String name; int value; &#125; public static void main(String[] args) &#123; Context context = new Context(); context.name = "mainName"; context.value = 10; ThreadLocalContext.context.set(context); Thread childThread = new Thread( new Runnable() &#123; @Override public void run() &#123; Context childContext = ThreadLocalContext.context.get(); System.out.println(childContext.name); System.out.println(childContext.value); &#125; &#125; ); childThread.start(); &#125;&#125; 运行后，不仅没有抛出异常，而且在子线程中输出了父线程设置好的值。皆大欢喜！ 总结今天分享了 InheritableThreadLocal，主要是因为周三在携程的分享会上听到了别人谈了这方面的分享，主讲人讲了一个更加普遍的问题，如果我们用线程池提交任务的话，线程池中的线程在执行任务时，如何能够获得提交任务的线程的 context，这时就要用到阿里的开源组件 TTL，我会在之后进行介绍。 加入携程也有1个月了，虽然感受到大公司有不少的弊端，比如沟通难等，但也有不少的优点，比如技术分享会，虽然也是忙里偷闲去参加的，但有了更多和技术相关的可以学习和交流的机会，也挺好的。 有兴趣的话可以访问我的博客或者关注我的公众号、头条号，说不定会有意外的惊喜。 https://jjcoder.top/ 公众号：健程之道]]></content>
      <tags>
        <tag>Java</tag>
        <tag>ThreadLocal</tag>
        <tag>InheritableThreadLocal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java——内部类详解]]></title>
    <url>%2F2019%2F11%2F26%2FJava%E2%80%94%E2%80%94%E5%86%85%E9%83%A8%E7%B1%BB%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[说起内部类，大家肯定感觉熟悉又陌生，因为一定在很多框架源码中有看到别人使用过，但又感觉自己使用的比较少，今天我就带你具体来看看内部类。 内部类基础 所谓内部类就是在类的内部继续定义其他内部结构类。 在 Java 中，广泛意义上的内部类一般来说包括这四种：成员内部类、局部内部类、匿名内部类和静态内部类。下面就先来了解一下这四种内部类的用法。 成员内部类成员内部类是最普通的内部类，它的定义为位于另一个类的内部，具体使用如下： 12345678910111213141516class Circle &#123; double radius = 0; public Circle(double radius) &#123; this.radius = radius; &#125; /** * 内部类 */ class Draw &#123; public void drawSahpe() &#123; System.out.println("drawshape"); &#125; &#125;&#125; 这样看起来，类 Draw 像是类 Circle 的一个成员， Circle 称为外部类。成员内部类可以无条件访问外部类的所有成员属性和成员方法（包括 private 成员和静态成员），例如： 12345678910111213141516171819class Circle &#123; private double radius = 0; public static int count =1; public Circle(double radius) &#123; this.radius = radius; &#125; /** * 内部类 */ class Draw &#123; public void drawSahpe() &#123; // 外部类的private成员 System.out.println(radius); // 外部类的静态成员 System.out.println(count); &#125; &#125;&#125; 不过要注意的是，当成员内部类拥有和外部类同名的成员变量或者方法时，会发生隐藏现象，即默认情况下访问的是成员内部类的成员。如果要访问外部类的同名成员，需要采取以下形式进行访问：12外部类.this.成员变量外部类.this.成员方法 虽然成员内部类可以无条件地访问外部类的成员，而外部类想访问成员内部类的成员却不是这么随心所欲了。在外部类中如果要访问成员内部类的成员，必须先创建一个成员内部类的对象，再通过指向这个对象的引用来访问，其具体形式为： 1234567891011121314151617181920212223class Circle &#123; private double radius = 0; public Circle(double radius) &#123; this.radius = radius; // 必须先创建成员内部类的对象，再进行访问 getDrawInstance().drawSahpe(); &#125; private Draw getDrawInstance() &#123; return new Draw(); &#125; /** * 内部类 */ class Draw &#123; public void drawSahpe() &#123; // 外部类的private成员 System.out.println(radius); &#125; &#125;&#125; 成员内部类是依附外部类而存在的，也就是说，如果要创建成员内部类的对象，前提是必须存在一个外部类的对象。创建成员内部类对象的一般方式如下： 12345678910111213141516171819202122232425262728public class Test &#123; public static void main(String[] args) &#123; // 第一种方式 Outter outter = new Outter(); // 必须通过Outter对象来创建 Outter.Inner inner = outter.new Inner(); // 第二种方式 Outter.Inner inner1 = outter.getInnerInstance(); &#125;&#125;class Outter &#123; private Inner inner = null; public Outter() &#123; &#125; public Inner getInnerInstance() &#123; if(inner == null) inner = new Inner(); return inner; &#125; class Inner &#123; public Inner() &#123; &#125; &#125;&#125; 内部类可以拥有 private 访问权限、 protected 访问权限、 public 访问权限及包访问权限。 比如上面的例子，如果成员内部类 Inner 用 private 修饰，则只能在外部类的内部访问；如果用 public 修饰，则任何地方都能访问；如果用 protected 修饰，则只能在同一个包下或者继承外部类的情况下访问；如果是默认访问权限，则只能在同一个包下访问。 这一点和外部类有一点不一样，外部类只能被 public 和包访问两种权限修饰。 我个人是这么理解的，由于成员内部类看起来像是外部类的一个成员，所以可以像类的成员一样拥有多种权限修饰。 局部内部类局部内部类是定义在一个方法或者一个作用域里面的类，它和成员内部类的区别在于局部内部类的访问仅限于方法内或者该作用域内。 12345678910111213141516171819class People&#123; public People() &#123; &#125;&#125;class Man&#123; public Man()&#123; &#125; public People getWoman()&#123; /** * 局部内部类 */ class Woman extends People&#123; int age =0; &#125; return new Woman(); &#125;&#125; 注意，局部内部类就像是方法里面的一个局部变量一样，是不能用 public 、 protected 、 private 以及 static 修饰的。 匿名内部类匿名内部类应该是平时我们编写代码时用得最多的，比如创建一个线程的时候： 1234567891011121314class Test &#123; public static void main(String[] args) &#123; Thread thread = new Thread( // 匿名内部类 new Runnable() &#123; @Override public void run() &#123; System.out.println("Thread run"); &#125; &#125; ); &#125;&#125; 同样的，匿名内部类也是不能有访问修饰符和 static 修饰符的。 匿名内部类是唯一一种没有构造器的类。正因为其没有构造器，所以匿名内部类的使用范围非常有限，大部分匿名内部类用于接口回调。 匿名内部类在编译的时候由系统自动起名为Outter$1.class。一般来说，匿名内部类用于继承其他类或是实现接口，并不需要增加额外的方法，只是对继承方法的实现或是重写。 静态内部类静态内部类也是定义在另一个类里面的类，只不过在类的前面多了一个关键字 static 。 静态内部类是不需要依赖于外部类的，这点和类的静态成员属性有点类似，并且它不能使用外部类的非 static 成员变量或者方法，这点很好理解，因为在没有外部类的对象的情况下，可以创建静态内部类的对象，如果允许访问外部类的非 static 成员就会产生矛盾，因为外部类的非 static 成员必须依附于具体的对象。 例如：123456789101112131415161718public class Test &#123; public static void main(String[] args) &#123; Outter.Inner inner = new Outter.Inner(); &#125;&#125;class Outter &#123; public Outter() &#123; &#125; /** * 静态 */ static class Inner &#123; public Inner() &#123; &#125; &#125;&#125; 深入理解内部类通过上面的介绍，相比你已经大致了解的内部类的使用，那么你的心里想必会有一个疑惑： 为什么成员内部类可以无条件访问外部类的成员？首先我们先定义一个内部类：1234567891011121314151617public class Outter &#123; private Inner inner = null; public Outter() &#123; &#125; public Inner getInnerInstance() &#123; if (inner == null) inner = new Inner(); return inner; &#125; protected class Inner &#123; public Inner() &#123; &#125; &#125;&#125; 先用 javac 进行编译，你可以发现会生成两个文件： Outter$Inner.class 和 Outter.class 。接下来利用javap -p反编译 Outter$Inner.class ，其结果如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253Classfile /D:/project/Test/src/test/java/test/Outter$Inner.class Last modified 2019-11-25; size 408 bytes MD5 checksum b936e37bc77059b83951429e28f3f225 Compiled from "Outter.java"public class Outter$Inner minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPERConstant pool: #1 = Fieldref #3.#13 // test/Outter$Inner.this$0:Ltest/Outter; #2 = Methodref #4.#14 // java/lang/Object."&lt;init&gt;":()V #3 = Class #16 // test/Outter$Inner #4 = Class #19 // java/lang/Object #5 = Utf8 this$0 #6 = Utf8 Ltest/Outter; #7 = Utf8 &lt;init&gt; #8 = Utf8 (Ltest/Outter;)V #9 = Utf8 Code #10 = Utf8 LineNumberTable #11 = Utf8 SourceFile #12 = Utf8 Outter.java #13 = NameAndType #5:#6 // this$0:Ltest/Outter; #14 = NameAndType #7:#20 // "&lt;init&gt;":()V #15 = Class #21 // test/Outter #16 = Utf8 test/Outter$Inner #17 = Utf8 Inner #18 = Utf8 InnerClasses #19 = Utf8 java/lang/Object #20 = Utf8 ()V #21 = Utf8 test/Outter&#123; final Outter this$0; descriptor: Ltest/Outter; flags: ACC_FINAL, ACC_SYNTHETIC public Outter$Inner(Outter); descriptor: (Ltest/Outter;)V flags: ACC_PUBLIC Code: stack=2, locals=2, args_size=2 0: aload_0 1: aload_1 2: putfield #1 // Field this$0:Ltest/Outter; 5: aload_0 6: invokespecial #2 // Method java/lang/Object."&lt;init&gt;":()V 9: return LineNumberTable: line 16: 0 line 17: 9&#125;SourceFile: "Outter.java"InnerClasses: protected #17= #3 of #15; //Inner=class test/Outter$Inner of class test/Outter 32行的内容为：final Outter this$0; 学过 C 的朋友应该能知道，这是一个指向外部类 Outter 对象的指针，也就是说编译器会默认为成员内部类添加一个指向外部类对象的引用，这样也就解释了为什么成员内部类能够无条件访问外部类了。 那么这个引用是如何赋初值的呢？下面接着看内部类的构造器：public Outter$Inner(Outter); 从这里可以看出，虽然我们在定义的内部类的构造器是无参构造器，但编译器还是会默认添加一个参数，该参数的类型为指向外部类对象的一个引用，所以成员内部类中的 Outter this&amp;0 指针便指向了外部类对象，因此可以在成员内部类中随意访问外部类的成员。 从这里也间接说明了成员内部类是依赖于外部类的，如果没有创建外部类的对象，则无法对 Outter this&amp;0 引用进行初始化赋值，也就无法创建成员内部类的对象了。 为什么局部内部类和匿名内部类只能访问局部final变量？我们还是采用和之前一样的解答方式，先定义一个类：123456789101112131415161718public class Outter &#123; public static void main(String[] args) &#123; Outter outter = new Outter(); int b = 10; outter.test(b); &#125; public void test(final int b) &#123; final int a = 10; new Thread()&#123; public void run() &#123; System.out.println(a); System.out.println(b); &#125;; &#125;.start(); &#125;&#125; 通过 javac 编译 Outter，也会生成两个文件： Outter.class 和 Outter1.class。默认情况下，编译器会为匿名内部类和局部内部类起名为 Outter$x.class（ x 为正整数）。 根据我提供的类，可以思考一个问题： 当 test 方法执行完毕之后，变量 a 的生命周期就结束了，而此时 Thread 对象的生命周期很可能还没有结束，那么在 Thread 的 run 方法中继续访问变量 a 就变成不可能了，但是又要实现这样的效果，怎么办呢？ Java 采用了复制的手段来解决这个问题。将 Outter$1.class 反编译可以得到下面的内容： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697Classfile /D:/project/Test/src/test/java/test/Outter$1.class Last modified 2019-11-25; size 653 bytes MD5 checksum 2e238dafbd73356eba22d473c6469082 Compiled from "Outter.java"class test.Outter$1 extends java.lang.Thread minor version: 0 major version: 52 flags: ACC_SUPERConstant pool: #1 = Fieldref #6.#23 // test/Outter$1.this$0:Ltest/Outter; #2 = Fieldref #6.#24 // test/Outter$1.val$b:I #3 = Methodref #7.#25 // java/lang/Thread."&lt;init&gt;":()V #4 = Fieldref #26.#27 // java/lang/System.out:Ljava/io/PrintStream; #5 = Methodref #28.#29 // java/io/PrintStream.println:(I)V #6 = Class #30 // test/Outter$1 #7 = Class #32 // java/lang/Thread #8 = Utf8 val$b #9 = Utf8 I #10 = Utf8 this$0 #11 = Utf8 Ltest/Outter; #12 = Utf8 &lt;init&gt; #13 = Utf8 (Ltest/Outter;I)V #14 = Utf8 Code #15 = Utf8 LineNumberTable #16 = Utf8 run #17 = Utf8 ()V #18 = Utf8 SourceFile #19 = Utf8 Outter.java #20 = Utf8 EnclosingMethod #21 = Class #33 // test/Outter #22 = NameAndType #34:#35 // test:(I)V #23 = NameAndType #10:#11 // this$0:Ltest/Outter; #24 = NameAndType #8:#9 // val$b:I #25 = NameAndType #12:#17 // "&lt;init&gt;":()V #26 = Class #36 // java/lang/System #27 = NameAndType #37:#38 // out:Ljava/io/PrintStream; #28 = Class #39 // java/io/PrintStream #29 = NameAndType #40:#35 // println:(I)V #30 = Utf8 test/Outter$1 #31 = Utf8 InnerClasses #32 = Utf8 java/lang/Thread #33 = Utf8 test/Outter #34 = Utf8 test #35 = Utf8 (I)V #36 = Utf8 java/lang/System #37 = Utf8 out #38 = Utf8 Ljava/io/PrintStream; #39 = Utf8 java/io/PrintStream #40 = Utf8 println&#123; final int val$b; descriptor: I flags: ACC_FINAL, ACC_SYNTHETIC final test.Outter this$0; descriptor: Ltest/Outter; flags: ACC_FINAL, ACC_SYNTHETIC test.Outter$1(test.Outter, int); descriptor: (Ltest/Outter;I)V flags: Code: stack=2, locals=3, args_size=3 0: aload_0 1: aload_1 2: putfield #1 // Field this$0:Ltest/Outter; 5: aload_0 6: iload_2 7: putfield #2 // Field val$b:I 10: aload_0 11: invokespecial #3 // Method java/lang/Thread."&lt;init&gt;":()V 14: return LineNumberTable: line 10: 0 public void run(); descriptor: ()V flags: ACC_PUBLIC Code: stack=2, locals=1, args_size=1 0: getstatic #4 // Field java/lang/System.out:Ljava/io/PrintStream; 3: bipush 10 5: invokevirtual #5 // Method java/io/PrintStream.println:(I)V 8: getstatic #4 // Field java/lang/System.out:Ljava/io/PrintStream; 11: aload_0 12: getfield #2 // Field val$b:I 15: invokevirtual #5 // Method java/io/PrintStream.println:(I)V 18: return LineNumberTable: line 12: 0 line 13: 8 line 14: 18&#125;SourceFile: "Outter.java"EnclosingMethod: #21.#22 // test.Outter.testInnerClasses: #6; //class test/Outter$1 我们看到在 run 方法中有一条指令：bipush 10 这条指令表示将操作数10压栈，表示使用的是一个本地局部变量。 这个过程是在编译期间由编译器默认进行，如果这个变量的值在编译期间可以确定，则编译器默认会在匿名内部类（局部内部类）的常量池中添加一个内容相等的字面量或直接将相应的字节码嵌入到执行字节码中。 这样一来，匿名内部类使用的变量是另一个局部变量，只不过值和方法中局部变量的值相等，因此和方法中的局部变量完全独立开。 接下来也来看一下 test.Outter$1 的构造方法：test.Outter$1(test.Outter, int); 我们看到匿名内部类 Outter$1 的构造器含有两个参数，一个是指向外部类对象的引用，一个是 int 型变量，很显然，这里是将变量 test 方法中的形参 b 以参数的形式传进来对匿名内部类中的拷贝（变量 b 的拷贝）进行赋值初始化。 也就说如果局部变量的值在编译期间就可以确定，则直接在匿名内部里面创建一个拷贝。如果局部变量的值无法在编译期间确定，则通过构造器传参的方式来对拷贝进行初始化赋值。 从上面可以看出，在 run 方法中访问的变量 b 根本就不是test方法中的局部变量 b 。这样一来就解决了前面所说的 生命周期不一致的问题。但是新的问题又来了，既然在 run 方法中访问的变量 b 和test方法中的变量 b 不是同一个变量，那么当在 run 方法中改变变量 b 的值的话，会出现什么情况？ 会造成数据不一致性，这样就达不到原本的意图和要求。为了解决这个问题， Java 编译器就限定必须将变量 b 限制为 final ，不允许对变量 b 进行更改（对于引用类型的变量，是不允许指向新的对象），这样数据不一致性的问题就得以解决了。 到这里，想必大家应该清楚为何 方法中的局部变量和形参都必须用 final 进行限定了。 静态内部类有特殊的地方吗？从前面可以知道，静态内部类是不依赖于外部类的，也就说可以在不创建外部类对象的情况下创建内部类的对象。 另外，静态内部类是不持有指向外部类对象的引用的，这个读者可以自己尝试反编译 class 文件看一下就知道了，是没有 Outter this&amp;0 引用的。 总结今天介绍了内部类相关的知识，包括其一般的用法以及内部类和外部类的依赖关系，通过对字节码进行反编译详细了解了其实现模式，最后留给大家一个任务自己去实际探索一下静态内部类的实现。希望通过这篇介绍可以帮大家更加深刻了解内部类。 有兴趣的话可以访问我的博客或者关注我的公众号、头条号，说不定会有意外的惊喜。 https://jjcoder.top/]]></content>
      <tags>
        <tag>Java</tag>
        <tag>内部类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GC 知识点补充——CMS]]></title>
    <url>%2F2019%2F11%2F01%2FGC%20%E7%9F%A5%E8%AF%86%E7%82%B9%E8%A1%A5%E5%85%85%E2%80%94%E2%80%94CMS%2F</url>
    <content type="text"><![CDATA[之前已经讲过了不少有关 GC 的内容，今天准备将之前没有细讲的部分进行补充，首先要提到的就是垃圾收集器。 基础的回收方式有三种：清除、压缩、复制，衍生出来的垃圾收集器有： Serial 收集器新生代收集器，使用停止复制算法，使用一个线程进行 GC ，串行，其它工作线程暂停。 使用-XX:+UseSerialGC开关来控制使用Serial + Serial Old模式运行进行内存回收（这也是虚拟机在 Client 模式下运行的默认值）。 ParNew 收集器新生代收集器，使用停止复制算法，Serial 收集器的多线程版，用多个线程进行 GC ，并行，其它工作线程暂停，关注缩短垃圾收集时间。 使用-XX:+UseParNewGC开关来控制使用ParNew + Serial Old收集器组合收集内存；使用-XX:ParallelGCThreads来设置执行内存回收的线程数。 Parallel Scavenge 收集器新生代收集器，使用停止复制算法，关注 CPU 吞吐量，即运行用户代码的时间/总时间，比如：JVM 运行 100 分钟，其中运行用户代码 99 分钟，垃 圾收集 1 分钟，则吞吐量是 99% ，这种收集器能最高效率的利用 CPU ，适合运行后台运算（其他关注缩短垃圾收集时间的收集器，如 CMS ，等待时间很少，所以适 合用户交互，提高用户体验）。 使用-XX:+UseParallelGC开关控制使用Parallel Scavenge + Serial Old收集器组合回收垃圾（这也是在 Server 模式下的默认值）；使用-XX:GCTimeRatio来设置用户执行时间占总时间的比例，默认 99 ，即 1% 的时间用来进行垃圾回收。使用-XX:MaxGCPauseMillis设置 GC 的最大停顿时间（这个参数只对 Parallel Scavenge 有效），用开关参数-XX:+UseAdaptiveSizePolicy可以进行动态控制，如自动调整 Eden / Survivor 比例，老年代对象年龄，新生代大小等，这个参数在 ParNew 下没有。 Serial Old 收集器老年代收集器，单线程收集器，串行，使用标记-整理算法，使用单线程进行GC，其它工作线程暂停（注意：在老年代中进行标记-整理算法清理，也需要暂停其它线程），在JDK1.5之前，Serial Old 收集器与 ParallelScavenge 搭配使用。 整理的方法是 Sweep （清除）和 Compact （压缩），清除是将废弃的对象干掉，只留幸存的对象，压缩是移动对象，将空间填满保证内存分为2块，一块全是对象，一块空闲）， Parallel Old 收集器老年代收集器，多线程，并行，多线程机制与 Parallel Scavenge 差不错，使用标记-整理算法，在 Parallel Old 执行时，仍然需要暂停其它工作线程。 Parallel Old 收集器的整理，与 Serial Old 不同，这里的整理是Copy（复制）和Compact（压缩），复制的意思就是将幸存的对象复制到预先准备好的区域，而不是像Sweep（清除）那样清除废弃的对象。 Parallel Old 在多核计算中很有用。 Parallel Old 出现后（JDK 1.6），与 Parallel Scavenge 配合有很好的效果，充分体现 Parallel Scavenge 收集器吞吐量优先的效果。使用-XX:+UseParallelOldGC开关控制使用Parallel Scavenge + Parallel Old组合收集器进行收集。 CMS全称 Concurrent Mark Sweep，老年代收集器，致力于获取最短回收停顿时间（即缩短垃圾回收的时间），使用标记-清除算法，多线程，优点是并发收集（用户线程可以和 GC 线程同时工作），停顿小。 使用-XX:+UseConcMarkSweepGC进行ParNew + CMS + Serial Old进行内存回收，优先使用ParNew + CMS（原因见后面），当用户线程内存不足时，采用备用方案Serial Old收集。 如何开始首先来看一下 CMS 是在什么情况下进行 GC： 首先 JVM 根据-XX:CMSInitiatingOccupancyFraction、-XX:+UseCMSInitiatingOccupancyOnly来决定什么时间开始垃圾收集。 如果设置了-XX:+UseCMSInitiatingOccupancyOnly，那么只有当老年代占用确实达到了-XX:CMSInitiatingOccupancyFraction参数所设定的比例时才会触发 CMS GC。 如果没有设置-XX:+UseCMSInitiatingOccupancyOnly，那么系统会根据统计数据自行决定什么时候触发 CMS GC。因此有时会遇到设置了 80% 比例才 CMS GC，但是 50% 时就已经触发了，就是因为这个参数没有设置的原因。 具体执行CMS GC 的执行过程，具体来说就是： 初始标记(CMS-initial-mark)该阶段是 stop the world 阶段，因此此阶段标记的对象只是从 root 集最直接可达的对象。 此阶段会打印 1 条日志：CMS-initial-mark：961330K（1572864K），指标记时，老年代的已用空间和总空间 并发标记(CMS-concurrent-mark)此阶段是和应用线程并发执行的，所谓并发收集器指的就是这个，主要作用是标记可达的对象，此阶段不需要用户线程停顿。 此阶段会打印 2 条日志：CMS-concurrent-mark-start，CMS-concurrent-mark 预清理(CMS-concurrent-preclean)此阶段主要是进行一些预清理，因为标记和应用线程是并发执行的，因此会有些对象的状态在标记后会改变，此阶段正是解决这个问题。因为之后的 CMS-remark 阶段也会 stop the world，为了使暂停的时间尽可能的小，也需要 preclean 阶段先做一部分工作以节省时间。 此阶段会打印 2 条日志：CMS-concurrent-preclean-start，CMS-concurrent-preclean 可控预清理(CMS-concurrent-abortable-preclean)此阶段的目的是使 CMS GC 更加可控一些，作用也是执行一些预清理，以减少 CMS-remark 阶段造成应用暂停的时间。 此阶段涉及几个参数：123-XX:CMSMaxAbortablePrecleanTime：当 abortable-preclean 阶段执行达到这个时间时才会结束。-XX:CMSScheduleRemarkEdenSizeThreshold（默认2m）：控制 abortable-preclean 阶段什么时候开始执行，即当年轻代使用达到此值时，才会开始 abortable-preclean 阶段。-XX:CMSScheduleRemarkEdenPenetratio（默认50%）：控制 abortable-preclean 阶段什么时候结束执行。 此阶段会打印 3 条日志：CMS-concurrent-abortable-preclean-start，CMS-concurrent-abortable-preclean，CMS：abort preclean due to time XXX 重新标记(CMS-remark)此阶段暂停应用线程，停顿时间比并发标记小得多，但比初始标记稍长，因为会对所有对象进行重新扫描并标记。 此阶段会打印以下日志： YG occupancy：964861K（2403008K），指执行时年轻代的情况。 CMS remark：961330K（1572864K），指执行时老年代的情况。 此外，还打印出了弱引用处理、类卸载等过程的耗时。 并发清除(CMS-concurrent-sweep)此阶段进行并发的垃圾清理。 并发重设状态等待下次CMS的触发(CMS-concurrent-reset)此阶段是为下一次 CMS GC 重置相关数据结构。 总结CMS 的收集过程，概括一下就是：2 次标记，2 次预清除，1 次重新标记，1 次清除。 在CMS清理过程中，只有初始标记和重新标记需要短暂停顿用户线程，并发标记和并发清除都不需要暂停用户线程，因此效率很高，很适合高交互的场合。 CMS也有缺点，它需要消耗额外的 CPU 和内存资源。在 CPU 和内存资源紧张，会加重系统负担（CMS 默认启动线程数为( CPU数量 + 3 ) / 4 ）。 另外，在并发收集过程中，用户线程仍然在运行，仍然产生内存垃圾，所以可能产生“浮动垃圾”（本次无法清理，只能下一次Full GC才清理）。因此在 GC 期间，需要预留足够的内存给用户线程使用。 所以使用 CMS 的收集器并不是老年代满了才触发 Full GC ，而是在使用了一大半（默认 68% ，即 2/3 ，使用-XX:CMSInitiatingOccupancyFraction来设置）的时候就要进行 Full GC。如果用户线程消耗内存不是特别大，可以适当调高-XX:CMSInitiatingOccupancyFraction以降低 GC 次数，提高性能。如果预留的用户线程内存不够，则会触发 Concurrent Mode Failure，此时，将触发备用方案：使用 Serial Old 收集器进行收集，但这样停顿时间就长了，因此-XX:CMSInitiatingOccupancyFraction不宜设的过大。 还有，CMS 采用的是标记-清除算法，会导致内存碎片的产生，可以使用-XX：+UseCMSCompactAtFullCollection来设置是否在 Full GC 之后进行碎片整理，用-XX：CMSFullGCsBeforeCompaction来设置在执行多少次不压缩的 Full GC 之后，来一次带压缩的 Full GC。 并发和并行并发收集： 指用户线程与GC线程同时执行（不一定是并行，可能交替，但总体上是在同时执行的），不需要停顿用户线程（其实在 CMS 中用户线程还是需要停顿的，只是非常短，GC 线程在另一个 CPU 上执行）； 并行收集： 指多个 GC 线程并行工作，但此时用户线程是暂停的； 所以，Serial 是串行的，Parallel 收集器是并行的，而 CMS 收集器是并发的。 总结今天了解了一下普通的垃圾收集器，并且详细介绍了 CMS，其特性其实是基于普通的垃圾算法，增加了预处理、预清除的过程，因此效率更加优越。当然它也有自己的缺点，更加消耗资源，因此在选用的时候需要结合实际场景。 有兴趣的话可以访问我的博客或者关注我的公众号、头条号，说不定会有意外的惊喜。 https://jjcoder.top/]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>GC</tag>
        <tag>CMS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM 知识点补充——永久代和元空间]]></title>
    <url>%2F2019%2F10%2F31%2FJVM%20%E7%9F%A5%E8%AF%86%E7%82%B9%E8%A1%A5%E5%85%85%E2%80%94%E2%80%94%E6%B0%B8%E4%B9%85%E4%BB%A3%E5%92%8C%E5%85%83%E7%A9%BA%E9%97%B4%2F</url>
    <content type="text"><![CDATA[之前已经讲过了不少有关 JVM 的内容，今天准备将之前没有细讲的部分进行补充，比如：永久代和元空间。 永久代Java 的内存中有一块称之为方法区的部分，在 JDK8 之前， Hotspot 虚拟机中的实现方式为永久代（Permanent Generation），别的JVM都没有这个东西。 在过去（当自定义类加载器使用不普遍的时候），类几乎是“静态的”并且很少被卸载和回收，因此类也可以被看成“永久的”。另外由于类作为 JVM 实现的一部分，它们不由程序来创建，因为它们也被认为是“非堆”的内存。 永久代是一段连续的内存空间，我们在 JVM 启动之前可以通过设置-XX:MaxPermSize的值来控制永久代的大小，32 位机器默认的永久代的大小为 64M，64 位的机器则为 85M。 永久代的垃圾回收和老年代的垃圾回收是绑定的，一旦其中一个区域被占满，这两个区都要进行垃圾回收。但是有一个明显的问题，由于我们可以通过‑XX:MaxPermSize设置永久代的大小，一旦类的元数据超过了设定的大小，程序就会耗尽内存，并出现内存溢出错误 (java.lang.OutOfMemoryError: PermGen space)。 为什么类的元数据占用内存会那么大？因为在 JDK7 之前的 HotSpot 虚拟机中，纳入字符串常量池的字符串被存储在永久代中，因此导致了一系列的性能问题和内存溢出错误。 为了解决这些性能问题，也为了能够让 Hotspot 能和其他的虚拟机一样管理，元空间就产生了。 元空间元空间是 Hotspot 在 JDK8 中新加的内容，其本质和永久代类似，都是对 JVM 规范中方法区的实现。不过元空间与永久代之间最大的区别在于： 元空间并不在虚拟机中，而是使用本地内存。因此，默认情况下，元空间的大小仅受本地内存限制，但可以通过以下参数来指定元空间的大小： -XX:MetaspaceSize 初始空间大小，达到该值就会触发垃圾收集进行类型卸载，同时GC会对该值进行调整：如果释放了大量的空间，就适当降低该值；如果释放了很少的空间，那么在不超过MaxMetaspaceSize时，适当提高该值。 -XX:MaxMetaspaceSize最大空间，默认是没有限制的。 除了上面两个指定大小的选项以外，还有两个与 GC 相关的属性： -XX:MinMetaspaceFreeRatio 在GC之后，最小的Metaspace剩余空间容量的百分比，减少为分配空间所导致的垃圾收集 -XX:MaxMetaspaceFreeRatio 在GC之后，最大的Metaspace剩余空间容量的百分比，减少为释放空间所导致的垃圾收集 移除永久代的影响由于类的元数据分配在本地内存中，元空间的最大可分配空间就是系统可用内存空间。因此，我们就不会遇到永久代存在时的内存溢出错误，也不会出现泄漏的数据移到交换区这样的事情。最终用户可以为元空间设置一个可用空间最大值，如果不进行设置，JVM 会自动根据类的元数据大小动态增加元空间的容量。 注意：永久代的移除并不代表自定义的类加载器泄露问题就解决了。因此，你还必须监控你的内存消耗情况，因为一旦发生泄漏，会占用你的大量本地内存，并且还可能导致交换区交换更加糟糕。 元空间内存管理元空间的内存管理由元空间虚拟机来完成。 先前，对于类的元数据我们需要不同的垃圾回收器进行处理，现在只需要执行元空间虚拟机的 C++ 代码即可完成。在元空间中，类和其元数据的生命周期和其对应的类加载器是相同的。话句话说，只要类加载器存活，其加载的类的元数据也是存活的，因而不会被回收掉。 准确的来说，每一个类加载器的存储区域都称作一个元空间，所有的元空间合在一起就是我们一直说的元空间。当一个类加载器被垃圾回收器标记为不再存活，其对应的元空间会被回收。在元空间的回收过程中没有重定位和压缩等操作。但是元空间内的元数据会进行扫描来确定 Java 引用。 那具体是如何管理的呢？ 元空间虚拟机负责元空间的分配，其采用的形式为组块分配。组块的大小因类加载器的类型而异。在元空间虚拟机中存在一个全局的空闲组块列表。 当一个类加载器需要组块时，它就会从这个全局的组块列表中获取并维持一个自己的组块列表。 当一个类加载器不再存活时，那么其持有的组块将会被释放，并返回给全局组块列表。 类加载器持有的组块又会被分成多个块，每一个块存储一个单元的元信息。组块中的块是线性分配（指针碰撞分配形式）。组块分配自内存映射区域。这些全局的虚拟内存映射区域以链表形式连接，一旦某个虚拟内存映射区域清空，这部分内存就会返回给操作系统。 运行时常量池运行时常量池在 JDK6 及之前版本的 JVM 中是方法区的一部分，而在 HotSpot 虚拟机中方法区的实现是永久代(Permanent Generation)。所以运行时常量池也是在永久代的。 但是 JDK7 及之后版本的 JVM 已经将字符串常量池从方法区中移了出来，在堆（Heap）中开辟了一块区域存放运行时常量池。 String.intern()是一个 Native 方法，它的作用是：如果运行时常量池中已经包含一个等于此 String 对象内容的字符串，则返回常量池中该字符串的引用；如果没有，则在常量池中创建与此 String 内容相同的字符串，并返回常量池中创建的字符串的引用。 存在的问题前面已经提到，元空间虚拟机采用了组块分配的形式，同时区块的大小由类加载器类型决定。类信息并不是固定大小，因此有可能分配的空闲区块和类需要的区块大小不同，这种情况下可能导致碎片存在。元空间虚拟机目前并不支持压缩操作，所以碎片化是目前最大的问题。 总结曾经的永久代，因为容易产生 OOM 而被优化成了元空间，但即便这样，依然存在着问题，不知道 JDK 之后还会怎样优化呢？ 有兴趣的话可以访问我的博客或者关注我的公众号、头条号，说不定会有意外的惊喜。 https://jjcoder.top/]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>永久代</tag>
        <tag>元空间</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式——原型模式]]></title>
    <url>%2F2019%2F10%2F30%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[设计模式中，单例模式应该是大家最为熟悉的了，那如果我们需要对一个对象进行多次复制的话，大家会用什么呢？这就要用到今天要讲的原型模式了。 简介其定义为： 使用原型实例指定将要创建的对象类型，通过复制这个实例创建新的对象。 具体来说就是，通过给出一个原型对象来指明所创建的对象的类型，然后使用自身实现的克隆接口来复制这个原型对象，该模式就是用这种方式来创建出更多同类型的对象。 这样的好处是： Object 类的 clone() 方法是一个本地方法，它可以直接操作内存中的二进制流，所以性能相对 new 实例化来说，更加优秀。 一个对象通过 new 实例化创建过程为： 在内存中开辟一块空间。 在开辟的内存空间中创建对象。 调用对象的构造函数进行初始化对象。 而一个对象通过 clone() 创建过程为： 根据原对象内存大小开辟一块内存空间。 复制已有对象，克隆对象中所有属性值。 相对 new 来说，clone() 少了调用构造函数。如果构造函数中存在大量属性初始化或大对象，则使用 clone() 的复制对象的方式性能会好一些。 简单例子让我们通过一个例子来具体了解一下：12345678910111213141516171819202122232425262728293031323334353637383940/** * 实现Cloneable 接口的原型抽象类Prototype */public class Prototype implements Cloneable &#123; /** * 重写 clone() 方法 */ @Override public Prototype clone() &#123; Prototype prototype = null; try &#123; prototype = (Prototype) super.clone(); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; return prototype; &#125;&#125;/** * 实现原型类 */public class ConcretePrototype extends Prototype &#123; public void show() &#123; System.out.println(&quot;原型模式实现类&quot;); &#125;&#125;/** * 测试类 */public class Client &#123; public static void main(String[] args) &#123; ConcretePrototype cp = new ConcretePrototype(); for (int i = 0; i &lt; 10; i++) &#123; ConcretePrototype cloneCp = (ConcretePrototype) cp.clone(); cloneCp.show(); &#125; &#125;&#125; 当我们实现原型抽象类时，需要注意三点： 实现 Cloneable 接口：Cloneable 接口与序列化接口的作用类似，它只是告诉虚拟机可以安全地在实现了这个接口的类上使用 clone() 方法。在 JVM 中，只有实现了 Cloneable 接口的类才可以被拷贝，否则会抛出 CloneNotSupportedException 异常。 重写 Object 类中的 clone() 方法：在 Java 中，所有类的父类都是 Object 类，而 Object 类中有一个 clone() 方法，作用是返回对象的一个拷贝。 在重写的 clone() 方法中调用 super.clone()：默认情况下，类不具备复制对象的能力，需要调用 super.clone() 来实现。 深拷贝与浅拷贝谈到了拷贝，就不得不说到一个经典的问题：深拷贝与浅拷贝，有的地方也叫深克隆与浅克隆。 在上面的原型模式中，在调用 super.clone() 方法之后，首先会检查当前对象所属的类是否支持 clone，也就是看该类是否实现了 Cloneable 接口。 如果支持，则创建当前对象所属类的一个新对象，并对该对象进行初始化，使得新对象的成员变量的值与当前对象的成员变量的值一模一样，但对于其它对象的引用以及 List 等类型的成员属性，则只能复制这些对象的引用了。所以简单调用 super.clone() 这种克隆对象方式，就是一种浅拷贝。 为了让大家更加清楚浅拷贝的弊端，举个具体的例子： Student 类中有一个 Teacher 对象，我们让这两个类都实现 Cloneable 接口：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@Getter@Setterpublic class Student implements Cloneable&#123; /** * 学生姓名 */ private String name; /** * 学生所属的老师 */ private Teacher teacher; /** * 重写克隆方法，对学生进行克隆 */ public Student clone() &#123; Student student = null; try &#123; student = (Student) super.clone(); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; return student; &#125;&#125;@Getter@Setterpublic class Teacher implements Cloneable&#123; /** * 老师姓名 */ private String name; /** * 重写克隆方法，对老师类进行克隆 */ public Teacher clone() &#123; Teacher teacher= null; try &#123; teacher= (Teacher) super.clone(); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; return teacher; &#125;&#125; 测试的时候，我们先定义一个学生和一个老师，并让其关联在一起。然后复制之前的学生，生成一个新的学生，修改新学生的老师。12345678910111213141516171819202122public class Test &#123; public static void main(String args[]) &#123; // 定义老师1 Teacher teacher = new Teacher(); teacher.setName("刘老师"); // 定义学生1 Student stu1 = new Student(); stu1.setName("test1"); // 老师1和学生1进行关联 stu1.setTeacher(teacher); // 复制学生1，生成学生2 Student stu2 = stu1.clone(); stu2.setName("test2"); // 修改学生2的老师 stu2.getTeacher().setName("王老师"); // 查看修改结果 System.out.println("学生" + stu1.getName() + "的老师是:" + stu1.getTeacher().getName()); System.out.println("学生" + stu1.getName() + "的老师是:" + stu2.getTeacher().getName()); &#125;&#125; 我们想要的结果是：12学生test1的老师是：刘老师学生test2的老师是：王老师 但实际结果是：12学生test1的老师是：王老师学生test2的老师是：王老师 观察以上运行结果，我们可以发现：在我们给学生2修改老师的时候，学生1的老师也跟着被修改了。这就是浅拷贝带来的问题。 我们可以通过深拷贝的方式解决这类问题，修改 Student 类的 clone() 方法：123456789101112131415/** * 重写克隆方法，对学生和老师都进行克隆 */public Student clone() &#123; Student student = null; try &#123; student = (Student) super.clone(); // 克隆 teacher 对象 Teacher teacher = this.teacher.clone(); student.setTeacher(teacher); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; return student;&#125; 此时，我们再次运行 Test 中的 main() 方法，就可以得到我们预想的结果了。 适用场景在一些重复创建对象的场景下，我们就可以使用原型模式来提高对象的创建性能。例如：循环体内创建对象时，我们就可以考虑用 clone() 的方式来实现。 除此之外，原型模式在开源框架中的应用也非常广泛。例如 Spring 中，@Service 默认都是单例的。用了私有全局变量，若不想影响下次注入或每次上下文获取 bean，就需要用到原型模式，我们可以通过以下注解来实现，@Scope(“prototype”)。有兴趣的朋友深入了解一下其中的原理。 总结原型模式，就是针对需要大量复制同一对象的场景，比如用户获取商品、循环体内创建对象等，都是不错的选择，且效率好。 有兴趣的话可以访问我的博客或者关注我的公众号、头条号，说不定会有意外的惊喜。 https://jjcoder.top/]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>原型模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty - 粘包和半包(下)]]></title>
    <url>%2F2019%2F10%2F24%2FNetty%20-%20%E7%B2%98%E5%8C%85%E5%92%8C%E5%8D%8A%E5%8C%85(%E4%B8%8B)%2F</url>
    <content type="text"><![CDATA[上一篇介绍了粘包和半包及其通用的解决方案，今天重点来看一下 Netty 是如何实现封装成帧(Framing)方案的。 解码核心流程之前介绍过三种解码器FixedLengthFrameDecoder、DelimiterBasedFrameDecoder、LengthFieldBasedFrameDecoder，它们都继承自ByteToMessageDecoder，而ByteToMessageDecoder继承自ChannelInboundHandlerAdapter，其核心方法为channelRead。因此，我们来看看ByteToMessageDecoder的channelRead方法：123456789101112131415161718192021@Overridepublic void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; if (msg instanceof ByteBuf) &#123; CodecOutputList out = CodecOutputList.newInstance(); try &#123; // 将传入的消息转化为data ByteBuf data = (ByteBuf) msg; // 最终实现的目标是将数据全部放进cumulation中 first = cumulation == null; // 第一笔数据直接放入 if (first) &#123; cumulation = data; &#125; else &#123; // 不是第一笔数据就进行追加 cumulation = cumulator.cumulate(ctx.alloc(), cumulation, data); &#125; // 解码 callDecode(ctx, cumulation, out); &#125; // 以下代码省略，因为不属于解码过程&#125; 再来看看callDecode方法：123456789101112131415protected void callDecode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) &#123; try &#123; while (in.isReadable()) &#123; int outSize = out.size(); if (outSize &gt; 0) &#123; // 以下代码省略，因为初始状态时，outSize 只可能是0，不可能进入这里 &#125; int oldInputLength = in.readableBytes(); // 在进行 decode 时，不执行handler的remove操作。 // 只有当 decode 执行完之后，开始清理数据。 decodeRemovalReentryProtection(ctx, in, out); // 省略以下代码，因为后面的内容也不是解码的过程 再来看看decodeRemovalReentryProtection方法：12345678910111213141516171819final void decodeRemovalReentryProtection(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception &#123; // 设置当前状态为正在解码 decodeState = STATE_CALLING_CHILD_DECODE; try &#123; // 解码 decode(ctx, in, out); &#125; finally &#123; // 执行hander的remove操作 boolean removePending = decodeState == STATE_HANDLER_REMOVED_PENDING; decodeState = STATE_INIT; if (removePending) &#123; handlerRemoved(ctx); &#125; &#125;&#125;// 子类都重写了该方法，每种实现都会有自己特殊的解码方式protected abstract void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception; 从上面的过程可以总结出，在解码之前，需要先将数据写入cumulation，当解码结束后，需要通过 handler 进行移除。 具体解码过程刚刚说到decode方法在子类中都有实现，那针对我们说的三种解码方式，一一看其实现。 FixedLengthFrameDecoder其源码为：1234567891011121314151617@Overrideprotected final void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception &#123; Object decoded = decode(ctx, in); if (decoded != null) &#123; out.add(decoded); &#125;&#125;protected Object decode( @SuppressWarnings("UnusedParameters") ChannelHandlerContext ctx, ByteBuf in) throws Exception &#123; // 收集到的数据是否小于固定长度，小于就代表无法解析 if (in.readableBytes() &lt; frameLength) &#123; return null; &#125; else &#123; return in.readRetainedSlice(frameLength); &#125;&#125; 就和这个类的名字一样简单，就是固定长度进行解码，因此，在设置该解码器的时候，需要在构造方式里传入frameLength。 DelimiterBasedFrameDecoder其源码为：12345678910111213141516171819202122232425@Overrideprotected final void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception &#123; Object decoded = decode(ctx, in); if (decoded != null) &#123; out.add(decoded); &#125;&#125;protected Object decode(ChannelHandlerContext ctx, ByteBuf buffer) throws Exception &#123; // 当前的分割符是否是换行分割符(\n或者\r\n) if (lineBasedDecoder != null) &#123; return lineBasedDecoder.decode(ctx, buffer); &#125; // Try all delimiters and choose the delimiter which yields the shortest frame. int minFrameLength = Integer.MAX_VALUE; ByteBuf minDelim = null; // 其他分割符进行一次切分 for (ByteBuf delim: delimiters) &#123; int frameLength = indexOf(buffer, delim); if (frameLength &gt;= 0 &amp;&amp; frameLength &lt; minFrameLength) &#123; minFrameLength = frameLength; minDelim = delim; &#125; &#125; // 以下代码省略 根据它的名字可以知道，分隔符才是它的核心。它将分割符分成两类，只有换行分割符(\n或者\r\n)和其他。因此，需要注意的是，你可以定义多种分割符，它都是支持的。 LengthFieldBasedFrameDecoder该类比较复杂，如果直接看方法容易把自己看混乱，因此我准备结合类上的解释，先看看其私有变量。 2 bytes length field at offset 1 in the middle of 4 bytes header, strip the first header field and the length field, the length field represents the length of the whole message Let’s give another twist to the previous example. The only difference from the previous example is that the length field represents the length of the whole message instead of the message body, just like the third example. We have to count the length of HDR1 and Length into lengthAdjustment. Please note that we don’t need to take the length of HDR2 into account because the length field already includes the whole header length. 12345* BEFORE DECODE (16 bytes) AFTER DECODE (13 bytes)* +------+--------+------+----------------+ +------+----------------+* | HDR1 | Length | HDR2 | Actual Content |-----&gt;| HDR2 | Actual Content |* | 0xCA | 0x0010 | 0xFE | &quot;HELLO, WORLD&quot; | | 0xFE | &quot;HELLO, WORLD&quot; |* +------+--------+------+----------------+ +------+----------------+ lengthFieldOffset : 该字段代表 Length 字段是从第几个字节开始的。上面的例子里，Length 字段是从第1个字节开始（HDR1 是第0个字节），因此该值即为0。 lengthFieldLength : 该字段代表 Length 字段所占用的字节数。上面的例子里，Length 字段占用2个字节，因此该值为2。 lengthAdjustment : 该字段代表 Length 字段结束位置到真正的内容开始位置的距离。上面例子里，因为 Length 字段的含义是整个消息（包括 HDR1、Length、HDR2、Actual Content，一般 Length 指的只是 Actual Content），所以 Length 末尾到真正的内容开始位置（HDR1的开始处），相当于减少3个字节，所以是-3。 initialBytesToStrip : 展示时需要从 Length 字段末尾开始跳过几个字节。上面例子里，因为真正的内容是从 HDR1 开始的，最终展示的内容是从 HDR2 开始的，所以中间差了3个字节，所以该值是3。 该类的解码方法比较复杂，有兴趣的同学可以试着自己分析一下。 总结这一篇主要是结合 Netty 里的源代码讲解了 Netty 中封装成帧(Framing)的三种方式，相信你一定有了不一样的理解。 有兴趣的话可以访问我的博客或者关注我的公众号、头条号，说不定会有意外的惊喜。 https://death00.github.io/]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Netty</tag>
        <tag>粘包</tag>
        <tag>半包</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty - 粘包和半包(上)]]></title>
    <url>%2F2019%2F10%2F23%2FNetty%20-%20%E7%B2%98%E5%8C%85%E5%92%8C%E5%8D%8A%E5%8C%85(%E4%B8%8A)%2F</url>
    <content type="text"><![CDATA[在网络传输中，粘包和半包应该是最长出现的问题，作为 Java 中最常使用的 NIO 网络框架 Netty，它又是如何解决的呢？今天就让我们来看看。 定义TCP 传输中，客户端发送数据，实际是把数据写入到了 TCP 的缓存中，粘包和半包也就会在此时产生。 客户端给服务端发送了两条消息ABC和DEF，服务端这边的接收会有多少种情况呢？有可能是一次性收到了所有的消息ABCDEF，有可能是收到了三条消息AB、CD、EF。 上面所说的一次性收到了所有的消息ABCDEF，类似于粘包。如果客户端发送的包的大小比 TCP 的缓存容量小，并且 TCP 缓存可以存放多个包，那么客户端和服务端的一次通信就可能传递了多个包，这时候服务端从 TCP 缓存就可能一下读取了多个包，这种现象就叫粘包。 上面说的后面那种收到了三条消息AB、CD、EF，类似于半包。如果客户端发送的包的大小比 TCP 的缓存容量大，那么这个数据包就会被分成多个包，通过 Socket 多次发送到服务端，服务端第一次从接受缓存里面获取的数据，实际是整个包的一部分，这时候就产生了半包(半包不是说只收到了全包的一半，是说收到了全包的一部分)。 产生原因其实从上面的定义，我们就可以大概知道产生的原因了。 粘包的主要原因： 发送方每次写入数据 &lt; 套接字(Socket)缓冲区大小 接收方读取套接字(Socket)缓冲区数据不够及时 半包的主要原因： 发送方每次写入数据 &gt; 套接字(Socket)缓冲区大小 发送的数据大于协议的 MTU (Maximum Transmission Unit，最大传输单元)，因此必须拆包 其实我们可以换个角度看待问题： 从收发的角度看，便是一个发送可能被多次接收，多个发送可能被一次接收。 从传输的角度看，便是一个发送可能占用多个传输包，多个发送可能公用一个传输包。 根本原因，其实是 TCP 是流式协议，消息无边界。 (PS ： UDP 虽然也可以一次传输多个包或者多次传输一个包，但每个消息都是有边界的，因此不会有粘包和半包问题。) 解决方法就像上面说的，UDP 之所以不会产生粘包和半包问题，主要是因为消息有边界，因此，我们也可以采取类似的思路。 改成短连接将 TCP 连接改成短连接，一个请求一个短连接。这样的话，建立连接到释放连接之间的消息即为传输的信息，消息也就产生了边界。 这样的方法就是十分简单，不需要在我们的应用中做过多修改。但缺点也就很明显了，效率低下，TCP 连接和断开都会涉及三次握手以及四次握手，每个消息都会涉及这些过程，十分浪费性能。 因此，并不推介这种方式。 封装成帧封装成帧(Framing)，也就是原本发送消息的单位是缓冲大小，现在换成了帧，这样我们就可以自定义边界了。一般有4种方式： 固定长度这种方式下，消息边界也就是固定长度即可。 优点就是实现很简单，缺点就是空间有极大的浪费，如果传递的消息中大部分都比较短，这样就会有很多空间是浪费的。 因此，这种方式一般也是不推介的。 分隔符这种方式下，消息边界也就是分隔符本身。 优点是空间不再浪费，实现也比较简单。缺点是当内容本身出现分割符时需要转义，所以无论是发送还是接受，都需要进行整个内容的扫描。 因此，这种方式效率也不是很高，但可以尝试使用。 专门的 length 字段这种方式，就有点类似 Http 请求中的 Content-Length，有一个专门的字段存储消息的长度。作为服务端，接受消息时，先解析固定长度的字段（length字段）获取消息总长度，然后读取后续内容。 优点是精确定位用户数据，内容也不用转义。缺点是长度理论上有限制，需要提前限制可能的最大长度从而定义长度占用字节数。 因次，十分推介用这种方式。 其他方式其他方式就各不相同了，比如 JSON 可以看成是使用{}是否成对。这些优缺点就需要大家在各自的场景中进行衡量了。 Netty 中的实现Netty 支持上文所讲的封装成帧(Framing)中的前三种方式，简单介绍下： 方式 解码 编码 固定长度 FixedLengthFrameDecoder 简单 分割符 DelimiterBasedFrameDecoder 简答 专门的 length 字段 LengthFieldBasedFrameDecoder LengthFieldPrepender 总结今天主要介绍了粘包和半包问题、解决思路和 Netty 中的支持，我会在下一篇文章里重点讲述 Netty 中的具体实现，敬请期待。 有兴趣的话可以访问我的博客或者关注我的公众号、头条号，说不定会有意外的惊喜。 https://death00.github.io/]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Netty</tag>
        <tag>粘包</tag>
        <tag>半包</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 面试 - ThreadLocal 原理]]></title>
    <url>%2F2019%2F10%2F23%2FJava%20%E9%9D%A2%E8%AF%95%20-%20ThreadLocal%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[关于 ThreadLocal，我们经常用它来解决多线程并发问题，那它究竟是如何做到的？今天就让我们来好好看一下。 从源码入手首先，让我们看看 ThreadLocal 类中的介绍： This class provides thread-local variables. These variables differ from their normal counterparts in that each thread that accesses one (via its get or set method) has its own, independently initialized copy of the variable. ThreadLocal instances are typically private static fields in classes that wish to associate state with a thread (e.g., a user ID or Transaction ID). Each thread holds an implicit reference to its copy of a thread-local variable as long as the thread is alive and the ThreadLocal instance is accessible; after a thread goes away, all of its copies of thread-local instances are subject to garbage collection (unless other references to these copies exist). 按照文中所述，ThreadLocal 提供的是线程本地变量，每个线程都有一份单独的副本，经常使用的方式是私有静态变量。关键在于下一段，线程存活，ThreadLocal 实例就可以被访问，线程消失，就会被垃圾回收。 get()方法看到这儿，有没有想起上一篇内容所说的引用类型，有可能是软引用或者弱引用，具体是什么呢？还是来看看代码：12345678910111213141516171819public T get() &#123; // 获取当前线程 Thread t = Thread.currentThread(); // 获取线程里的map ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125;ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; 上面展示的是 ThreadLocal 中的get()方法，关键的 map 是在 Thread 类中的threadLocals变量，让我们继续看看 ThreadLocalMap 的源代码： 12345678910111213141516ThreadLocal.ThreadLocalMap threadLocals = null;static class ThreadLocalMap &#123; static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; // 使用ThreadLocal作为key，并且是弱引用 super(k); value = v; &#125; &#125; // 省略代码&#125; 根据上一篇文章所述，如果一个对象只有弱引用，那么当下一次 GC 进行时，该对象就会被回收。那么让我们整理一下： ThreadLocalMap 的 Entry 对 ThreadLocal 的引用为弱引用。 ThreadLocal 本身并不存储值，具体的 value 依旧在各个线程中。因此你可以把 ThreadLocal 看成一个工具类。 但需要注意的是，Entry 中，只有key是弱引用，但 value 依旧是强引用。那会不会出现 key 被垃圾回收后，这个 map 的 key 为 null，但 value 依旧存在的情况呢？ set()方法确实是有可能的，但 JDK 本身也做了优化，可以看看 ThreadLocalMap 的 set()方法：1234567891011121314151617181920212223242526272829303132private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; // We don't use a fast path as with get() because it is at // least as common to use set() to create new entries as // it is to replace existing ones, in which case, a fast // path would fail more often than not. Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) &#123; e.value = value; return; &#125; if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();&#125; 调用 set()的时候，ThreadLocalMap 检查到 key 为 null 的 entry 时，会将 value 也设置为 null，这样 value 之前对应的实例也可以被回收。 使用场景简单使用先让我们看一个简单的例子：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class ThreadLocalSimpleDemo &#123; public static void main(String[] args) &#123; int threads = 3; InnerClass innerClass = new InnerClass(); for (int i = 1; i &lt;= threads; i++) &#123; new Thread(() -&gt; &#123; for (int j = 0; j &lt; 4; j++) &#123; innerClass.add(String.valueOf(j)); innerClass.print(); &#125; innerClass.set("hello world"); &#125;, "thread - " + i).start(); &#125; &#125; private static class InnerClass &#123; /** * 添加 */ public void add(String newStr) &#123; StringBuilder str = Counter.counter.get(); Counter.counter.set(str.append(newStr)); &#125; /** * 打印 */ public void print() &#123; System.out.printf( "Thread name:%s , ThreadLocal hashcode:%s, Instance hashcode:%s, Value:%s\n", Thread.currentThread().getName(), Counter.counter.hashCode(), Counter.counter.get().hashCode(), Counter.counter.get().toString() ); &#125; /** * 赋值 */ public void set(String words) &#123; Counter.counter.set(new StringBuilder(words)); System.out.printf( "Set, Thread name:%s , ThreadLocal hashcode:%s, Instance hashcode:%s, Value:%s\n", Thread.currentThread().getName(), Counter.counter.hashCode(), Counter.counter.get().hashCode(), Counter.counter.get().toString() ); &#125; &#125; private static class Counter &#123; /** * 初始化时是一个空的StringBuilder对象 */ private static ThreadLocal&lt;StringBuilder&gt; counter = ThreadLocal.withInitial(StringBuilder::new); &#125;&#125; 其打印结果为：123456789101112131415Thread name:thread - 3 , ThreadLocal hashcode:310471657, Instance hashcode:640658548, Value:0Thread name:thread - 2 , ThreadLocal hashcode:310471657, Instance hashcode:126253473, Value:0Thread name:thread - 2 , ThreadLocal hashcode:310471657, Instance hashcode:126253473, Value:01Thread name:thread - 2 , ThreadLocal hashcode:310471657, Instance hashcode:126253473, Value:012Thread name:thread - 2 , ThreadLocal hashcode:310471657, Instance hashcode:126253473, Value:0123Thread name:thread - 1 , ThreadLocal hashcode:310471657, Instance hashcode:829132711, Value:0Thread name:thread - 1 , ThreadLocal hashcode:310471657, Instance hashcode:829132711, Value:01Thread name:thread - 1 , ThreadLocal hashcode:310471657, Instance hashcode:829132711, Value:012Thread name:thread - 1 , ThreadLocal hashcode:310471657, Instance hashcode:829132711, Value:0123Set, Thread name:thread - 1 , ThreadLocal hashcode:310471657, Instance hashcode:820066274, Value:hello worldThread name:thread - 3 , ThreadLocal hashcode:310471657, Instance hashcode:640658548, Value:01Thread name:thread - 3 , ThreadLocal hashcode:310471657, Instance hashcode:640658548, Value:012Set, Thread name:thread - 2 , ThreadLocal hashcode:310471657, Instance hashcode:155293473, Value:hello worldThread name:thread - 3 , ThreadLocal hashcode:310471657, Instance hashcode:640658548, Value:0123Set, Thread name:thread - 3 , ThreadLocal hashcode:310471657, Instance hashcode:1804272849, Value:hello world 可以看出，我们在使用 ThreadLocal 时，用的是同一个对象，但各个线程对应的实例是不一样的。而在调用 set() 方法后，对应的实例会被替换。 Session对于 Java Web 应用而言，Session 保存了很多信息。很多时候需要通过 Session 获取信息，有些时候又需要修改 Session 的信息。一方面，需要保证每个线程有自己单独的 Session 实例。另一方面，由于很多地方都需要操作 Session，存在多方法共享 Session 的需求。使用 ThreadLocal 进行实现：123456789101112131415161718192021222324252627282930313233public class SessionHandler &#123; public static ThreadLocal&lt;Session&gt; session = ThreadLocal.&lt;Session&gt;withInitial(() -&gt; new Session()); @Data public static class Session &#123; private String id; private String user; private String status; &#125; public String getUser() &#123; return session.get().getUser(); &#125; public String getStatus() &#123; return session.get().getStatus(); &#125; public void setStatus(String status) &#123; session.get().setStatus(status); &#125; public static void main(String[] args) &#123; new Thread(() -&gt; &#123; SessionHandler handler = new SessionHandler(); handler.getStatus(); handler.getUser(); handler.setStatus("close"); handler.getStatus(); &#125;).start(); &#125;&#125; 总结ThreadLocal 使用起来虽然简单，但考虑到其设计确实很精巧，值得了解一下。 有兴趣的话可以访问我的博客或者关注我的公众号、头条号，说不定会有意外的惊喜。 https://death00.github.io/]]></content>
      <tags>
        <tag>Java</tag>
        <tag>ThreadLocal</tag>
        <tag>弱引用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 面试 - 四种引用类型]]></title>
    <url>%2F2019%2F10%2F22%2FJava%20%E9%9D%A2%E8%AF%95%20-%20%E5%9B%9B%E7%A7%8D%E5%BC%95%E7%94%A8%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[之前我们提到过 GC，但当 Java 中引用的对象越来越多，会导致内存空间不足，最终会产生错误 OutOfMemoryError，并让应用程序终止。那为什么 GC 在此时不能多收集一些对象呢？这就和今天说的引用类型有关了。 首先，从 JDK1.2 开始，对象的引用被划分为4种级别，从而使程序能更加灵活地控制对象的生命周期。这4种级别由高到低依次为：强引用、软引用、弱引用和虚引用。 强引用强引用(Strong Reference)是使用最普遍的引用。如果一个对象具有强引用，那么它永远不会被 GC。例如：1Object strongReference = new Object(); 当内存空间不足时，JVM 宁愿抛出OutOfMemoryError，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足的问题。 如果强引用对象不使用时，需要弱化从而可以被 GC，例如ArrayList中的clear()方法：12345678910111213/** * Removes all of the elements from this list. The list will * be empty after this call returns. */public void clear() &#123; modCount++; // clear to let GC do its work for (int i = 0; i &lt; size; i++) elementData[i] = null; size = 0;&#125; 显式地设置强引用对象为null，或让其超出对象的生命周期范围，则垃圾回收器认为该对象不存在引用，就会回收这个对象。具体什么时候收集这要取决于具体的垃圾回收器。 软引用如果一个对象只具有软引用(Soft Reference)，当内存空间充足时，垃圾回收器就不会回收它；如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。让我们来看一个例子具体了解一下：123String str = new String("abc");SoftReference&lt;String&gt; softReference = new SoftReference&lt;&gt;(str);String result = softReference.get(); 让我们来看一下get()：12345678public T get() &#123; T o = super.get(); // timestamp代表上一次软引用上一次被使用的时间(初始化、get()) // clock代表上一次GC的时间 if (o != null &amp;&amp; this.timestamp != clock) this.timestamp = clock; return o;&#125; 因此，软引用在被垃圾回收时，也遵循LRU法则，优先回收最近最少被使用的对象进行回收。 软引用的使用场景多是内存敏感的高速缓存。具体来说，就是我们希望将数据存放到缓存中，这样可以快速进行读取。但是，当 JVM 中内存不够用时，我们又不希望缓存数据会占用到 JVM 的内存。例如配合ReferenceQueue，如果软引用所引用对象被垃圾回收，JVM 就会把这个软引用加入到与之关联的引用队列中：123456789101112ReferenceQueue&lt;String&gt; referenceQueue = new ReferenceQueue&lt;&gt;();String str = new String("abc");SoftReference&lt;String&gt; softReference = new SoftReference&lt;&gt;(str, referenceQueue);str = null;// Notify GCSystem.gc();System.out.println(softReference.get()); // abcReference&lt;? extends String&gt; reference = referenceQueue.poll();System.out.println(reference); //null 但是需要注意的时，如果使用软引用缓存，有可能导致Full GC增多。 弱引用如果一个对象只具有弱引用(Weak Reference)，其生命周期相比于软引用更加短暂。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会对它进行回收。不过，由于垃圾回收器是一个优先级很低的线程，因此不一定会很快发现那些只具有弱引用的对象。其使用为：123String str = new String("abc");WeakReference&lt;String&gt; weakReference = new WeakReference&lt;&gt;(str);str = weakReference.get(); 讲到弱引用，就不得不提到WeakHashMap。和HashMap相比，当我们给 JVM 分配的内存不足的时候，HashMap 宁可抛出 OutOfMemoryError 异常，也不会回收其相应的没有被引用的对象，而 WeakHashMap 则会回收存储在其中但有被引用的对象。 WeakHashMap 通过将一些没有被引用的键的值赋值为 null ，这样的话就会告知GC去回收这些存储的值了。假如我们特地传入 key 为 null 的键，WeakHashMap 会将键设置为特殊的 Oject，源码为：123456789101112131415161718192021222324252627282930313233343536public V put(K key, V value) &#123; // key会被重新赋值 Object k = maskNull(key); int h = hash(k); Entry&lt;K,V&gt;[] tab = getTable(); int i = indexFor(h, tab.length); for (Entry&lt;K,V&gt; e = tab[i]; e != null; e = e.next) &#123; if (h == e.hash &amp;&amp; eq(k, e.get())) &#123; V oldValue = e.value; if (value != oldValue) e.value = value; return oldValue; &#125; &#125; modCount++; Entry&lt;K,V&gt; e = tab[i]; tab[i] = new Entry&lt;&gt;(k, value, queue, h, e); if (++size &gt;= threshold) resize(tab.length * 2); return null;&#125;/** * Value representing null keys inside tables. * 特殊的key */private static final Object NULL_KEY = new Object();/** * Use NULL_KEY for key if it is null. */private static Object maskNull(Object key) &#123; return (key == null) ? NULL_KEY : key;&#125; 虚引用虚引用(PhantomReference),顾名思义，就是形同虚设。与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。 虚引用主要用来跟踪对象被垃圾回收器回收的活动。 虚引用与软引用和弱引用的一个区别在于： 虚引用必须和引用队列(ReferenceQueue)联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。 例如：1234String str = new String("abc");ReferenceQueue queue = new ReferenceQueue();// 创建虚引用，要求必须与一个引用队列关联PhantomReference pr = new PhantomReference(str, queue); 程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要进行垃圾回收。如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动，也可以理解为一种回调方法。 总结Java 中4种引用的级别和强度由高到低依次为：强引用 -&gt; 软引用 -&gt; 弱引用 -&gt; 虚引用 通过表格，说明其特性： 引用类型 被垃圾回收的时间 使用场景 生存时间 强引用 从来不会 对象的一般状态 JVM停止运行时 软引用 内存不足时 对象缓存 内存不足时 弱引用 正常垃圾回收时 对象缓存 垃圾回收后终止 虚引用 正常垃圾回收时 跟踪对象的垃圾回收 垃圾回收后终止 有兴趣的话可以访问我的博客或者关注我的公众号、头条号，说不定会有意外的惊喜。 https://death00.github.io/]]></content>
      <tags>
        <tag>Java</tag>
        <tag>弱引用</tag>
        <tag>强引用</tag>
        <tag>软引用</tag>
        <tag>虚引用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 面试 - 垃圾回收（下）]]></title>
    <url>%2F2019%2F10%2F21%2FJava%20%E9%9D%A2%E8%AF%95%20-%20%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%EF%BC%88%E4%B8%8B%EF%BC%89%2F</url>
    <content type="text"><![CDATA[接着上一篇，介绍完了 JVM 中识别需要回收的垃圾对象之后，这一篇我们来说说 JVM 是如何进行垃圾回收。 首先要在这里介绍一下80/20 法则: 约仅有20%的变因操纵着80%的局面。也就是说：所有变量中，最重要的仅有20%，虽然剩余的80%占了多数，控制的范围却远低于“关键的少数”。 Java 对象的生命周期也满足也这样的定律，即大部分的 Java 对象只存活一小段时间，而存活下来的小部分 Java 对象则会存活很长一段时间。 因此，这也就造就了 JVM 中分代回收的思想。简单来说，就是将堆空间划分为两代，分别叫做新生代和老年代。新生代用来存储新建的对象。当对象存活时间够长时，则将其移动到老年代。 这样也就可以让 JVM 给不同代使用不同的回收算法。 对于新生代，我们猜测大部分的 Java 对象只存活一小段时间，那么便可以频繁地采用耗时较短的垃圾回收算法，让大部分的垃圾都能够在新生代被回收掉。 对于老年代，我们猜测大部分的垃圾已经在新生代中被回收了，而在老年代中的对象有大概率会继续存活。当真正触发针对老年代的回收时，则代表这个假设出错了，或者堆的空间已经耗尽了。此时，JVM 往往需要做一次全堆扫描，耗时也将不计成本。（当然，现代的垃圾回收器都在并发收集的道路上发展，来避免这种全堆扫描的情况。） 那么，我们先来看看 JVM 中堆究竟是如何划分的。 堆划分按照上文所述，JVM 将堆划分为新生代和老年代，其中，新生代又被划分为 Eden 区，以及两个大小相同的 Survivor 区。 通常来说，当我们调用 new 指令时，它会在 Eden 区中划出一块作为存储对象的内存。由于堆空间是线程共享的，因此直接在这里边划空间是需要进行同步的。否则，将有可能出现两个对象共用一段内存的事故。 JVM 的解决方法是为每个线程预先申请一段连续的堆空间，并且只允许每个线程在自己申请过的堆空间中创建对象，如果申请的堆空间被用完了，那么再继续申请即可，这也就是 TLAB（Thread Local Allocation Buffer，对应虚拟机参数 -XX:+UseTLAB，默认开启）。 此时，如果线程操作涉及到加锁，则该线程需要维护两个指针（实际上可能更多，但重要也就两个），一个指向 TLAB 中空余内存的起始位置，一个则指向 TLAB 末尾。 接下来的 new 指令，便可以直接通过指针加法（bump the pointer）来实现，即把指向空余内存位置的指针加上所请求的字节数。 如果加法后空余内存指针的值仍小于或等于指向末尾的指针，则代表分配成功。否则，TLAB 已经没有足够的空间来满足本次新建操作。这个时候，便需要当前线程重新申请新的 TLAB。 那有没有可能出现申请不到的情况呢？有的，这个时候就会触发Minor GC了。 Minor GC所谓 Minor GC，就是指： 当 Eden 区的空间耗尽时，JVM 会进行一次 Minor GC，来收集新生代的垃圾。存活下来的对象，则会被送到 Survivor 区。 上文提到，新生代共有两个 Survivor 区，我们分别用 from 和 to 来指代。其中 to 指向的 Survivior 区是空的。 当发生 Minor GC 时，Eden 区和 from 指向的 Survivor 区中的存活对象会被复制到 to 指向的 Survivor 区中，然后交换 from 和 to 指针，以保证下一次 Minor GC 时，to 指向的 Survivor 区还是空的。 JVM 会记录 Survivor 区中每个对象一共被来回复制了几次。如果一个对象被复制的次数为 15（对应虚拟机参数 -XX:+MaxTenuringThreshold），那么该对象将被晋升（promote）至老年代。 另外，如果单个 Survivor 区已经被占用了 50%（对应虚拟机参数 -XX:TargetSurvivorRatio），那么较高复制次数的对象也会被晋升至老年代。 总而言之，当发生 Minor GC 时，我们应用了标记 - 复制算法，将 Survivor 区中的老存活对象晋升到老年代，然后将剩下的存活对象和 Eden 区的存活对象复制到另一个 Survivor 区中。理想情况下，Eden 区中的对象基本都死亡了，那么需要复制的数据将非常少，因此采用这种标记 - 复制算法的效果极好。 Minor GC 的另外一个好处是不用对整个堆进行垃圾回收。但是，它却有一个问题，那就是老年代中的对象可能引用新生代的对象。也就是说，在标记存活对象的时候，我们需要扫描老年代中的对象。如果该对象拥有对新生代对象的引用，那么这个引用也会被作为 GC Roots。这样一来，岂不是又做了一次全堆扫描呢？ 为了避免扫描全堆，JVM 引入了名为卡表的技术，大致地标出可能存在老年代到新生代引用的内存区域。有兴趣的朋友可以去详细了解一下，这里限于篇幅，就不具体介绍了。 Full GC那什么时候会发生Full GC呢？针对不同的垃圾收集器，Full GC 的触发条件可能不都一样。按 HotSpot VM 的 serial GC 的实现来看，触发条件是: 当准备要触发一次 Minor GC 时，如果发现统计数据说之前 Minor GC 的平均晋升大小比目前老年代剩余的空间大，则不会触发 Minor GC 而是转为触发 Full GC。 因为 HotSpot VM 的 GC 里，除了垃圾回收器 CMS 能单独收集老年代之外，其他的 GC 都会同时收集整个堆，所以不需要事先准备一次单独的 Minor GC。 垃圾回收基础的回收方式有三种：清除、压缩、复制，接下来让我们来一一了解一下。 清除所谓清除，就是把死亡对象所占据的内存标记为空闲内存，并记录在一个空闲列表之中。当需要新建对象时，内存管理模块便会从该空闲列表中寻找空闲内存，并划分给新建的对象。 其原理十分简单，但是有两个缺点： 会造成内存碎片。由于 JVM 的堆中对象必须是连续分布的，因此可能出现总空闲内存足够，但是无法分配的极端情况。 分配效率较低。如果是一块连续的内存空间，那么我们可以通过指针加法（pointer bumping）来做分配。而对于空闲列表，JVM 则需要逐个访问空闲列表中的项，来查找能够放入新建对象的空闲内存。 压缩所谓压缩，就是把存活的对象聚集到内存区域的起始位置，从而留下一段连续的内存空间。 这种做法能够解决内存碎片化的问题，但代价是压缩算法的性能开销，因此分配效率问题依旧没有解决。 复制所谓复制，就是把内存区域平均分为两块，分别用两个指针 from 和 to 来维护，并且只是用 from 指针指向的内存区域来分配内存。当发生垃圾回收时，便把存活的对象复制到 to 指针所指向的内存区域中，并且交换 from 指针和 to 指针的内容。 这种回收方式同样能够解决内存碎片化的问题，但是它的缺点也极其明显，即堆空间的使用效率极其低下。 具体垃圾收集器针对新生代的垃圾回收器共有三个：Serial ，Parallel Scavenge 和 Parallel New。这三个采用的都是标记 - 复制算法。 其中，Serial 是一个单线程的，Parallel New 可以看成是 Serial 的多线程版本，Parallel Scavenge 和 Parallel New 类似，但更加注重吞吐率。此外，Parallel Scavenge 不能与 CMS 一起使用。 针对老年代的垃圾回收器也有三个：Serial Old ，Parallel Old 和 CMS。 Serial Old 和 Parallel Old 都是标记 - 压缩算法。同样，前者是单线程的，而后者可以看成前者的多线程版本。 CMS 采用的是标记 - 清除算法，并且是并发的。除了少数几个操作需要 STW(Stop the world) 之外，它可以在应用程序运行过程中进行垃圾回收。在并发收集失败的情况下，JVM 会使用其他两个压缩型垃圾回收器进行一次垃圾回收。由于 G1 的出现，CMS 在 Java 9 中已被废弃。 G1（Garbage First）是一个横跨新生代和老年代的垃圾回收器。实际上，它已经打乱了前面所说的堆结构，直接将堆分成极其多个区域。每个区域都可以充当 Eden 区、Survivor 区或者老年代中的一个。它采用的是标记 - 压缩算法，而且和 CMS 一样都能够在应用程序运行过程中并发地进行垃圾回收。 G1 能够针对每个细分的区域来进行垃圾回收。在选择进行垃圾回收的区域时，它会优先回收死亡对象较多的区域。这也是 G1 名字的由来。 总结这篇文章主要讲述的是 JVM 中具体的垃圾回收方法，从对象的生存规律，引出回收方法，结合多线程的特点，逐步优化，最终产生了我们现在所能知道各种垃圾收集器。 有兴趣的话可以访问我的博客或者关注我的公众号、头条号，说不定会有意外的惊喜。 https://death00.github.io/]]></content>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
        <tag>GC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 面试 - 垃圾回收（上）]]></title>
    <url>%2F2019%2F10%2F20%2FJava%20%E9%9D%A2%E8%AF%95%20-%20%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%EF%BC%88%E4%B8%8A%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Java 中的垃圾回收，常常是由 JVM 帮我们做好的。虽然这节省了大家很多的学习的成本，提高了项目的执行效率，但是当项目变得越来越复杂，用户量越来越大时，还是需要我们懂得垃圾回收机制，这样也能进行更深一步的优化。 辨别对象存亡垃圾回收( Garbage Collection，以下简称 GC )，从字面上理解，就是将已经分配出去的，但却不再使用的内存回收回来，以便能够再次分配。 在 JVM 中，垃圾就是指的死亡对象所占据的堆空间( GC 是发生在堆空间中)，那么我们如果辨别一个对象是否死亡呢？JVM 使用的是引用计数法和可达性分析。 引用计数法引用计数法( Reference Counting)，是为每个对象添加一个引用计数器，用来统计引用该对象的个数。一旦某个对象的引用计数器为0，则说明该对象已经死亡，便可以被回收了。 其具体实现为： 如果有一个引用，被赋值为某一对象，那么将该对象的引用计数器 +1。 如果一个指向某一对象的引用，被赋值为其他值，那么将该对象的引用计数器 -1。 也就是说，我们需要截获所有的引用更新操作，并且相应地增减目标对象的引用计数器。 看似很简单的实现，其实里面有不少缺陷： 需要额外的空间来存储计数器。 计数器的更新操作十分繁琐。 最重要的：无法处理循环引用对象。 针对第3点，举个例子特别说明一下： 假设对象 a 与 b 相互引用，除此之外没有其他引用指向他们。在这种情况下，a 和 b 实际上已经死了。 但由于它们的引用计数器皆不为0（因为相互引用，两者均为1），在引用计数法的计算中，这两个对象还活着。因此，这些循环引用对象所占据的空间将不可回收，从而造成了内存泄露。 可达性分析可达性分析( Reachability Analysis )，是目前 JVM 主要采取的判定对象死亡的方法。实质在于将一系列GC Roots作为初始的存活对象合集（live set），然后从该合集出发，探索所有能够被该集合引用到的对象，并将其加入到该集合中，这个过程我们也称之为标记（mark）。最终，未被探索到的对象便是死亡的，是可以回收的。 那么什么是GC Roots呢？我们可以暂时理解为由堆外指向堆内的引用，一般而言，GC Roots 包括（但不限于）如下几种： Java 方法栈桢中的局部变量 已加载类的静态变量 JNI handles 已启动且未停止的 Java 线程 之前我们说引用计数法会有循环引用的问题，可达性分析就不会了。举例来说，即便对象 a 和 b 相互引用，只要从 GC Roots 出发无法到达 a 或者 b，那么可达性分析便会认为它们已经死亡。 那可达性分析有没有什么缺点呢？有的，在多线程环境下，其他线程可能会更新已经分析过的对象中的引用，从而造成误报（将引用设置为 null）或者漏报（将引用设置为未被访问过的对象）。 误报并没有什么伤害，JVM 至多损失了部分垃圾回收的机会。漏报则比较麻烦，因为垃圾回收器可能回收事实上仍被引用的对象内存。一旦从原引用访问已经被回收了的对象，则很有可能会直接导致 JVM 崩溃。 STW既然可达性分析在多线程下有缺点，那 JVM 是如何解决的呢？答案便是 Stop-the-world(以下简称JWT)，停止了其他非垃圾回收线程的工作直到完成垃圾回收。这也就造成了垃圾回收所谓的暂停时间（GC pause）。 那 SWT 是如何实现的呢？当 JVM 收到 SWT 请求后，它会等待所有的线程都到达安全点（Safe Point），才允许请求 SWT 的线程进行独占的工作。 那什么又叫安全点呢？安全点是 JVM 能找到一个稳定的执行状态，在这个执行状态下，JVM 的堆栈不会发生变化。 这么一来，垃圾回收器便能够“安全”地执行可达性分析，所有存活的对象也都可以成功被标记，那么之后就可以将死亡的对象进行垃圾回收了。 总结以上便是发现死亡对象的过程，这也为之后的垃圾回收进行铺垫，具体的垃圾回收过程，我会在下一篇文章中讲述，敬请期待。 有兴趣的话可以访问我的博客或者关注我的公众号、头条号，说不定会有意外的惊喜。 https://death00.github.io/]]></content>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
        <tag>GC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 面试-即时编译( JIT )]]></title>
    <url>%2F2019%2F10%2F14%2FJava%20%E9%9D%A2%E8%AF%95-%E5%8D%B3%E6%97%B6%E7%BC%96%E8%AF%91(%20JIT%20)%20%2F</url>
    <content type="text"><![CDATA[当我们在写代码时，一个方法内部的行数自然是越少越好，这样逻辑清晰、方便阅读，其实好处远不止如此，通过即时编译，甚至可以提高执行时的性能，今天就让我们好好来了解一下其中的原理。 简介当 JVM 的初始化完成后，类在调用执行过程中，执行引擎会把字节码转为机器码，然后在操作系统中才能执行。在字节码转换为机器码的过程中，虚拟机中还存在着一道编译，那就是即时编译。 最初，JVM 中的字节码是由解释器（ Interpreter ）完成编译的，当虚拟机发现某个方法或代码块的运行特别频繁的时候，就会把这些代码认定为热点代码。 为了提高热点代码的执行效率，在运行时，即时编译器（JIT，Just In Time）会把这些代码编译成与本地平台相关的机器码，并进行各层次的优化，然后保存到内存中。 分类在 HotSpot 虚拟机中，内置了两种 JIT，分别为C1 编译器和C2 编译器，这两个编译器的编译过程是不一样的。 C1 编译器C1 编译器是一个简单快速的编译器，主要的关注点在于局部性的优化，适用于执行时间较短或对启动性能有要求的程序，也称为Client Compiler，例如，GUI 应用对界面启动速度就有一定要求。 C2 编译器C2 编译器是为长期运行的服务器端应用程序做性能调优的编译器，适用于执行时间较长或对峰值性能有要求的程序，也称为Server Compiler，例如，服务器上长期运行的 Java 应用对稳定运行就有一定的要求。 分层编译在 Java7 之前，需要根据程序的特性来选择对应的 JIT，虚拟机默认采用解释器和其中一个编译器配合工作。 Java7 引入了分层编译，这种方式综合了 C1 的启动性能优势和 C2 的峰值性能优势，我们也可以通过参数 -client或者-server 强制指定虚拟机的即时编译模式。 分层编译将 JVM 的执行状态分为了 5 个层次： 第 0 层：程序解释执行，默认开启性能监控功能（Profiling），如果不开启，可触发第二层编译； 第 1 层：可称为 C1 编译，将字节码编译为本地代码，进行简单、可靠的优化，不开启 Profiling； 第 2 层：也称为 C1 编译，开启 Profiling，仅执行带方法调用次数和循环回边执行次数 profiling 的 C1 编译； 第 3 层：也称为 C1 编译，执行所有带 Profiling 的 C1 编译； 第 4 层：可称为 C2 编译，也是将字节码编译为本地代码，但是会启用一些编译耗时较长的优化，甚至会根据性能监控信息进行一些不可靠的激进优化。 对于 C1 的三种状态，按执行效率从高至低：第 1 层、第 2层、第 3层。 通常情况下，C2 的执行效率比 C1 高出30%以上。 在 Java8 中，默认开启分层编译，-client 和 -server 的设置已经是无效的了。如果只想开启 C2，可以关闭分层编译（-XX:-TieredCompilation），如果只想用 C1，可以在打开分层编译的同时，使用参数：-XX:TieredStopAtLevel=1。 你可以通过 java -version命令行可以直接查看到当前系统使用的编译模式：1234C:\Users\Administrator&gt;java -versionjava version &quot;1.8.0_45&quot;Java(TM) SE Runtime Environment (build 1.8.0_45-b14)Java HotSpot(TM) 64-Bit Server VM (build 25.45-b02, mixed mode) mixed mode代表是默认的混合编译模式，除了这种模式外，我们还可以使用-Xint参数强制虚拟机运行于只有解释器的编译模式下，这时 JIT 完全不介入工作；也可以使用参数-Xcomp强制虚拟机运行于只有 JIT 的编译模式下。例如：123456789C:\Users\Administrator&gt;java -Xint -versionjava version &quot;1.8.0_45&quot;Java(TM) SE Runtime Environment (build 1.8.0_45-b14)Java HotSpot(TM) 64-Bit Server VM (build 25.45-b02, interpreted mode)C:\Users\Administrator&gt;java -Xcomp -versionjava version &quot;1.8.0_45&quot;Java(TM) SE Runtime Environment (build 1.8.0_45-b14)Java HotSpot(TM) 64-Bit Server VM (build 25.45-b02, compiled mode) 触发标准在 HotSpot 虚拟机中，热点探测是 JIT 的触发标准。 热点探测是基于计数器的热点探测，采用这种方法的虚拟机会为每个方法建立计数器统计方法的执行次数，如果执行次数超过一定的阈值就认为它是“热点方法” 。 虚拟机为每个方法准备了两类计数器：方法调用计数器（Invocation Counter）和回边计数器（Back Edge Counter）。在确定虚拟机运行参数的前提下，这两个计数器都有一个确定的阈值，当计数器超过阈值溢出了，就会触发 JIT 编译。 方法调用计数器方法调用计数器用于统计方法被调用的次数，默认阈值在 C1 模式下是 1500 次，在 C2 模式在是 10000 次，可通过-XX: CompileThreshold来设定；而在分层编译的情况下-XX: CompileThreshold指定的阈值将失效，此时将会根据当前待编译的方法数以及编译线程数来动态调整。当方法计数器和回边计数器之和超过方法计数器阈值时，就会触发 JIT 编译器。 回边计数器回边计数器用于统计一个方法中循环体代码执行的次数，在字节码中遇到控制流向后跳转的指令称为“回边”（Back Edge），该值用于计算是否触发 C1 编译的阈值，在不开启分层编译的情况下，C1 默认为 13995，C2 默认为 10700，可通过-XX: OnStackReplacePercentage=N来设置；而在分层编译的情况下，-XX: OnStackReplacePercentage指定的阈值同样会失效，此时将根据当前待编译的方法数以及编译线程数来动态调整。 建立回边计数器的主要目的是为了触发 OSR（On StackReplacement）编译，即栈上编译。在一些循环周期比较长的代码段中，当循环达到回边计数器阈值时，JVM 会认为这段是热点代码，JIT 编译器就会将这段代码编译成机器语言并缓存，在该循环时间段内，会直接将执行代码替换，执行缓存的机器语言。 优化技术JIT 编译运用了一些经典的编译优化技术来实现代码的优化，即通过一些例行检查优化，可以智能地编译出运行时的最优性能代码。主要有两种：方法内联、逃逸分析。 方法内联调用一个方法通常要经历压栈和出栈。调用方法是将程序执行顺序转移到存储该方法的内存地址，将方法的内容执行完后，再返回到执行该方法前的位置。 这种执行操作要求在执行前保护现场并记忆执行的地址，执行后要恢复现场，并按原来保存的地址继续执行。 因此，方法调用会产生一定的时间和空间方面的开销（其实可以理解为一种上下文切换的精简版）。 那么对于那些方法体代码不是很大，又频繁调用的方法来说，这个时间和空间的消耗会很大。 方法内联的优化行为就是把目标方法的代码复制到发起调用的方法之中，避免发生真实的方法调用。 JVM 会自动识别热点方法，并对它们使用方法内联进行优化。我们可以通过-XX:CompileThreshold来设置热点方法的阈值。但要强调一点，热点方法不一定会被 JVM 做内联优化，如果这个方法体太大了，JVM 将不执行内联操作。而方法体的大小阈值，我们也可以通过参数设置来优化： 经常执行的方法，默认情况下，方法体大小小于 325 字节的都会进行内联，我们可以通过-XX:MaxFreqInlineSize=N来设置大小值； 不是经常执行的方法，默认情况下，方法大小小于 35 字节才会进行内联，我们也可以通过-XX:MaxInlineSize=N来重置大小值。 之后我们就可以通过配置 JVM 参数来查看到方法被内联的情况：123456// 在控制台打印编译过程信息-XX:+PrintCompilation// 解锁对 JVM 进行诊断的选项参数。默认是关闭的，开启后支持一些特定参数对 JVM 进行诊断-XX:+UnlockDiagnosticVMOptions// 将内联方法打印出来-XX:+PrintInlining 热点方法的优化可以有效提高系统性能，一般我们可以通过以下几种方式来提高方法内联： 通过设置 JVM 参数来减小热点阈值或增加方法体阈值，以便更多的方法可以进行内联，但这种方法意味着需要占用更多地内存； 在编程中，避免在一个方法中写大量代码，习惯使用小方法体； 尽量使用 final、private、static 关键字修饰方法，编码方法因为继承，会需要额外的类型检查。 此处就联系到了最开始提出的观点，一个方法中的内容越少，当该方法经常被执行时，则容易进行方法内联，从而优化性能。 逃逸分析逃逸分析（Escape Analysis）是判断一个对象是否被外部方法引用或外部线程访问的分析技术，编译器会根据逃逸分析的结果对代码进行优化。 可以通过JVM参数进行设置：12-XX:+DoEscapeAnalysis 开启逃逸分析（jdk1.8 默认开启）-XX:-DoEscapeAnalysis 关闭逃逸分析 其具体优化方法主要有三种：栈上分配、锁消除、标量替换。 栈上分配在 Java 中默认创建一个对象是在堆中分配内存的，而当堆内存中的对象不再使用时，则需要通过垃圾回收机制回收，这个过程相对分配在栈中的对象的创建和销毁来说，更消耗时间和性能。 这个时候，逃逸分析如果发现一个对象只在方法中使用，就会将对象分配在栈上。 但是，HotSpot 虚拟机目前的实现导致栈上分配实现比较复杂，可以说，在 HotSpot 中暂时没有实现这项优化，所以大家可能暂时无法体会到这种优化（我看的资料显示在 Java8 中还没有实现，如果大家有什么其他的发现，欢迎留言）。 锁消除如果是在单线程环境下，其实完全没有必要使用线程安全的容器，但就算使用了，因为不会有线程竞争，这个时候 JIT 编译会对这个对象的方法锁进行锁消除。例如： 123456public static String getString(String s1, String s2) &#123; StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); return sb.toString(); &#125; 可以通过JVM参数进行设置：12-XX:+EliminateLocks 开启锁消除（jdk1.8 默认开启）-XX:-EliminateLocks 关闭锁消除 标量替换逃逸分析证明一个对象不会被外部访问，如果这个对象可以被拆分的话，当程序真正执行的时候可能不创建这个对象，而直接创建它的成员变量来代替。将对象拆分后，可以分配对象的成员变量在栈或寄存器上，原本的对象就无需分配内存空间了。这种编译优化就叫做标量替换。 例如：123456public void foo() &#123; TestInfo info = new TestInfo(); info.id = 1; info.count = 99; // to do something&#125; 逃逸分析后，代码会被优化为：12345public void foo() &#123; id = 1; count = 99; // to do something&#125; 可以通过JVM参数进行设置：12-XX:+EliminateAllocations 开启标量替换（jdk1.8 默认开启）-XX:-EliminateAllocations 关闭就可以了 总结今天的内容，由最基本的常识方法内部行数和逻辑需要尽可能简单引出，了解了 JVM 通过即时编译对热点代码进行优化的过程。如果你有什么想法，欢迎在下方留言。 有兴趣的话可以访问我的博客或者关注我的公众号、头条号，说不定会有意外的惊喜。 https://death00.github.io/]]></content>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java面试- JVM 内存模型讲解]]></title>
    <url>%2F2019%2F10%2F11%2FJava%E9%9D%A2%E8%AF%95-JVM%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E8%AE%B2%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[经常有人会有这么一个疑惑，难道 Java 开发就一定要懂得 JVM 的原理吗？我不懂 JVM ，但我照样可以开发。确实，但如果懂得了 JVM ，可以让你在技术的这条路上走的更远一些。 JVM 的重要性首先你应该知道，运行一个 Java 应用程序，我们必须要先安装 JDK 或者 JRE 。这是因为 Java 应用在编译后会变成字节码，然后通过字节码运行在 JVM 中，而 JVM 是 JRE 的核心组成部分。 优点JVM 不仅承担了 Java 字节码的分析（JIT compiler）和执行（Runtime），同时也内置了自动内存分配管理机制。这个机制可以大大降低手动分配回收机制可能带来的内存泄露和内存溢出风险，使 Java 开发人员不需要关注每个对象的内存分配以及回收，从而更专注于业务本身。 缺点这个机制在提升 Java 开发效率的同时，也容易使 Java 开发人员过度依赖于自动化，弱化对内存的管理能力，这样系统就很容易发生 JVM 的堆内存异常、垃圾回收（GC）的不合适以及 GC 次数过于频繁等问题，这些都将直接影响到应用服务的性能。 内存模型JVM 内存模型共分为5个区：堆(Heap)、方法区(Method Area)、程序计数器(Program Counter Register)、虚拟机栈(VM Stack)、本地方法栈(Native Method Stack)。 其中，堆(Heap)、方法区(Method Area)为线程共享，程序计数器(Program Counter Register)、虚拟机栈(VM Stack)、本地方法栈(Native Method Stack)为线程隔离。 堆(Heap)堆是 JVM 内存中最大的一块内存空间，该内存被所有线程共享，几乎所有对象和数组都被分配到了堆内存中。 堆被划分为新生代和老年代，新生代又被进一步划分为 Eden 区和 Survivor 区，最后 Survivor 由 From Survivor 和 To Survivor 组成。 随着 Java 版本的更新，其内容又有了一些新的变化： 在 Java6 版本中，永久代在非堆内存区；到了 Java7 版本，永久代的静态变量和运行时常量池被合并到了堆中；而到了 Java8，永久代被元空间(处于本地内存)取代了。 为什么要用元空间替换永久代呢？ 为了融合 HotSpot JVM 与 JRockit VM，因为 JRockit 没有永久代，所以不需要配置永久代。 永久代内存经常不够用或发生内存溢出（应该是 JVM 中占用内存最大的一块），产生异常 java.lang.OutOfMemoryError: PermGen。在 JDK1.7 版本中，指定的 PermGen 区大小为 8M，由于 PermGen 中类的元数据信息在每次 FullGC 的时候都可能被收集，回收率都偏低，成绩很难令人满意；还有，为 PermGen 分配多大的空间很难确定，PermSize 的大小依赖于很多因素，比如，JVM 加载的 class 总数、常量池的大小和方法的大小等。 看到这儿，自然就想到了 GC 回收算法，不用急，我会在之后的文章中进行讲解，现在还是以 JVM 内存模型为主。 方法区(Method Area)什么是方法区？ 方法区主要是用来存放已被虚拟机加载的类相关信息，包括类信息、常量池(字符串常量池以及所有基本类型都有其相应的常量池)、运行时常量池。这其中，类信息又包括了类的版本、字段、方法、接口和父类等信息。 类信息JVM 在执行某个类的时候，必须经过加载、连接、初始化，而连接又包括验证、准备、解析三个阶段。 在加载类的时候，JVM 会先加载 class 文件，而在 class 文件中便有类的版本、字段、方法和接口等描述信息，这就是类信息。 常量池在 class 文件中，除了类信息，还有一项信息是常量池 (Constant Pool Table)，用于存放编译期间生成的各种字面量和符号引用。 那字面量和符号引用又是什么呢？ 字面量包括字符串（String a=“b”）、基本类型的常量（final 修饰的变量），符号引用则包括类和方法的全限定名（例如 String 这个类，它的全限定名就是 Java/lang/String）、字段的名称和描述符以及方法的名称和描述符。 运行时常量池当类加载到内存后，JVM 就会将 class 文件常量池中的内容存放到运行时常量池中；在解析阶段，JVM 会把符号引用替换为直接引用（对象的索引值）。 例如： 类中的一个字符串常量在 class 文件中时，存放在 class 文件常量池中的。 在 JVM 加载完类之后，JVM 会将这个字符串常量放到运行时常量池中，并在解析阶段，指定该字符串对象的索引值。 运行时常量池是全局共享的，多个类共用一个运行时常量池，因此，class 文件中常量池多个相同的字符串在运行时常量池只会存在一份。 讲到这里，大家是不是有些头晕了，说实话，我在看到这些内容的时候，也是云里雾里的，这里举个例子帮助大家理解：123456789public static void main(String[] args) &#123; String str = "Hello"; System.out.println((str == ("Hel" + "lo"))); String loStr = "lo"; System.out.println((str == ("Hel" + loStr))); System.out.println(str == ("Hel" + loStr).intern());&#125; 其运行结果为：123truefalsetrue 第一个为 true，是因为在编译成 class 文件时，能够识别为同一字符串的, JVM 会将其自动优化成字符串常量,引用自同一 String 对象。 第二个为 false，是因为在运行时创建的字符串具有独立的内存地址,所以不引用自同一 String 对象。 最后一个为 true，是因为 String 的 intern() 方法会查找在常量池中是否存在一个相等(调用 equals() 方法结果相等)的字符串,如果有则返回该字符串的引用,如果没有则添加自己的字符串进入常量池。 涉及到的Error OutOfMemoryError出现在方法区无法满足内存分配需求的时候，比如一直往常量池中加入数据，运行时常量池就会溢出，从而报错。 程序计数器(Program Counter Register)程序计数器是一块很小的内存空间，主要用来记录各个线程执行的字节码的地址，例如，分支、循环、跳转、异常、线程恢复等都依赖于计数器。 由于 Java 是多线程语言，当执行的线程数量超过 CPU 数量时，线程之间会根据时间片轮询争夺 CPU 资源。如果一个线程的时间片用完了，或者是其它原因导致这个线程的 CPU 资源被提前抢夺，那么这个退出的线程就需要单独的一个程序计数器，来记录下一条运行的指令。 由此可见，程序计数器和上下文切换有关。 虚拟机栈(VM Stack) 虚拟机栈是线程私有的内存空间，它和 Java 线程一起创建。 当创建一个线程时，会在虚拟机栈中申请一个线程栈，用来保存方法的局部变量、操作数栈、动态链接方法和返回地址等信息，并参与方法的调用和返回。 每一个方法的调用都伴随着栈帧的入栈操作，方法的返回则是栈帧的出栈操作。 可以这么理解，虚拟机栈针对当前 Java 应用中所有线程，都有一个其相应的线程栈，每一个线程栈都互相独立、互不影响，里面存储了该线程中独有的信息。 涉及到的Error StackOverflowError出现在栈内存设置成固定值的时候，当程序执行需要的栈内存超过设定的固定值时会抛出这个错误。 OutOfMemoryError出现在栈内存设置成动态增长的时候，当JVM尝试申请的内存大小超过了其可用内存时会抛出这个错误。 本地方法栈(Native Method Stack) 本地方法栈跟虚拟机栈的功能类似，虚拟机栈用于管理 Java 方法的调用，而本地方法栈则用于管理本地方法的调用。 但本地方法并不是用 Java 实现的，而是由 C 语言实现的。 也就是说，本地方法栈中并没有我们写的代码逻辑，其由native修饰，由 C 语言实现。 总结以上就是 JVM 内存模型的基本介绍，大致了解了一下5个分区及其相应的含义和功能，由此可以继续延伸出 Java 内存模型、 GC 算法等等，我也会在之后的文章中进行讲解。如果你有什么想法，欢迎在下方留言。 有兴趣的话可以访问我的博客或者关注我的公众号、头条号，说不定会有意外的惊喜。 https://death00.github.io/]]></content>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lombok中关于@Data的使用]]></title>
    <url>%2F2019%2F10%2F10%2FLombok%E4%B8%AD%E5%85%B3%E4%BA%8E-Data%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[当你在使用 Lombok 的 @Data 注解时，其实会有一些坑需要关注，今天就让我们来见识一下。 Lombok先来简单介绍一下 Lombok ，其官方介绍如下： Project Lombok makes java a spicier language by adding ‘handlers’ that know how to build and compile simple, boilerplate-free, not-quite-java code. 大致意思是 Lombok 通过增加一些”处理程序”，可以让 Java 代码变得简洁、快速。 Lombok 提供了一系列的注解帮助我们简化代码，比如： 注解名称 功能 @Setter 自动添加类中所有属性相关的 set 方法 @Getter 自动添加类中所有属性相关的 get 方法 @Builder 使得该类可以通过 builder (建造者模式)构建对象 @RequiredArgsConstructor 生成一个该类的构造方法，禁止无参构造 @ToString 重写该类的toString()方法 @EqualsAndHashCode 重写该类的equals()和hashCode()方法 @Data 等价于上面的@Setter、@Getter、@RequiredArgsConstructor、@ToString、@EqualsAndHashCode 看起来似乎这些注解都很正常，并且对我们的代码也有一定的优化，那为什么说@Data注解存在坑呢？ @Data注解内部实现由上面的表格我们可以知道，@Data是包含了@EqualsAndHashCode的功能，那么它究竟是如何重写equals()和hashCode()方法的呢？ 我们定义一个类TestA：12345@Datapublic class TestA &#123; String oldName;&#125; 我们将其编译后的 class 文件进行反编译：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class TestA &#123; String oldName; public TestA() &#123; &#125; public String getOldName() &#123; return this.oldName; &#125; public void setOldName(String oldName) &#123; this.oldName = oldName; &#125; public boolean equals(Object o) &#123; // 判断是否是同一个对象 if (o == this) &#123; return true; &#125; // 判断是否是同一个类 else if (!(o instanceof TestA)) &#123; return false; &#125; else &#123; TestA other = (TestA) o; if (!other.canEqual(this)) &#123; return false; &#125; else &#123; // 比较类中的属性(注意这里，只比较了当前类中的属性) Object this$oldName = this.getOldName(); Object other$oldName = other.getOldName(); if (this$oldName == null) &#123; if (other$oldName != null) &#123; return false; &#125; &#125; else if (!this$oldName.equals(other$oldName)) &#123; return false; &#125; return true; &#125; &#125; &#125; protected boolean canEqual(Object other) &#123; return other instanceof TestA; &#125; public int hashCode() &#123; int PRIME = true; int result = 1; Object $oldName = this.getOldName(); int result = result * 59 + ($oldName == null ? 43 : $oldName.hashCode()); return result; &#125; public String toString() &#123; return "TestA(oldName=" + this.getOldName() + ")"; &#125;&#125; 针对其equals()方法，当它进行属性比较时，其实只比较了当前类中的属性。如果你不信的话，我们再来创建一个类TestB，它是TestA的子类：1234567@Datapublic class TestB extends TestA &#123; private String name; private int age;&#125; 我们将其编译后的 class 文件进行反编译：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class TestB extends TestA &#123; private String name; private int age; public TestB() &#123; &#125; public String getName() &#123; return this.name; &#125; public int getAge() &#123; return this.age; &#125; public void setName(String name) &#123; this.name = name; &#125; public void setAge(int age) &#123; this.age = age; &#125; public boolean equals(Object o) &#123; if (o == this) &#123; return true; &#125; else if (!(o instanceof TestB)) &#123; return false; &#125; else &#123; TestB other = (TestB)o; if (!other.canEqual(this)) &#123; return false; &#125; else &#123; // 注意这里，真的是只比较了当前类中的属性，并没有比较父类中的属性 Object this$name = this.getName(); Object other$name = other.getName(); if (this$name == null) &#123; if (other$name == null) &#123; return this.getAge() == other.getAge(); &#125; &#125; else if (this$name.equals(other$name)) &#123; return this.getAge() == other.getAge(); &#125; return false; &#125; &#125; &#125; protected boolean canEqual(Object other) &#123; return other instanceof TestB; &#125; public int hashCode() &#123; int PRIME = true; int result = 1; Object $name = this.getName(); int result = result * 59 + ($name == null ? 43 : $name.hashCode()); result = result * 59 + this.getAge(); return result; &#125; public String toString() &#123; return "TestB(name=" + this.getName() + ", age=" + this.getAge() + ")"; &#125;&#125; 按照代码的理解，如果两个子类对象，其子类中的属性相同、父类中的属性不同时，利用equals()方法时，依旧会认为这两个对象相同，测试一下：12345678910111213141516171819202122public static void main(String[] args) &#123; TestB t1 = new TestB(); TestB t2 = new TestB(); t1.setOldName("123"); t2.setOldName("12345"); String name = "1"; t1.name = name; t2.name = name; int age = 1; t1.age = age; t2.age = age; System.out.println(t1.equals(t2)); System.out.println(t2.equals(t1)); System.out.println(t1.hashCode()); System.out.println(t2.hashCode()); System.out.println(t1 == t2); System.out.println(Objects.equals(t1, t2));&#125; 结果为：123456truetrue63736373falsetrue 问题总结 对于父类是Object且使用了@EqualsAndHashCode(callSuper = true)注解的类，这个类由 Lombok 生成的equals()方法只有在两个对象是同一个对象时，才会返回 true ，否则总为 false ，无论它们的属性是否相同。 这个行为在大部分时间是不符合预期的，equals()失去了其意义。即使我们期望equals()是这样工作的，那么其余的属性比较代码便是累赘，会大幅度降低代码的分支覆盖率。 解决方法 用了@Data就不要有继承关系，类似 Kotlin 的做法。 自己重写equals()， Lombok 不会对显式重写的方法进行生成。 显式使用@EqualsAndHashCode(callSuper = true)， Lombok 会以显式指定的为准。 总结以上便是我在使用@Data时碰到的问题以及自己的一些思考，在现在的项目，我干脆不再使用该注解。如果你有什么想法，欢迎在下方留言。 有兴趣的话可以访问我的博客或者关注我的公众号、头条号，说不定会有意外的惊喜。 https://death00.github.io/]]></content>
      <tags>
        <tag>Java</tag>
        <tag>Lombok</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中Synchronized的优化原理]]></title>
    <url>%2F2019%2F10%2F02%2FJava%E4%B8%ADSynchronized%E7%9A%84%E4%BC%98%E5%8C%96%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[我们知道，从 JDK1.6 开始，Java 对 Synchronized 同步锁做了充分的优化，甚至在某些场景下，它的性能已经超越了 Lock 同步锁。那么就让我们来看看，它究竟是如何优化的。 原本的问题Synchronized是基于底层操作系统的 Mutex Lock 实现的，每次获取锁和释放锁的操作都会带来用户态和内核态的切换，从而增加系统性能开销。 因此，在锁竞争激烈的情况下，Synchronized同步锁在性能上就表现得非常糟糕，它也常被大家称为重量级锁。 到了 JDK1.5 版本，并发包中新增了 Lock 接口来实现锁功能，它提供了与 Synchronized 关键字类似的同步功能，只是在使用时需要显示获取锁和释放锁。 在单个线程重复申请锁的情况下，JDK1.5 版本的 Lock 性能要比 Synchronized 锁的性能好很多，也就是当时的 Synchronized 并不具备可重入锁的功能。 那么当时的 Synchronized 是怎么实现的？又为什么不具备可重入的功能呢？ Synchronized原理JVM 中的同步是基于进入和退出管程（Monitor）对象实现的。每个对象实例都会有一个 Monitor，Monitor 可以和对象一起创建、销毁。 当多个线程同时访问一段同步代码时，多个线程会先被存放在EntryList集合（也可称为阻塞队列）中，处于BLOCKED状态的线程，都会被加入到该列表。 接下来当线程获取到对象的 Monitor 时，Monitor 是依靠底层操作系统的 Mutex Lock 来实现互斥的，线程申请 Mutex 成功，则持有该 Mutex，其它线程将无法获取到该 Mutex。 如果线程调用 wait() 方法，就会释放当前持有的 Mutex，并且该线程会进入WaitSet集合（也可称为等待队列）中，等待下一次被唤醒。此时线程会处于WAITING或者TIMEDWAITING状态， 如果当前线程顺利执行完方法，也将释放 Mutex。 总的来说，就是同步锁在这种实现方式中，因 Monitor 是依赖于底层的操作系统实现，存在用户态与内核态之间的切换(可以理解为上下文切换)，所以增加了性能开销。 锁升级为了提升性能，JDK1.6 引入了偏向锁、轻量级锁、重量级锁概念，来减少锁竞争带来的上下文切换，而正是新增的Java对象头实现了锁升级功能。 所谓锁升级，就是指 Synchronized 同步锁初始为偏向锁，随着线程竞争越来越激烈，偏向锁升级到轻量级锁，最终升级到重量级锁。 偏向锁偏向锁主要用来优化同一线程多次申请同一个锁的竞争，也就是现在的Synchronized锁实际已经拥有了可重入锁的功能。 为什么要有偏向锁？因为在我们的应用中，可能大部分时间是同一个线程竞争锁资源（比如单线程操作一个线程安全的容器），如果这个线程每次都要获取锁和释放锁，那么就在不断的从内核态与用户态之间切换。 那么有了偏向锁，当一个线程再次访问这个同步代码或方法时，该线程只需去对象头中去判断一下是否当前线程是否持有该偏向锁就可以了。 一旦出现其它线程竞争锁资源时，偏向锁就会被撤销。偏向锁的撤销需要等待全局安全点(JVM的stop the world)，暂停持有该锁的线程，同时检查该线程是否还在执行该方法，如果是，则升级锁，反之则被其它线程抢占。 轻量级锁当有另外一个线程竞争获取这个锁时，由于该锁已经是偏向锁，当发现对象头中的线程 ID 不是自己的线程 ID，就会进行 CAS 操作获取锁，如果获取成功，直接替换对象头中的线程 ID 为自己的 ID，该锁会保持偏向锁状态；如果获取锁失败，代表当前锁有一定的竞争，偏向锁将升级为轻量级锁。 轻量级锁适用于线程交替执行同步块的场景，绝大部分的锁在整个同步周期内都不存在长时间的竞争。 轻量级锁也支持自旋，因此其他线程再次争抢时，如果CAS失败，将不再会进入阻塞状态，而是不断自旋。 之所以自旋更好，是因为之前说了，默认线程持有锁的时间都不会太长，如果线程被挂起阻塞可能代价会更高。 如果自旋锁重试之后抢锁依然失败，那么同步锁就会升级至重量级锁。 重量级锁在这个状态下，未抢到锁的线程都会进入 Monitor，之后会被阻塞在WaitSet集合中，也就变成了优化之前的Synchronized锁。 JVM参数优化偏向锁升级为轻量级锁时，会发生stop the world，如果系统常常是多线程竞争，那么禁止偏向锁也许是更好的选择，可以通过以下JVM参数进行优化： 1234// 关闭偏向锁（默认打开）-XX:-UseBiasedLocking// 设置重量级锁-XX:+UseHeavyMonitors 轻量级锁拥有自旋锁的功能，那么如果线程持有锁的时间很长，那么竞争的线程也会常常处于自旋状态，占用系统 CPU ，增加系统开销，那么此时关闭自旋锁的优化可以更好一些： 1-XX:-UseSpinning 总结以上便是 Java 中针对 Synchronized 锁的优化，也正是因为这个优化，ConcurrentHashMap 在 JDK1.8 之后，再次采用 Synchronized 锁。如果你有什么想法，欢迎在下方留言。 有兴趣的话可以访问我的博客或者关注我的公众号、头条号，说不定会有意外的惊喜。 https://death00.github.io/]]></content>
      <tags>
        <tag>Java</tag>
        <tag>Synchronized</tag>
        <tag>优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[升级@Scheduled-分布式定时任务]]></title>
    <url>%2F2019%2F09%2F30%2F%E5%8D%87%E7%BA%A7%40Scheduled-%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[最近我在对项目的定时任务服务升级，希望改造成分布式，原本是利用@Scheduled注解实现，然而它并不支持分布式，如果改成quartz或者Spring Cloud Task，感觉对于自己这个简单的项目也没有必要。因此，我准备手写一个简单的支持分布式定时调度任务的框架。 项目地址是https://github.com/death00/dis-schedule，欢迎大家star、提意见。 分析先分析了一下自己的项目，全都是用的cron表达式，因此执行时间点都是固定的，如果升级为分布式的话，肯定是希望在同一个时间点只有一个应用去执行定时调度。 场景就变成了： 多个应用在同一个时间都尝试去执行任务，但最终只有一个应用真正执行。 这样的话，立马就会让人联想到使用锁去解决，因为是多个应用，所以就是分布式锁。那么，场景又变了： 多个应用在同一个时间都尝试去获取分布式锁，只有一个应用能抢到这把锁，抢到锁的应用可以执行定时任务，其他应用则直接放弃，等待下一次执行时间。 抢锁的时机是每次定时任务执行之前，这又让我联想到了AOP，那么利用注解也就顺理成章了。 分布式锁既然谈到了分布式锁，那么就想一下，这把锁的名称构成是什么。因为定时任务都有自己专门的时间，如果仅仅采用时间的话，那么当有两个任务同时执行时，则就是在抢一把锁，这同样是不合理的。 所以，锁的名称由两部分组成：任务执行时间、任务名称。 实现实现方案其实已经很成熟了，可以利用Redis、数据库、Zookeeper等，Redis用的命令是setNx，数据库一般都是利用的唯一索引，Zookeeper这点我也不是很了解（如果有感兴趣的同学，欢迎在我的项目中添加）。 我的项目中实现了Redis、数据库两种方式，可以看类DisScheduleRedisServiceImpl、DisScheduleMongodbServiceImpl。 注解其次，我自定义了一个注解DisSchedule， 12345678910111213141516171819@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface DisSchedule &#123; /** * 定时调度任务的名称(默认是方法名) */ String name() default ""; /** * 任务的间隔时间 */ int duration(); /** * duration的时间单位(默认：分钟) */ DisScheduleUnit unit() default DisScheduleUnit.MINUTES;&#125; name代表此次定时调度任务的名称。 duration代表任务的间隔时间，配合unit。 unit是自定义的时间单位，有秒、分钟。 该注解需要配合@Scheduled共同使用，例如：12@DisSchedule(name = "testSchedule", duration = 1, unit = DisScheduleUnit.MINUTES)@Scheduled(cron = "0 0/1 * * * ?") 该cron表达式代表1分钟执行一次，且是在整数分钟开始的时候执行，因此@DisSchedule也需要设置为1分钟的时间。 切面接下来，我们只需要在Aspect中定义好切入点（有注解@DisSchedule的方法上），针对这些方法，需要使用Around(环绕增强)进行拦截，因为当抢不到锁的时候，就不允许执行。 具体可以参考类DisScheduleAspect。 总结以上就是我实现的简单的分布式定时任务，虽然简单，但应该可以满足你的基础需求，接下来，我会在这个之上，逐步增加功能（比如监测、失败后预警等）。如果你有什么想法，欢迎在下方留言。 有兴趣的话可以访问我的博客或者关注我的公众号、头条号，说不定会有意外的惊喜。 https://death00.github.io/]]></content>
      <tags>
        <tag>分布式</tag>
        <tag>Scheduled</tag>
        <tag>定时任务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx的负载均衡]]></title>
    <url>%2F2019%2F09%2F30%2FNginx%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F</url>
    <content type="text"><![CDATA[我们都知道，Nginx支持负载均衡，可以很方便的帮助我们进行水平扩容，然而它究竟是依据什么原则进行请求的分发，其中又有哪些负载均衡算法可供选择和配置，今天就让我们好好来了解一下。 负载均衡的定义什么叫负载均衡，我们可以参考一下图片中的这种情况： 当客户端发送请求时，会先到Nginx，然后Nginx会将请求分发到后台不同的服务器上。 如果后台的服务器群中有一个宕机了，那么Nginx会自动忽略这台服务器，不会将请求再次分发到这台服务器上。 如果有新加入的服务器，Nginx也会将请求分发到这台服务器上。 我所理解的负载均衡，就是： 能够将客户端的请求均匀地分发到后台各个应用服务器上，从而缓解服务器压力。 并且当服务器出现宕机或者扩容时，也能正常运行。 负载均衡的方法上面了解了什么是负载均衡，那么Nginx是怎么实现这个功能的呢？ upstream和server的使用Nginx中负责与上游交互的模块，统称为upstream模块。 而指定上游服务地址是通过upstream和server指令完成的，其关系为： 指定上游服务器的address时，其地址可以是域名、IP地址或者unix socket地址。 可以在域名或者IP地址后加端口，如果不加端口，那么默认使用80端口。 在address后面可以添加一些参数，比如： backup：指定当前server为备份服务，仅当非备份server不可用时，请求才会转发到该server。 down：标识某台服务已经下线，不再服务。 举个例子： 1234upstream upstream-service &#123; server 127.0.0.1:17002; server 127.0.0.1:17000;&#125; round-robin在upstream这个模块中，它还提供了一个最基本的负载均衡算法round-robin。 其功能是： 以加权轮询的方式访问server指令指定的上游服务。 这个算法是默认集成在Nginx的框架中，无法移除，所以后面讲解的所有算法都是基于此，所有算法在某些特殊情况下最终都会变成round-robin。 涉及到的指令有： weight：服务访问的权重，默认是1。 max_conns：server的最大并发连接数，仅作用于单worker进程。 max_fails：在fail_timeout时间内，最大的失败次数。当达到最大失败时，会在fail_timeout时间内不允许再次被选择。 fail_timeout：单位为秒，默认是10秒。指定一段时间内，最大的失败次数max_fails。到达max_fails后，该server不能访问的时间。 简单的hash模块有的时候，正常的轮询算法并不能满足我们的需求， 比如：带有cookie请求状态的连接，如果应用服务没有设置专门的管理cookie的服务器，那么我们就希望同一个用户能被分配到同一个服务器。 再比如：我们后端应用需要针对请求当中的参数或者URL，将相同的请求放到相同的服务器上进行处理。 针对第一种情况，就可以用upstream_ip_hash。针对第二种情况，可以使用upstream_hash。 upstream_ip_hash功能： 以客户端的IP地址作为hash算法的关键字，映射到特定的上游服务器中。 对IPV4地址使用前3个字节作为关键字，对IPV6则使用完整地址。 可以使用round-robin算法的参数。 可以基于realip模块修改用于执行算法的IP地址。 举个例子： 12345upstream upstream-service &#123; ip_hash; server 127.0.0.1:17002; server 127.0.0.1:17000;&#125; upstream_hash功能： 通过制定关键字作为hash key，基于hash算法映射到特定的上游服务器中。 关键字可以含有变量、字符串。 可以使用round-robin算法的参数。 举个例子(以请求中的参数username作为hash key)： 12345upstream upstream-service &#123; hash user_$arg_username; server 127.0.0.1:17002; server 127.0.0.1:17000;&#125; 一致性哈希算法hash算法在一定程度上已经可以满足了我们的业务需求，但如果这个时候遇到应用宕机或者应用扩容，那么hash的总数就会变化，这样很有可能带来大量请求原本请求的服务器会更换，路由会失效，这样对于我们的应用服务也会产生极大的影响，这时候就可以采用一致性hash算法。 对于一致性哈希算法的理解，可以参考这篇文章：一致性哈希算法的理解与实践 它的使用也十分简单，就是在之前说的upstream_hash模块的hash指令最后，添加参数consistent，这样Nginx就可以使用一致性哈希算法了。 举个例子(仍以请求中的参数username作为hash key)： 12345upstream upstream-service &#123; hash user_$arg_username consistent; server 127.0.0.1:17002; server 127.0.0.1:17000;&#125; 总结以上就是Nginx中比较常见的负载均衡方法了，还有一些比如最少连接算法等，都是在此之上的一些应用。如果大家有什么疑问，欢迎在下方留言。 有兴趣的话可以访问我的博客或者关注我的公众号、头条号，说不定会有意外的惊喜。 https://death00.github.io/]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[github博客Hexo引流到微信]]></title>
    <url>%2F2019%2F09%2F26%2Fgithub%E5%8D%9A%E5%AE%A2hexo%E5%BC%95%E6%B5%81%E5%88%B0%E5%BE%AE%E4%BF%A1%2F</url>
    <content type="text"><![CDATA[相信有不少小伙伴都在github上创建了属于自己的博客，其中用Hexo的Next主题应该不少，那么，我们究竟该如何将博客的流量引流到微信呢？今天就来带你看一看。 如何引流现在网上有一种套路，当你在看别人博客时，只能看一半，想继续看的话，需要扫码关注别人的公众号才能继续，这样的话，你的公众号粉丝自然就能蹭蹭上涨。 这里需要解决两个问题： 文章看到一半就不允许继续观看 关注你的公众号后才能继续观看 这里我是借助了OpenWrite中的引流工具实现的。 导流当你注册进入OpenWrite后，会有一个博客导流公众号功能，添加完相应的信息后，即可获得一段具有隐藏功能的JS代码： 如何设置文章看到一半这就需要我们在文章模块页面增加相应的隐藏功能，并且能够展示二维码并锁住页面。 增加自定义swig文件进入你的博客文件夹，在themes\next\layout\_custom文件夹中，新建一个hide.swig文件（这个文件夹专门用来存放自定义的一些代码），复制上文提到的JS代码，注意id的值，它默认用的是container，我设置成了container-1。 修改文章模板文件进入你的博客文件夹，在themes\next\layout文件夹中，会有一个_layout.swig文件，这就是你的文章模板文件。其中有一段内容是： 123456&lt;main id="main" class="main"&gt; &lt;div class="main-inner"&gt; &lt;div class="content-wrap"&gt; &lt;div id="content" class="content"&gt; &#123;% block content %&#125;&#123;% endblock %&#125; &lt;/div&gt; id为content的地方，就是你的文章内容，这时候你可以在外面再嵌套一层div，其id就是上面我设置的container-1： 12345678&lt;main id="main" class="main"&gt; &lt;div class="main-inner"&gt; &lt;div class="content-wrap"&gt; &lt;div id="container-1"&gt; &lt;div id="content" class="content"&gt; &#123;% block content %&#125;&#123;% endblock %&#125; &lt;/div&gt; &lt;/div&gt; 此时就可以发布你的博客，现在你的文章就会产生阅读全文的按钮了： 按下这个按钮，就会弹出相应的二维码和你当初设置的关键字： 微信公众号自动回复设置在微信公众号后台页面，选择自动回复-关键词回复，点击添加回复： 填写规则名称、关键词(你当初在OpenWrite中设置的)，回复内容选择文字，填上OpenWrite中返回的那段文字。 此时，当别人关注你的公众号并输入关键字后(比如我设置的关键字就是git)，就会显示回复了 总结如果你的博客有一定的日活，那就千万不要错过这种微信涨粉、互相引流的机会。如果大家有什么疑问，欢迎在下方留言。]]></content>
      <tags>
        <tag>github</tag>
        <tag>Hexo</tag>
        <tag>Next</tag>
        <tag>微信</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中的interrupt]]></title>
    <url>%2F2019%2F09%2F25%2FJava%E4%B8%AD%E7%9A%84interrupt%2F</url>
    <content type="text"><![CDATA[我们都知道，Java中停止一个线程不能用stop，因为stop会瞬间强行停止一个线程，且该线程持有的锁并不能释放。大家多习惯于用interrupt，那么使用它又有什么需要注意的呢？ interrupt相关的方法Java中和interrupt相关的方法有三个 12345public boolean isInterrupted()public void interrupt()public static boolean interrupted() boolean isInterrupted()每个线程都一个状态位用于标识当前线程对象是否是中断状态。isInterrupted主要用于判断当前线程对象的中断标志位是否被标记了，如果被标记了则返回true，表示当前已经被中断，否则返回false。我们也可以看看它的实现源码： 12345public boolean isInterrupted() &#123; return isInterrupted(false);&#125;private native boolean isInterrupted(boolean ClearInterrupted); 底层调用的native方法isInterrupted，传入一个boolean类型的参数，用于指定调用该方法之后是否需要清除该线程的中断标识位。从这里我们也可以看出来，调用isInterrupted()并不会清除线程的中断标识位。 void interrupt()interrupt()用于设置当前线程对象的中断标识位，其源码为： 123456789101112131415public void interrupt() &#123; // 检查当前线程是否有权限修改目标线程，如果没有，则会抛出异常SecurityException if (this != Thread.currentThread()) checkAccess(); synchronized (blockerLock) &#123; Interruptible b = blocker; if (b != null) &#123; interrupt0(); // Just to set the interrupt flag b.interrupt(this); return; &#125; &#125; interrupt0();&#125; blockerLock和blocker都和阻塞IO时产生的中断相关，因此推测interrupt()需要当阻塞IO操作执行完之后，才可以执行。 interrupt()其实只是改变了一个标志位，对于线程本身的状态并没有影响。 boolean interrupted()该方法是一个静态的方法，用于返回当前线程是否被中断，其源码是： 123public static boolean interrupted() &#123; return currentThread().isInterrupted(true);&#125; 需要注意的是：该方法调用结束的时候会清空中断标识位。 线程的状态与中断的关系我们知道，Java中的线程一共6种状态，分别是NEW，RUNNABLE，BLOCKED，WAITING，TIMED_WAITING，TERMINATED（Thread类中有一个State枚举类型列举了线程的所有状态）。下面我们就将把线程分别置于上述的不同种状态，然后看看中断操作对它们的影响。 NEW和TERMINATEDNEW状态表示线程还未调用start()方法，TERMINATED状态表示线程已经运行终止。 这两个状态下调用中断方法来中断线程的时候，Java认为毫无意义，所以并不会设置线程的中断标识位。例如： NEW状态： 12345678public static void main(String[] args) &#123; Thread thread = new Thread(); System.out.println(thread.getState()); System.out.println(thread.isInterrupted()); thread.interrupt(); System.out.println(thread.isInterrupted());&#125; 输出结果：123NEWfalsefalse TERMINATED状态： 123456789101112public static void main(String[] args) throws InterruptedException &#123; Thread thread = new Thread(); // 开始线程 thread.start(); // 等待线程结束 thread.join(); System.out.println(thread.getState()); System.out.println(thread.isInterrupted()); thread.interrupt(); System.out.println(thread.isInterrupted());&#125; 输出结果：123TERMINATEDfalsefalse 从上述的两个例子来看，处于NEW和TERMINATED状态的线程，对于中断是屏蔽的，也就是说中断操作对这两种状态下的线程是无效的。 RUNNABLE处于RUNNABLE状态的线程，当中断线程后，会修改其中断标志位，但并不会影响线程本身。例如： 123456789101112131415161718192021222324/** * 自定义线程类 */public class MyThread extends Thread&#123; @Override public void run()&#123; while(true)&#123; // 什么都不做，就是空转 &#125; &#125; public static void main(String[] args) &#123; Thread thread = new MyThread(); thread.start(); System.out.println(thread.getState()); System.out.println(thread.isInterrupted()); thread.interrupt(); System.out.println(thread.isInterrupted()); System.out.println(thread.getState()); &#125;&#125; 结果为：1234RUNNABLEfalsetrueRUNNABLE 中断标志位确实被改变了，但线程依旧继续运行。那我们调用interrupt()方法的意义在哪儿？ 其实Java是将中断线程的权利交给了我们自己的程序，通过中断标志位，我们的程序可以通过boolean isInterrupted()方法来判断当前线程是否中断，从而决定之后的操作。 我们可以在此基础上，保证执行任务的原子性。例如修改MyThread类的方法： 12345678910111213141516171819202122232425262728/** * 自定义线程类 */public class MyThread extends Thread&#123; @Override public void run()&#123; while(true)&#123; if (this.isInterrupted())&#123; System.out.println("exit MyThread"); break; &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; Thread thread = new MyThread(); thread.start(); System.out.println(thread.getState()); System.out.println(thread.isInterrupted()); thread.interrupt(); System.out.println(thread.isInterrupted()); thread.join(); System.out.println(thread.getState()); &#125;&#125; 结果为：12345RUNNABLEfalsetrueexit MyThreadTERMINATED BLOCKED当线程处于BLOCKED状态，说明该线程由于竞争某个对象的锁失败而被挂在了该对象的阻塞队列上了。 那么此时发起中断操作不会对该线程产生任何影响，依然只是设置中断标志位。例如： 1234567891011121314151617181920212223242526272829303132/** * 自定义线程类 */public class MyThread extends Thread&#123; public synchronized static void doSomething()&#123; while(true)&#123; // 空转 &#125; &#125; @Override public void run()&#123; doSomething(); &#125; public static void main(String[] args) throws InterruptedException &#123; // 启动两个线程 Thread thread1 = new MyThread(); thread1.start(); Thread thread2 = new MyThread(); thread2.start(); Thread.sleep(1000); System.out.println(thread1.getState()); System.out.println(thread2.getState()); System.out.println(thread2.isInterrupted()); thread2.interrupt(); System.out.println(thread2.isInterrupted()); System.out.println(thread2.getState()); &#125;&#125; 结果为：12345RUNNABLEBLOCKEDfalsetrueBLOCKED thread2处于BLOCKED状态，执行中断操作之后，该线程仍然处于BLOCKED状态，但是中断标志位却已被修改。 这种状态下的线程和处于RUNNABLE状态下的线程是类似的，给了我们程序更大的灵活性去判断和处理中断。 WAITING/TIMED_WAITING这两种状态本质上是同一种状态，只不过TIMED_WAITING在等待一段时间后会自动释放自己，而WAITING则是无限期等待，需要其他线程调用类似notify方法释放自己。但是他们都是线程在运行的过程中由于缺少某些条件而被挂起在某个对象的等待队列上。 当这些线程遇到中断操作的时候，会抛出一个InterruptedException异常，并清空中断标志位。例如： 123456789101112131415161718192021222324252627282930/** * 自定义线程类 */public class MyThread extends Thread&#123; @Override public void run()&#123; synchronized (this)&#123; try &#123; wait(); &#125; catch (InterruptedException e) &#123; System.out.println("catch InterruptedException"); &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; Thread thread = new MyThread(); thread.start(); Thread.sleep(1000); System.out.println(thread.getState()); System.out.println(thread.isInterrupted()); thread.interrupt(); Thread.sleep(1000); System.out.println(thread.isInterrupted()); &#125;&#125; 结果为：1234WAITINGfalsecatch InterruptedExceptionfalse 从运行结果看，当线程启动之后就被挂起到该线程对象的等待队列上，然后我们调用interrupt()方法对该线程进行中断，输出了我们在catch中的输出语句，显然是捕获了InterruptedException异常，接着就看到该线程的中断标志位被清空。 因此我们要么就在catch语句中结束线程，否则就在catch语句中加上this.interrupt();，再次设置标志位，这样也方便在之后的逻辑或者其他地方继续判断。 总结我们介绍了线程在不同状态下对于中断请求的反应： NEW和TERMINATED对于中断操作几乎是屏蔽的。 RUNNABLE和BLOCKED类似，对于中断操作只是设置中断标志位并没有强制终止线程，对于线程的终止权利依然在程序手中。 WAITING和TIMED_WAITING状态下的线程对于中断操作是敏感的，他们会抛出异常并清空中断标志位。]]></content>
      <tags>
        <tag>Java</tag>
        <tag>interrupt</tag>
        <tag>线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中的管程]]></title>
    <url>%2F2019%2F06%2F29%2FJava%E4%B8%AD%E7%9A%84%E7%AE%A1%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Java是利用管程解决并发编程问题的，那么究竟什么是管程？而它又是如何解决并发问题的呢？ 什么是管程管程，英文名是 Monitor ，因此有的时候会被翻译为监视器。其实你也许很早就接触到这个概念了，比如 synchronized关键字，很多文章就介绍过其原理是使用了监视器，只是你那个时候还并不知道监视器和管程，其实是一回事。 我们来看看维基百科上的概念： 管程 (英语：Monitors，也称为监视器) 是一种程序结构，结构内的多个子程序（对象或模块）形成的多个工作线程互斥访问共享资源。 感觉这句话听得有点迷糊，但下面这句话应该就很好理解了： 管程提供了一种机制，线程可以临时放弃互斥访问，等待某些条件得到满足后，重新获得执行权恢复它的互斥访问。 我的理解是：我们通过管程管理 Java 中的类，使得类是线程安全的。 这应该是管程最终要达到的效果，那么，它是怎么做到的呢？ 管程模型管程这个概念最早来源于操作系统，操作系统发展了那么多年，管程的实现也有多种方式，主流的有三种：Hasen模型、Hoare模型和MESA模型， Java 中借鉴的是MESA模型，让我们来重点看一下。 谈到MESA模型，就不得不提到并发主要解决2个核心问题：一个是互斥，即同一时刻只允许一个线程访问共享资源；另一个是同步，即多个线程之间如何通信、协作。 如何解决互斥呢？我们可以在操作共享变量之前，增加一个等待队列，每一个线程想要操作共享变量的话，都需要在等待队列中等待，直到管程选出一个线程操作共享变量。 那又是如何解决同步的呢？线程在操作共享变量时候，它不一定是直接执行，可能有一些自己的执行条件限制（比如取钱操作要求账户里一定要有钱，出队操作要求队列一定不能是空的），我们将这些限制称之为条件变量，每一个条件变量也有自己对应的等待队列，当线程发现自己的条件变量不满足时，就进入相应的等待队列中排队，直至条件变量满足，那么其等待队列中的线程也不会是立马执行，而是到最开始共享变量对应的等待队列中再次排队，重复之前的过程。 可以参考下面这幅图： 理论说了那么多，还是来看看用代码是如何实现的吧 实现首先可以自定一个支持并发的队列12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788public class MyQueen &#123; // 共享变量（任何操作之前，都需要获得该锁才可以执行） private final Lock lock = new ReentrantLock(); // 条件变量：队列不满 private final Condition notFull = lock.newCondition(); // 条件变量：队列不空 private final Condition notEmpty = lock.newCondition(); /** * 存储队列的容器 */ private final LinkedList&lt;Integer&gt; list = new LinkedList&lt;&gt;(); /** * 最大容量 */ private int capacity; /** * 当前容器中存储的数量 */ private int size; public MyQueen(int capacity) &#123; this.capacity = capacity; this.size = 0; &#125; /** * 入队 */ public void enter(int value) &#123; lock.lock(); try &#123; // 如果队列已满，则需要等到队列不满 while (size &gt;= capacity) &#123; notFull.await(1, TimeUnit.MILLISECONDS); &#125; // 入队 list.add(value); size++; System.out.println(value + &quot; has bean entered&quot;); // 通知可以出队 notEmpty.signal(); &#125; catch (InterruptedException e) &#123; &#125; finally &#123; lock.unlock(); &#125; &#125; /** * 出队 */ public int dequeue() &#123; Integer result = null; lock.lock(); try &#123; // 如果队列已空，则需要等到队列不空 while (size &lt;= 0) &#123; notEmpty.await(1, TimeUnit.MILLISECONDS); &#125; // 出队 result = list.removeFirst(); size--; System.out.println(result + &quot; has bean dequeued&quot;); // 通知可以入队 notFull.signal(); return result; &#125; catch (InterruptedException e) &#123; &#125; finally &#123; lock.unlock(); &#125; return result; &#125; public static void main(String[] args) &#123; MyQueen myQueen = new MyQueen(3); new Thread(new Pruducer(&quot;producer1&quot;, myQueen, 0, 2)).start(); new Thread(new Pruducer(&quot;producer2&quot;, myQueen, 2, 5)).start(); new Thread(new Consumer(&quot;consumer2&quot;, myQueen, 5)).start(); new Thread(new Consumer(&quot;consumer1&quot;, myQueen, 3)).start(); &#125;&#125; 定义生产者和消费者：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768class Pruducer implements Runnable &#123; private final MyQueen queen; /** * 该线程的名字 */ private final String name; /** * 开始的大小 */ private final int start; /** * 需要生产的资料个数 */ private final int size; public Pruducer(String name, MyQueen queen, int start, int size) &#123; this.name = name; this.queen = queen; this.start = start; this.size = size; &#125; @Override public void run() &#123; for (int i = 1; i &lt;= size; i++) &#123; int now = start + i;// System.out.println(name + &quot; produce : &quot; + now + &quot; start&quot;); queen.enter(now);// System.out.println(name + &quot; produce : &quot; + now + &quot; end&quot;); &#125; &#125;&#125;class Consumer implements Runnable &#123; private final MyQueen queen; /** * 该线程的名字 */ private final String name; /** * 需要消费的资料个数 */ private final int size; public Consumer(String name, MyQueen queen, int size) &#123; this.name = name; this.queen = queen; this.size = size; &#125; @Override public void run() &#123; for (int i = 1; i &lt;= size; i++) &#123;// System.out.println(name + &quot; consume start&quot;); int result = queen.dequeue();// System.out.println(name + &quot; consume : &quot; + result + &quot; end&quot;); &#125; &#125;&#125; 做一个测试的main方法：1234567public static void main(String[] args) &#123; MyQueen myQueen = new MyQueen(3); new Thread(new Pruducer(&quot;producer1&quot;, myQueen, 0, 2)).start(); new Thread(new Pruducer(&quot;producer2&quot;, myQueen, 2, 5)).start(); new Thread(new Consumer(&quot;consumer1&quot;, myQueen, 3)).start(); new Thread(new Consumer(&quot;consumer2&quot;, myQueen, 5)).start();&#125; 结果为：1234567891011121314151617181 has bean entered2 has bean entered3 has bean entered1 has bean dequeued2 has bean dequeued3 has bean dequeued4 has bean entered5 has bean entered6 has bean entered4 has bean dequeued5 has bean dequeued6 has bean dequeued7 has bean entered8 has bean entered9 has bean entered7 has bean dequeued8 has bean dequeued9 has bean dequeued 虽然满足我想要的结果，但显示的内容有些奇怪，总是容器先被填满之后，然后容器被清空，感觉原因应该和可重入锁有关。 总结以上就是我对于管程的一些理解，如果大家有什么疑问，欢迎在下方留言。]]></content>
      <tags>
        <tag>Java</tag>
        <tag>管程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx报错111: Connection refused]]></title>
    <url>%2F2019%2F06%2F06%2FNginx%E6%8A%A5%E9%94%99111-Connection-refused%2F</url>
    <content type="text"><![CDATA[最近遇到了Nginx疯狂抛错，access.log一天一共5W多条，但error.log中有大概9K多条，基本都是111: Connection refused，这到底是为什么呢？ 从日志看起我们还是先来看日志。我提取了一条error.log当中抛错的日志(稍微分一下行，否则实在太长，敏感信息稍微处理了一下):12342019/06/06 10:09:45 [error] 28652#0: *883239 connect() failed (111: Connection refused) while connecting to upstream, client: 124.104.90.145, server: xxx.xxxxx.com, request: &quot;POST /test-service/upload?mcachenum=155978698 HTTP/1.1&quot;, upstream: &quot;http://[::1]:17000/test-service/upload?mcachenum=155978698&quot;, host: &quot;xxx.xxxxx.com&quot;, referrer: &quot;https://servicewechat.com/x98b46f69/2/page-frame.html&quot; 看了一下前面的报错和后面的描述，第一眼看上去感觉都是正常。但再看之后发现，upstream中的host有些不一样。[::1]，这实际是一个IPv6的地址。 这时候你可以查看一下你的机器是否开启了IPv6的地址，linux的命令是：ip address，看看返回结果中是否出现了inet6，如果有，那么恭喜你，原因找到了。 解决办法解决方法有两种，一个是禁用你机器的IPv6配置，另一个则是修改nginx.conf中的配置。 个人觉得后一个方法更加保险一些，因为这不涉及到你的机器配置，应该相对而言最少。 nginx.conf的修改，则是针对server模块中的location，修改proxy_pass中的host，我们在网上经常看到别人用的是： proxy_pass http://localhost:18000/test-service/; 但为了强制指定IPv4的地址，需要变成： proxy_pass http://127.0.0.1:18000/test-service/; 这样操作之后，再观察nginx的error.log，应该就不会再报upstream里含有IPv6地址的错误了。 总结以上就是我这次错误的整个过程，虽然整个过程不长，但确实让我知道了，作为一个后端开发，我的知识面还是太窄了。而且Bing也是真的好用，最近无法翻墙了，暂时用Bing代替，感觉还是不错的。]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>[object Object]</tag>
        <tag>upstream</tag>
        <tag>IPv6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[力扣-65不同路径]]></title>
    <url>%2F2019%2F05%2F10%2F%E5%8A%9B%E6%89%A3-65%E4%B8%8D%E5%90%8C%E8%B7%AF%E5%BE%84%2F</url>
    <content type="text"><![CDATA[最近在刷力扣上的题目，刷到了65不同路径，当初上大学的时候，曾在hihocoder上刷到过这道题目，但是现在已经几乎全忘光了，大概的知识点是动态规划，如今就让我们一起来回顾一下。 从题目说起题目原文是： 一个机器人位于一个 m x n 网格的左上角 （起始点在下图中标记为“Start” ）。 机器人每次只能向下或者向右移动一步。机器人试图达到网格的右下角（在下图中标记为“Finish”）。 问总共有多少条不同的路径？ 例如，上图是一个7 x 3 的网格。有多少可能的路径？ 说明：m 和 n 的值均不超过 100。 示例 1: 输入: m = 3, n = 2 输出: 3 解释: 从左上角开始，总共有 3 条路径可以到达右下角。 向右 -&gt; 向右 -&gt; 向下 向右 -&gt; 向下 -&gt; 向右 向下 -&gt; 向右 -&gt; 向右 示例 2: 输入: m = 7, n = 3 输出: 28 正向思路我们先按照正常思路来想一下，当你处于起点时，你有两个选择，向右或者向下，除非你处于最下面一排或者最右边一列，那你只有一种选择（比如处于最下面一排，你只能往右），其他位置，你都有两种选择。 因此，我们就根据这个思路，可以写出代码：123456789101112131415161718192021222324252627class Solution &#123; public int uniquePaths(int m, int n) &#123; // 特殊情况：起点即终点 if (m == 1 &amp;&amp; n == 1) &#123; return 1; &#125; // 当前处于(1,1)，终点为(m,n) return walk(1, 1, m, n); &#125; public int walk(int x, int y, int m, int n)&#123; // 已经处于终点 if (x &gt;= m &amp;&amp; y &gt;= n) &#123; return 0; &#125; // 处于最下面一排或者最右边一列 if (x &gt;= m || y &gt;= n) &#123; return 1; &#125; // 往下走，有多少种走法 int down = walk(x, y + 1, m, n); // 往右走，有多少种走法 int right = walk(x + 1, y, m, n); // 从当前(x,y)出发，走到(m,n)，共有多少种走法 return down + right; &#125;&#125; 优化我们考虑一下，这种写法，有没有可以优化的地方。 你们应该一眼就发现，walk方法的第一个判断if (x &gt;= m &amp;&amp; y &gt;= n)，永远都不可能为true，因为下一个判断if (x &gt;= m || y &gt;= n)就已经是临界点情况，直接就已经有返回值，根本不可能达到x &gt;= m &amp;&amp; y &gt;= n的情况。因此，该判断可以删除。 假设我们从(1,1)的位置出发，终点是(3,3)，那么到达(2,2)这个中间点的话有几种走法呢？两种，先到(1,2)再到(2,2)，或者，先到(2,1)再到(2,2)。 因此，如果根据我们上面的写法，从(2,2)到终点(3,3)，我们会算两次，虽然这样的思路本身是正确，但这样的情况应该是可以优化的。因为从(1,1)到(3,3)，一共只有6种路径，但已经有2条是重复的路径了，那么随着m与n越来越大，中间点会越来越多，那么重复的路径也会越来越多。 这就是前面的选择对于后面的选择会有影响，即使后面的选择相同，但由于前面的选择不同，从而也被认为是不同的选择。 很明显，后面的选择更加唯一，如果我们先在后面做出选择，那么就可以减少重复计算的次数。因此，我们可以试试反向思路。 反向思路如果我们不是从起点出发，而是从终点倒退到起点开始算的话。假设终点是(3,3)，它只能由(2,3)和(3,2)直接到达，(2,3)也只能由(2,2)和(1,3)直接到达，(1,3)只能由(1,2)直接到达，(1,2)只能由(1,1)直接到达，因此(1,3)只能由(1,1)直达。 我们可以得出规律：除了最左边一列和最上面一排的点，只能由起点(1,1)直达以外，其他的点(x,y)都是由(x-1,y)和(x,y-1)两个点直接到达的。 因此，根据这个思路，我们可以写出代码：12345678910111213141516171819class Solution &#123; public int uniquePaths(int m, int n) &#123; int[][] result = new int[m][n]; int j; for (int i = 0; i &lt; m; i++) &#123; for (j = 0; j &lt; n; j++) &#123; if (i == 0 || j == 0) &#123; // 最上面一排的点和最左边一列的点，只能由(1,1)到达 result[i][j] = 1; &#125; else &#123; // 其他的点都可以由左边的点和上面的点到达 result[i][j] = result[i - 1][j] + result[i][j - 1]; &#125; &#125; &#125; return result[m - 1][n - 1]; &#125;&#125; 其实这样的想法就已经是动态规划的范畴了，我们看看维基上的定义 动态规划（英语：Dynamic programming，简称DP）是一种在数学、管理科学、计算机科学、经济学和生物信息学中使用的，通过把原问题分解为相对简单的子问题的方式求解复杂问题的方法。 一开始我感觉很像分治法，因为都需要将一个大问题分解为子问题，但分治法最终会将子问题合并，但动态规划却不用。 优化我们考虑一下，这种写法，有没有可以优化的地方。 首先是空间上的优化，我们一定要用二维数组吗？可以用一维数组代替吗？ 答案是肯定的，因为每个点的计算只和左边与上边相邻的点有关，因此，不需要更加久远的点。 一维数组假如只用一维数组，那么只需要存储上一排的结果，如果计算到下一排的时候，则依次替换，代码为： 12345678910111213141516171819class Solution &#123; public int uniquePaths(int m, int n) &#123; int[] dp = new int[m]; int j; for(int i = 0; i &lt; n; i++) &#123; for(j = 0; j &lt; m; j++) &#123; if(j == 0) &#123; dp[j] = 1; &#125; else &#123; // 其他的点都可以由左边的点和上面的点到达 dp[j] += dp[j-1]; &#125; &#125; &#125; return dp[m-1]; &#125;&#125; 这样的优化，差不多就结束了。那我们是否可以从思路上进行优化呢？ 组合数因为我们只有向右或向下两种选择，而我们一共要走的路径其实是(m-n-2)，其中有(m-1)的路径是向右，(n-1)的路径是向下，其实可以转变为： 从(m-n-2)中挑出(m-1)，即组合数C((m-n-2), (m-1))的值 那么我们可以写出代码：12345678910111213141516class Solution &#123; public int uniquePaths(int m, int n) &#123; // 用double，因为计算出的数值会很大 double num = 1, denom = 1; // 找出更小的数，这样可以减少计算次数和计算出的数值 int small = m &gt; n ? n : m; for (int i = 1; i &lt;= small - 1; ++i) &#123; num *= m + n - 1 - i; denom *= i; &#125; return (int)(num / denom); &#125;&#125; ##总结 以上就是我做这道题的一些思路和想法了，虽然题目本身不难，但可以讨论的点还是很多的，如果大家有什么疑问，欢迎在下方留言。 有兴趣的话可以关注我的公众号，说不定会有意外的惊喜。]]></content>
      <tags>
        <tag>Java</tag>
        <tag>力扣</tag>
        <tag>动态规划</tag>
        <tag>组合数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JWT与Session的比较]]></title>
    <url>%2F2019%2F04%2F24%2FJWT%E7%9A%84%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[如今，越来越多的项目开始采用JWT作为认证授权机制，那么它和之前的Session究竟有什么区别呢？今天就让我们来了解一下。 JWT是什么定义 JSON Web Token（JWT）是一个开放标准（RFC 7519），它定义了一种紧凑和自包含的方式，用于在各方之间作为JSON对象安全地传输信息。作为标准，它没有提供技术实现，但是大部分的语言平台都有按照它规定的内容提供了自己的技术实现，所以实际在用的时候，只要根据自己当前项目的技术平台，到官网上选用合适的实现库即可。 特点使用JWT来传输数据，实际上传输的是一个字符串，这个字符串就是所谓的json web token字符串。所以广义上，JWT是一个标准的名称；狭义上，JWT指的就是用来传递的那个token字符串。这个串有两个特点： 紧凑：指的是这个串很小，能通过url 参数，http 请求提交的数据以及http header的方式来传递； 自包含：这个串可以包含很多信息，比如用户的id、角色等，别人拿到这个串，就能拿到这些关键的业务信息，从而避免再通过数据库查询等方式才能得到它们。 结构 它由三部分组成：header（头部）、payload（载荷）、signature（签名），以.进行分割。（这个字符串本来是只有一行的，此处分成3行，只是为了区分其结构） header用来声明类型（typ）和算法（alg）。 payload一般存放一些不敏感的信息，比如用户名、权限、角色等。 signature则是将header和payload对应的json结构进行base64url编码之后得到的两个串用英文句点号拼接起来，然后根据header里面alg指定的签名算法生成出来的。 和Session的区别为什么我们要把JWT和Session做对比呢？因为我们主要在每一次请求的认证时会用JWT，在此之前我们都是用Session的。那这两者的区别在哪儿呢？ 本身的含义看了前面的介绍，我们发现JWT这个字符串其实本身就包含了关于用户的信息，比如用户名、权限、角色等。 Session传递的sessionId虽然是一个更简单的字符串，但它本身并没有任何含义。 所以一般说来JWT的字符串要比sessionId长，如果你在JWT中存储的信息越长，那么JWT本身也会越长。 而Cookie的存储容量是有限制的（通常为4KB），所以大家在使用的时候需要注意。 解析方法JWT的header和payload其实是有json转变过来的，而signature其实就是一个加密后的字符串，因此解析起来较为简单，不需要其他辅助的内容。 sessionId是服务器存储的用户对象的标识，理论上需要一个额外的map才能找出当前用户的信息。 管理方法JWT理论上用于无状态的请求，因此其用户管理也只是依赖本身而已。我们一般是在它的payload中加入过期时间，在不增加额外管理的情况下，它只有自动过期的方式。 Session因为它本就是存储在服务器端的，因此管理方案就有很多，而且大多都很成熟。 跨平台JWT本身就是基于json的，因此它是比较容易跨平台的，可以从官网下载不同平台的包，解析即可。 session的跨平台可能就不那么好做了，需要考虑的地方在于用户信息存储的格式，ProtoBuf、json、xml等，管理的话可能就需要专门的统一登录平台，这个就不展开了。 时效性无状态JWT一旦被生成，就不会再和服务端有任何瓜葛。一旦服务端中的相关数据更新，无状态JWT中存储的数据由于得不到更新，就变成了过期的数据。 session就不一样了，sessionId本身就没有太多含义，只需修改服务端中存储的数据即可。 适用场景JWTJWT的最佳用途是一次性授权Token，这种场景下的Token的特性如下： 有效期短 只希望被使用一次 真实场景的例子——文件托管服务，由两部分组成： Web 应用：这是一个可以被用户登录并维持状态的应用，用户在应用中挑选想要下载的文件。 文件下载服务：无状态下载服务，只允许通过密钥下载。 如何把JWT用在这个场景中呢？ 用户登录到 Web 应用中，挑选好想要下载的文件，点击下载。 认证服务颁发包含下载信息的、具有较短过期时间的JWT。JWT中包含的信息可以是这样的： 1234&#123; &quot;file&quot;: &quot;/books/我这一辈子.pdf&quot;, &quot;exp&quot;: 1500719759621&#125; 使用 JWT 从文件下载服务下载文件。 SessionSession比较适用于Web应用的会话管理，其特点一般是： 权限多，如果用JWT则其长度会很长，很有可能突破Cookie的存储限制。 基本信息容易变动。如果是一般的后台管理系统，肯定会涉及到人员的变化，那么其权限也会相应变化，如果使用JWT，那就需要服务器端进行主动失效，这样就将原本无状态的JWT变成有状态，改变了其本意。 总结我们使用JWT，并不是说看到它新就用，而应该考虑其适用场景，如果需要进行管理，可以考虑使用Session，毕竟其方案更加成熟。如果大家有什么新发现想和作者探讨的，欢迎在下方留言。]]></content>
      <tags>
        <tag>JWT</tag>
        <tag>Session</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP连接及其优化]]></title>
    <url>%2F2019%2F04%2F18%2FTCP%E8%BF%9E%E6%8E%A5%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[作为一个后端程序员，网络连接这块是一个绕不过的砍，当你在做服务器优化的时候，网络优化也是其中一环，那么作为网络连接中最基础的部分-TCP连接你了解吗？今天我们来仔细看看这个部分。 TCP建立连接-三次握手详解 客户端和服务器还未建立连接，但服务器一般处于listen状态 客户端主动建立连接，向服务器发送SYN报文，客户端变为SYN_SENT状态 服务器收到客户端发送的报文，也回了一个SYN报文，包含了一个ack。此时，服务器变为SYN_RCVD状态 客户端收到了服务器发送的SYN报文，确认了ack，它将向服务器发送一个ACK报文。此时，客户端变为ESTABLISHED 服务器收到客户端的ACK报文，确认了ack。此时，服务器也变为ESTABLISHED 服务器和客户端可以正常通信了 其中步骤2~4就是三次握手，那么为什么需要三次握手呢？为什么不是一次或者两次握手呢？ 首先，我们需要知道，只有当服务器和客户端都能确保自己能够发消息和接收消息，这次网络通信才算成功的。 步骤2的作用是让服务器知道了自己是可以接收消息的。 步骤3的作用是让客户端知道自己发送消息和接收消息的功能是OK的，发送消息的能力是通过服务器返回的ack=x+1确认的，因为这个值基于当初客户端发送的消息seq=x。接收消息的能力是因为收到了服务器的返回。 步骤4的作用是让服务器端知道自己发送消息的能力是OK的（和步骤3类似）。 linux查看linux服务器可以利用netstat -anp | grep tcp命令，查看服务器上各个端口和应用的连接状态。 你还可以通过修改linux的配置文件/etc/sysctl.conf，调整各个状态的数量 SYN_SENT状态相关 主动建立连接时，发SYN（步骤2）的重试次数 1nct.ipv4.tcp_syn_rctries = 6 建立连接时的本地端口可用范围 1net.ipv4.ip_local_port_range = 32768 60999 SYN_RCVD状态相关 SYN_RCVD状态连接的最大个数 1net.ipv4.tcp_max_syn_backlog 被动建立连接时，发SYN/ACK（步骤3）重试次数 1net.ipv4.tcp_synack_retries 说完了TCP建立连接，接下来，我们再来看看TCP正常断开连接的过程 TCP断开连接-四次挥手详解 客户端与服务器端正常传输数据 客户端主动断开连接，向服务器端发送FIN报文，客户端变为FIN_WAIT1状态 服务器收到客户端的FIN后，向客户端发送ACK报文，服务器变为CLOSE_WAIT状态 客户端收到服务器的ACK报文后，客户端变为FIN_WAIT2状态 服务器向客户端发送FIN报文，服务器变为LAST_ACK状态 客户端收到服务器发送的FIN报文后，向服务器发送ACK报文，客户端变为TIME_WAIT状态 服务器收到客户端的ACK报文后，服务器变为CLOSED状态 客户端经过2MSL(max segment lifetime，报文最大生存时间)时间后，也变为CLOSED状态 其中，步骤2、3、5、6即为4次挥手。 TIME_WAIT状态及其优化看完之后，大家想必会有一个疑问，为什么TIME_WAIT状态需要保持2MSL？因为这可以保证至少一次报文的往返时间内，端口是不可复用的。 假设TIME_WAIT状态的持续时间很短，我们来模拟下面这种场景： 客户端向服务器端发送了三条报文，其中第3条报文卡在网络中，服务器只收到了前两条，向客户单发送ACK=2，客户端重新发送第三条报文。 服务器主动发送FIN报文，客户端收到后发送FIN、ACK，服务器端收到后发送ACK并进入TIME_WAIT状态（假设这个状态很短）。 现在服务器又再次和客户端建立连接，三次握手之后开始发送正常数据，结果之前卡住的第三条报文，现在终于发送到服务器，但服务器也不知道该如何处理这条报文。 因此这也是TIME_WAIT状态需要保持2MSL的原因，如果这么长时间也没有收到报文，即使有正确的报文从客户端发出，也已经过期了，因此不会影响到之后的通信。 但这同样也会带来一个问题，TIME_WAIT状态保持的时间较长，假设服务器端有大量TIME_WAIT状态的TCP连接，就相当于白白浪费掉大量的服务器资源(端口)。此时，我们可以通过修改以下配置进行服务器调优：1net.ipv4.tcp_tw_reuse = 1 开启后，作为客户端时新连接可以使用仍然处于TIME_WAIT状态的端口 由于timestamp的存在，操作系统可以拒绝迟到的报文（例如上面说的第三条报文），可以利用以下配置： 1net.ipv4.tcp_timestamps = 1 其他状态的优化CLOSE_WAIT状态如果服务器端有大量CLOSE_WAIT状态的连接，很有可能是应用进程出现bug，没有及时关闭连接。 FIN_WAIT1状态调整发送FIN报文的重试次数，0相当于81net.ipv4.tcp_orphan_retries = 0 FIN_WAIT2状态调整保持在FIN_WAIT2状态的时间1net.ipv4.tcp_fin_timeout = 60 总结看到这里，想必你应该对TCP连接有了一个大致的了解。现在服务器大多都用了nginx做了负载均衡，因此，我们可能需要在此基础上了解一些nginx相关的配置原理，这样应该会对我们的服务器性能调优会有更大的帮助。有兴趣的同学不妨可以去了解一下，如果有什么新发现想和作者探讨的，欢迎在下方留言。]]></content>
      <tags>
        <tag>优化</tag>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中容器的遍历]]></title>
    <url>%2F2019%2F04%2F17%2FJava%E4%B8%AD%E5%AE%B9%E5%99%A8%E7%9A%84%E9%81%8D%E5%8E%86%2F</url>
    <content type="text"><![CDATA[当我们用增强for循环遍历非并发容器（HashMap、ArrayList等），如果修改其结构，会抛出异常ConcurrentModificationException，因此在阿里巴巴的Java规范中有说到：不要在foreach循环里进行元素的remove/add操作，remove元素请使用Iterator方式。，但是不是真的就不可以在增强for循环中修改结构吗？其原理又是什么呢？ ConcurrentModificationException的含义ConcurrentModificationException可以将其通俗的翻译为并发修改异常，那么关注点就在并发和修改了。也许有些人会说，我只是在单线程中修改了，并没有并发操作，但系统也抛了这样的这样的错误，这是为什么呢？别急，我们看看它的源码解释： This exception may be thrown by methods that have detected concurrent modification of an object when such modification is not permissible. 这个异常就是应用程序在做一些系统不允许的操作时抛出的。记住，只要是系统不允许的操作，就一定会抛错的。 后面有一个值得注意的地方 Note that fail-fast behavior cannot be guaranteed as it is, generally speaking, impossible to make any hard guarantees in the presence of unsynchronized concurrent modification. Fail-fast operations throw ConcurrentModificationException on a best-effort basis. Therefore, it would be wrong to write a program that depended on this exception for its correctness: ConcurrentModificationException should be used only to detect bugs. fail-fast（快速失败）并不能一定被保证，所以fail-fast操作会尽最大努力抛出该异常。既然是尽最大努力，因此无论是不是并发操作，只要是修改了，就一定会报错。 既然如此，我们来看看for循环中遍历修改容器结构，系统是如何知道的。 增加for循环的原理我们来看看增强for循环遍历修改HashMap的代码：12345678910Map&lt;String, String&gt; hashMap = new HashMap&lt;&gt;(10);// 添加for (int i = 0; i &lt; 10; i++) &#123; hashMap.put(&quot;key&quot; + i, &quot;value&quot; + i);&#125;// 遍历修改for (Entry&lt;String, String&gt; entry : hashMap.entrySet()) &#123; String key = entry.getKey(); hashMap.remove(key);&#125; 这个时候，你如果运行的话，就会抛出ConcurrentModificationException，这个时候我们需要具体调试一下，发现遍历第一次并删除时没有报错，但第二次遍历，在for循环的括号执行完后，就抛出了异常，这又是为什么呢？ 让我们反编译一下class文件，看看究竟增强for循环做了什么：123456789101112Map&lt;String, String&gt; hashMap = new HashMap(10);for(int i = 0; i &lt; 10; ++i) &#123; hashMap.put(&quot;key&quot; + i, &quot;value&quot; + i);&#125;Iterator var5 = hashMap.entrySet().iterator();while(var5.hasNext()) &#123; Entry&lt;String, String&gt; entry = (Entry)var5.next(); String key = (String)entry.getKey(); hashMap.remove(key);&#125; 我们发现，虽然写法上是增强for循环，但实际还是使用的while结合iterator进行遍历，现在我们贴上这个代码进行调试。 发现在第二次var5.next()处抛异常，接下来我们看看next方法究竟做了什么？ 在HashMap的源码中显示：1234567891011121314151617final class EntryIterator extends HashIterator implements Iterator&lt;Map.Entry&lt;K,V&gt;&gt; &#123; public final Map.Entry&lt;K,V&gt; next() &#123; return nextNode(); &#125;&#125;final Node&lt;K,V&gt; nextNode() &#123; Node&lt;K,V&gt;[] t; Node&lt;K,V&gt; e = next; if (modCount != expectedModCount) throw new ConcurrentModificationException(); if (e == null) throw new NoSuchElementException(); if ((next = (current = e).next) == null &amp;&amp; (t = table) != null) &#123; do &#123;&#125; while (index &lt; t.length &amp;&amp; (next = t[index++]) == null); &#125; return e;&#125; 我们注意到，nextNode()方法的第一个判断就决定了是否抛出ConcurrentModificationException，那么modCount和expectedModCount究竟是什么呢？ modCount和expectedModCount我们来看看modCount和expectedModCount的关系，当我们调用Iterator var5 = hashMap.entrySet().iterator();时，源代码做了什么：123456789HashIterator() &#123; expectedModCount = modCount; Node&lt;K,V&gt;[] t = table; current = next = null; index = 0; if (t != null &amp;&amp; size &gt; 0) &#123; // advance to first entry do &#123;&#125; while (index &lt; t.length &amp;&amp; (next = t[index++]) == null); &#125;&#125; 在一开始，就让expectedModCount等于modCount，而当我们调用hashMap.remove(key);时，实际上修改了modCount的值：12345678910111213141516171819202122232425262728293031323334353637383940final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; else if ((e = p.next) != null) &#123; if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) tab[index] = node.next; else p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; &#125; &#125; return null;&#125; modCount增大1，那么，当我们下一次调用var5.next()时，自然就发现modCount和expectedModCount不等了。 修改结构的正确姿势使用增强for循环，本质还是在使用iterator，那为什么大家都在推介使用iterator.remove()呢？让我们看看源代码：1234567891011public final void remove() &#123; Node&lt;K,V&gt; p = current; if (p == null) throw new IllegalStateException(); if (modCount != expectedModCount) throw new ConcurrentModificationException(); current = null; K key = p.key; removeNode(hash(key), key, null, false, false); expectedModCount = modCount;&#125; 我们发现，这个remove方法虽然也调用了removeNode，但它在最后一步再次将modCount的值赋给expectedModCount，因此保证了下一次调用next()方法是不抛错。 所以，我们要么就直接显示地使用iterator，用它的remove方法移除对象。如果你实在想用增强for循环遍历删除，那么也只能在删除一个后，立刻退出循环。但无论用哪种方法，当多个线程同时修改时，都会有出错的可能性，因为你即时保证单个线程内的modCount和expectedModCount，但这个操作并不能保证原子性。 因此，如果在多线程环境下，我更推介使用ConcurrentHashMap，因为它没有modCount和expectedModCount的概念，因此，即时你是使用增强for循环遍历删除，也不会出现问题。]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DDL-事务的一种实现]]></title>
    <url>%2F2019%2F03%2F09%2FDDL-%E4%BA%8B%E5%8A%A1%E7%9A%84%E4%B8%80%E7%A7%8D%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[上次曾和大家说过DDL-脏数据层的实现，当时的我以为使用它的最大好处就是减少IO操作。但最近在项目中使用时，发现它也可以作为事务的一种临时实现。 大家知道，在Mongodb4.0之前是不支持事务的。因此，如果你的MongoDB使用的是低于4.0的版本，那么你一般都是在业务层去弥补，而这个DDL也可以做这样的事。 DDL中，业务场景一般是一个请求过来，直接修改缓存中的数据，我们默认这一步是成功的。后台会有一个专门的线程去定期扫描所有的脏数据，如果脏数据有脏字段，那么就将脏数据入库，入库成功自然便是皆大欢喜了，但如果不成功呢？ 记得当时用MySql数据库，项目用的Spring boot + MyBatis，利用@Transactional注解，将几个数据库操作放在一个方法，这样即便出错，也可以自动回退。 但现在我们用的是MongoDB，而且我现在的版本是3.2（坑爹的阿里云服务）。数据库本身就不支持事务，这样我的DDL在将脏数据刷入数据库时，如果抛错，那么我的缓存里依旧是正确的数据，我只需要继续记录这些没有成功刷入数据库的脏数据字段，那么缓存里的数据，就依旧是刷入数据库之前的状态。而当后续请求进来后，其访问到的，也还是缓存里的正确数据。你只需要在抛错处设置报警，这样就可以即时知道问题，此时只需要专心修改这些问题，这样脏数据就会在线程下一次运行中，将数据刷入数据库中。]]></content>
      <categories>
        <category>DDL</category>
      </categories>
      <tags>
        <tag>事务</tag>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Disruptor原理探讨]]></title>
    <url>%2F2019%2F02%2F14%2FDisruptor%E5%8E%9F%E7%90%86%E6%8E%A2%E8%AE%A8%2F</url>
    <content type="text"><![CDATA[之前谈到了在我的项目里用到了Disruptor，因为对它了解不足的原因，才会引发之前的问题，因此，今天特意来探讨其原理。 为什么采用Disruptor先介绍一下我的这个服务。这个服务主要是作为游戏服务器的游戏逻辑部分，包括帧同步逻辑及其他在游戏过程中玩家产生的一些业务逻辑。 从用户量来说，现在最高峰大概有300人同时在线，游戏服务器设置1秒有30帧的数据量，因此，1秒内服务器接收到的请求量为30 * 300 = 9000。 虽然QPS并不是很高，但对于多人对抗竞技类游戏而言，低延迟十分重要，每一次客户端向服务器端的响应时间需要低于1/30秒（因为1秒需要发送30次）。针对这种情况，我需要的存储消息的容器应该具备快速生产、快速消费的特性。 那为什么当初要选择使用Disruptor作为存储客户端发来消息的容器，为什么不直接使用Java本身自带的那些队列结构呢？ 让我们看看Java里常用的线程安全的内置队列： 类 是否有界 是否加锁 底层数据结构 ArrayBlockingQueue 有界 加锁 数组 LinkedBlockingQueue 有界（2^31-1） 加锁 链表 ConcurrentLinkedQueue 无界 无锁 链表 LinkedTransferQueue 无界 无锁 链表 PriorityBlockingQueue 无界 加锁 堆 DelayQueue 无界 加锁 堆 一般来说我们并不会考虑堆，因为堆在实现带有优先级的队列更好。 从性能上来说，无锁时的QPS一般来说优于加锁，而ConcurrentLinkedQueue的无锁其实是通过原子变量进行compare and swap（以下简称为CAS，由CPU保证原子性）这种不加锁的方式来实现的。 但无锁的结构都是无界的，为了系统的稳定，我们需要防止生产者速度过快导致内存溢出，我们需要使队列有界；同时，为了减少Java的垃圾回收对系统性能的影响，会尽量选择array/heap（因为使用这两种结构，数据在内存中存储的地址连续）。 这样筛选下来，ArrayBlockingQueue可能相对而言更加合适，但它依旧存在性能问题——加锁、伪共享。 加锁上面也提到了，更好的方式是使用CAS，那伪共享又是什么呢？ 伪共享什么是共享下图是计算的基本结构。L1、L2、L3分别表示一级缓存、二级缓存、三级缓存，越靠近CPU的缓存，速度越快，容量也越小。所以L1缓存很小但很快，并且紧靠着在使用它的CPU内核；L2大一些，也慢一些，并且仍然只能被一个单独的CPU核使用；L3更大、更慢，并且被单个插槽上的所有CPU核共享；最后是主存，由全部插槽上的所有CPU核共享。如图： 当CPU执行运算的时候，它先去L1查找所需的数据、再去L2、然后是L3，如果最后这些缓存中都没有，所需的数据就要去主内存拿。走得越远，运算耗费的时间就越长。所以如果你在做一些很频繁的事，你要尽量确保数据在L1缓存中。 另外，线程之间共享一份数据的时候，需要一个线程把数据写回主存，而另一个线程访问主存中相应的数据。 缓存行Cache是由很多个cache line组成的。每个cache line通常是64字节，并且它有效地引用主内存中的一块儿地址。一个Java的long类型变量是8字节，因此在一个缓存行中可以存8个long类型的变量。 CPU每次从主存中拉取数据时，会把相邻的数据也存入同一个cache line。 在访问一个long数组的时候，如果数组中的一个值被加载到缓存中，它会自动加载另外7个。因此你能非常快的遍历这个数组。事实上，你可以非常快速的遍历在连续内存块中分配的任意数据结构。 下面的例子是测试利用cache line的特性和不利用cache line的特性的效果对比。 12345678910111213141516171819202122232425262728293031323334353637383940/** * 缓存行 * Cache是由很多个cache line组成的。每个cache line通常是64字节，并且它有效地引用主内存中的一块儿地址。一个Java的long类型变量是8字节，因此在一个缓存行中可以存8个long类型的变量。 * * CPU每次从主存中拉取数据时，会把相邻的数据也存入同一个cache line。 * * 在访问一个long数组的时候，如果数组中的一个值被加载到缓存中，它会自动加载另外7个。因此你能非常快的遍历这个数组。事实上，你可以非常快速的遍历在连续内存块中分配的任意数据结构。 */public class CacheLineEffect &#123; //考虑一般缓存行大小是64字节，一个 long 类型占8字节 static long[][] arr; public static void main(String[] args) &#123; arr = new long[1024 * 1024][]; for (int i = 0; i &lt; 1024 * 1024; i++) &#123; arr[i] = new long[8]; for (int j = 0; j &lt; 8; j++) &#123; arr[i][j] = 0L; &#125; &#125; long sum = 0L; long marked = System.currentTimeMillis(); for (int i = 0; i &lt; 1024 * 1024; i+=1) &#123; // 此时的8个数据其实已经直接在拿第1次的时候就全部拿下来了 for(int j =0; j&lt; 8;j++)&#123; sum = arr[i][j]; &#125; &#125; System.out.println(&quot;Loop times:&quot; + (System.currentTimeMillis() - marked) + &quot;ms&quot;); marked = System.currentTimeMillis(); for (int i = 0; i &lt; 8; i+=1) &#123; // 此时拿的数据其实同一列上的数据，从内存地址上来说并不连续 for(int j =0; j&lt; 1024 * 1024;j++)&#123; sum = arr[j][i]; &#125; &#125; System.out.println(&quot;Loop times:&quot; + (System.currentTimeMillis() - marked) + &quot;ms&quot;); &#125;&#125; 结果为：12Loop times:16msLoop times:72ms 速度差异还是比较明显的。 什么是伪共享ArrayBlockingQueue有三个成员变量： - takeIndex：需要被取走的元素下标 - putIndex：可被元素插入的位置的下标 - count：队列中元素的数量 这三个变量很容易放到一个缓存行中，但是之间修改没有太多的关联。所以每次修改，都会使之前缓存的数据失效，从而不能完全达到共享的效果。 如上图所示，当生产者线程put一个元素到ArrayBlockingQueue时，putIndex会修改，从而导致消费者线程的缓存中的缓存行无效，需要从主存中重新读取。 这种无法充分使用缓存行特性的现象，称为伪共享。 对于伪共享，一般的解决方案是，增大数组元素的间隔使得由不同线程存取的元素位于不同的缓存行上，以空间换时间。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101/** * 伪共享 * * 针对处在同一个缓存行内的数据，假设线程1修改了其中的一个数据a后，线程2想要读取数据a， * 因为a已经被修改了，因此缓存行失效，需要从主内存中重新读取。 * 这种无法充分使用缓存行特性的现象，称为伪共享。 * 当多线程修改互相独立的变量时，如果这些变量共享同一个缓存行，就会无意中影响彼此的性能，这就是伪共享。 */public class FalseSharing implements Runnable&#123; public final static long ITERATIONS = 500L * 1000L * 100L; private int arrayIndex = 0; private static ValueNoPadding[] longsNoPadding; private static ValuePadding[] longsPadding; private boolean padding; public FalseSharing(final int arrayIndex, boolean padding) &#123; this.arrayIndex = arrayIndex; this.padding = padding; &#125; public static void main(final String[] args) throws Exception &#123; for(int i=1;i&lt;10;i++)&#123; System.gc(); final long start = System.currentTimeMillis(); runTestNoPadding(i); System.out.println("NoPadding Thread num "+i+" duration = " + (System.currentTimeMillis() - start)); &#125; for(int i=1;i&lt;10;i++)&#123; System.gc(); final long start = System.currentTimeMillis(); runTestPadding(i); System.out.println("Padding Thread num "+i+" duration = " + (System.currentTimeMillis() - start)); &#125; &#125; private static void runTestPadding(int NUM_THREADS) throws InterruptedException &#123; Thread[] threads = new Thread[NUM_THREADS]; longsPadding = new ValuePadding[NUM_THREADS]; for (int i = 0; i &lt; longsPadding.length; i++) &#123; longsPadding[i] = new ValuePadding(); &#125; for (int i = 0; i &lt; threads.length; i++) &#123; threads[i] = new Thread(new FalseSharing(i, true)); &#125; for (Thread t : threads) &#123; t.start(); &#125; for (Thread t : threads) &#123; t.join(); &#125; &#125; private static void runTestNoPadding(int NUM_THREADS) throws InterruptedException &#123; Thread[] threads = new Thread[NUM_THREADS]; longsNoPadding = new ValueNoPadding[NUM_THREADS]; for (int i = 0; i &lt; longsNoPadding.length; i++) &#123; longsNoPadding[i] = new ValueNoPadding(); &#125; for (int i = 0; i &lt; threads.length; i++) &#123; threads[i] = new Thread(new FalseSharing(i, false)); &#125; for (Thread t : threads) &#123; t.start(); &#125; for (Thread t : threads) &#123; t.join(); &#125; &#125; public void run() &#123; long i = ITERATIONS + 1; while (0 != --i) &#123; if (padding) &#123; longsPadding[arrayIndex].value = 0L; &#125; else &#123; longsNoPadding[arrayIndex].value = 0L; &#125; &#125; &#125; public final static class ValuePadding &#123; protected long p1, p2, p3, p4, p5, p6, p7; protected volatile long value = 0L; protected long p9, p10, p11, p12, p13, p14; protected long p15; &#125; public final static class ValueNoPadding &#123; // protected long p1, p2, p3, p4, p5, p6, p7; protected volatile long value = 0L; // protected long p9, p10, p11, p12, p13, p14, p15; &#125;&#125; 结果：123456789101112131415161718NoPadding Thread num 1 duration = 394NoPadding Thread num 2 duration = 1594NoPadding Thread num 3 duration = 1702NoPadding Thread num 4 duration = 1580NoPadding Thread num 5 duration = 3217NoPadding Thread num 6 duration = 3539NoPadding Thread num 7 duration = 3269NoPadding Thread num 8 duration = 3317NoPadding Thread num 9 duration = 2800Padding Thread num 1 duration = 373Padding Thread num 2 duration = 432Padding Thread num 3 duration = 453Padding Thread num 4 duration = 490Padding Thread num 5 duration = 533Padding Thread num 6 duration = 565Padding Thread num 7 duration = 622Padding Thread num 8 duration = 685Padding Thread num 9 duration = 810 从这儿可以看出，使用了共享机制比没有使用共享机制，速度快了4倍左右。（在jdk1.8中，有专门的注解@Contended来避免伪共享，更优雅地解决问题，有兴趣地朋友可以取了解一下。） 因此，虽然ArrayBlockingQueue相对于其他队列结构而言更适合我的服务，但依旧有着性能上的缺陷，因此我选择了Disruptor。 生产者和消费者Disruptor通过环形数组结构来解决队列速度慢的问题，那具体针对生产者和消费者，它是如何保证数据读写一致性的呢？ 一个生产者写数据生产者单线程写数据的流程比较简单： 1. 申请写入m个元素； 2. 若是有m个元素可以写入，则返回最大的序列号。这儿主要判断是否会覆盖未读的元素； 3. 若是返回的正确，则生产者开始写入元素。 多个生产者多个生产者的情况下，会遇到“如何防止多个线程重复写同一个元素”的问题。Disruptor的解决方法是，每个线程获取不同的一段数组空间进行操作。这个通过CAS很容易达到。只需要在分配元素的时候，通过CAS判断一下这段空间是否已经分配出去即可。 但是会遇到一个新问题：如何防止读取的时候，读到还未写的元素。Disruptor在多个生产者的情况下，引入了一个与Ring Buffer大小相同的buffer：available Buffer。当某个位置写入成功的时候，便把availble Buffer相应的位置置位，标记为写入成功。读取的时候，会遍历available Buffer，来判断元素是否已经就绪。 下面分读数据和写数据两种情况介绍。 读数据生产者多线程写入的情况会复杂很多： 1. 申请读取到序号n； 2. 若writer cursor &gt;= n，这时仍然无法确定连续可读的最大下标。从reader cursor开始读取available Buffer，一直查到第一个不可用的元素，然后返回最大连续可读元素的位置； 3. 消费者读取元素。 如下图所示，读线程读到下标为2的元素，三个线程Writer1/Writer2/Writer3正在向RingBuffer相应位置写数据，写线程被分配到的最大元素下标是11。 读线程申请读取到下标从3到11的元素，判断writer cursor&gt;=11。然后开始读取availableBuffer，从3开始，往后读取，发现下标为7的元素没有生产成功，于是WaitFor(11)返回6。 然后，消费者读取下标从3到6共计4个元素。 写数据多个生产者写入的时候： 1. 申请写入m个元素； 2. 若是有m个元素可以写入，则返回最大的序列号。每个生产者会被分配一段独享的空间； 3. 生产者写入元素，写入元素的同时设置available Buffer里面相应的位置，以标记自己哪些位置是已经写入成功的。 如下图所示，Writer1和Writer2两个线程写入数组，都申请可写的数组空间。Writer1被分配了下标3到下表5的空间，Writer2被分配了下标6到下标9的空间。 Writer1写入下标3位置的元素，同时把available Buffer相应位置置位，标记已经写入成功，往后移一位，开始写下标4位置的元素。Writer2同样的方式。最终都写入完成。 消费者的等待策略 名称 措施 适用场景 BlockingWaitStrategy 加锁 CPU资源紧缺，吞吐量和延迟并不重要的场景 BusySpinWaitStrategy 自旋 通过不断重试，减少切换线程导致的系统调用，而降低延迟。推荐在线程绑定到固定的CPU的场景下使用 PhasedBackoffWaitStrategy 自旋 + yield + 自定义策略 CPU资源紧缺，吞吐量和延迟并不重要的场景 SleepingWaitStrategy 自旋 + yield + sleep 性能和CPU资源之间有很好的折中。延迟不均匀 TimeoutBlockingWaitStrategy 加锁，有超时限制 CPU资源紧缺，吞吐量和延迟并不重要的场景 YieldingWaitStrategy 自旋 + yield + 自旋 性能和CPU资源之间有很好的折中。延迟比较均匀 从这儿可以看出，我需要的就是低延迟，因此就采用了BusySpinWaitStrategy，它虽然占用的资源多，但延迟低，非常符合我这个服务的要求。后来测试了一下其他的策略，发现都会有一些卡顿，毕竟不是一直在运行，接受到的客户端的消息就会有延迟产生。 总结Disruptor的高性能一方面是在于它没有用很重的锁，仅仅通过CPU的CAS就保证了操作的原子性；另一方面是在于它的数据结构RingBuffer（也包括Available）和Cursor的设计巧妙；当然还有它的等待策略、线程池等等。 如果你有什么意见或者建议，欢迎在下方评论。]]></content>
      <tags>
        <tag>Disruptor</tag>
        <tag>Java</tag>
        <tag>缓存行</tag>
        <tag>RingBuffer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线上Java服务使用Disruptor导致CPU占用超过100%的问题排查]]></title>
    <url>%2F2019%2F02%2F13%2F%E6%B8%B8%E6%88%8F%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B9%8BDisruptor%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[最近看了一下部署游戏后台的服务器状况，发现我的一个Java程序其占用的CPU时长超过100%，排查后发现竟是Disruptor引起的，让我们来看看究竟为什么Disruptor会有这样的表现。 发现占用CPU时间超过100%的进程首先是在服务器上用top命令查看服务器状态，发现有一个应用程序占用的CPU时长超过100%，如图： 我根据进程号查了一下，发现是我的一个Java游戏后台服务，有一个CPU几乎被占满，因此继续排查究竟是什么代码导致了这种情况。 用top -Hp 27538将这个进程的所有线程显示出来，按照CPU占用时间排序，看到了这个结果： 27658线程占用了近乎所有的CPU时间，而且一直都是，因此查看这个进程的详细信息。 用jstack pid &gt; pid.log命令将该进程的进程快照输出到一个文件中，下载下来。 将27658转换为16进制0x6c0a后在线程快照中查询(因为线程快照中线程ID都是16进制存放，所以需要转换)：1234567&quot;disruptor-0&quot; #27 prio=5 os_prio=0 tid=0x00007fa100c58000 nid=0x6c0a runnable [0x00007fa0ae080000] java.lang.Thread.State: RUNNABLE at com.lmax.disruptor.BusySpinWaitStrategy.waitFor(BusySpinWaitStrategy.java:39) at com.lmax.disruptor.ProcessingSequenceBarrier.waitFor(ProcessingSequenceBarrier.java:56) at com.lmax.disruptor.BatchEventProcessor.processEvents(BatchEventProcessor.java:159) at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:125) at java.lang.Thread.run(Thread.java:748) 这是Disruptor的一个堆栈，为了更直观地查看线程的状态信息，可以将快照上传到专门的分析平台上。 （博主本人对于进程快照分析也是处于新手阶段，如果大家有什么建议或者意见，欢迎在下方留言。） 分析Disruptor为何会占用整个CPU根据上面快照的分析，实际是Disruptor的等待策略相关的线程所导致的，查看BusySpinWaitStrategy类，发现有相关说明：12* This strategy will use CPU resource to avoid syscalls which can introduce latency jitter. It is best* used when threads can be bound to specific CPU cores. 现在终于知道了，原来是因为这个策略就是让线程绑定了一个CPU核心，自然其CPU占用时间就超过100%了。 总结通过这一次问题的排查，不仅了解了linux系统中进程、线程的关系，也开始着手java服务的线上排查，顺便也回顾了一下之前有过接触的Disruptor。如果大家有什么建议或者意见，欢迎在下方留言]]></content>
      <tags>
        <tag>Disruptor</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java服务器获取客户端的真实IP]]></title>
    <url>%2F2018%2F11%2F12%2FJava%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%8E%B7%E5%8F%96%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9A%84%E7%9C%9F%E5%AE%9EIP%2F</url>
    <content type="text"><![CDATA[在进行一些小游戏开发时，我们经常比较关注的一个功能便是分享。针对分享，我们希望能根据各个城市或者地区，能有不同的分享文案，辨识地区的功能如果由服务器来完成的话，我们就需要知道客户端的真实IP。今天我们就来看看服务器是如何获取到客户端的真实IP的。 nginx配置首先，一个请求肯定是可以分为请求头和请求体的，而我们客户端的IP地址信息一般都是存储在请求头里的。如果你的服务器有用Nginx做负载均衡的话，你需要在你的location里面配置X-Real-IP和X-Forwarded-For请求头： 12345location ^~ /your-service/ &#123; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://localhost:60000/your-service/;&#125; X-Real-IP在《实战nginx》中，有这么一句话：1经过反向代理后，由于在客户端和web服务器之间增加了中间层，因此web服务器无法直接拿到客户端的ip，通过$remote_addr变量拿到的将是反向代理服务器的ip地址。 这句话的意思是说，当你使用了nginx反向服务器后，在web端使用request.getRemoteAddr()（本质上就是获取$remote_addr），取得的是nginx的地址，即$remote_addr变量中封装的是nginx的地址，当然是没法获得用户的真实ip的。但是，nginx是可以获得用户的真实ip的，也就是说nginx使用$remote_addr变量时获得的是用户的真实ip，如果我们想要在web端获得用户的真实ip，就必须在nginx里作一个赋值操作，即我在上面的配置：1proxy_set_header X-Real-IP $remote_addr; X-Forwarded-ForX-Forwarded-For变量，这是一个squid开发的，用于识别通过HTTP代理或负载平衡器原始IP一个连接到Web服务器的客户机地址的非rfc标准，如果有做X-Forwarded-For设置的话,每次经过proxy转发都会有记录,格式就是client1,proxy1,proxy2以逗号隔开各个地址，由于它是非rfc标准，所以默认是没有的，需要强制添加。在默认情况下经过proxy转发的请求，在后端看来远程地址都是proxy端的ip 。也就是说在默认情况下我们使用request.getAttribute(&quot;X-Forwarded-For&quot;)获取不到用户的ip，如果我们想要通过这个变量获得用户的ip，我们需要自己在nginx添加配置：1proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 意思是增加一个$proxy_add_x_forwarded_for到X-Forwarded-For里去，注意是增加，而不是覆盖，当然由于默认的X-Forwarded-For值是空的，所以我们总感觉X-Forwarded-For的值就等于$proxy_add_x_forwarded_for的值，实际上当你搭建两台nginx在不同的ip上，并且都使用了这段配置，那你会发现在web服务器端通过request.getAttribute(&quot;X-Forwarded-For&quot;)获得的将会是客户端ip和第一台nginx的ip。 那么$proxy_add_x_forwarded_for又是什么？ $proxy_add_x_forwarded_for变量包含客户端请求头中的X-Forwarded-For与$remote_addr两部分，他们之间用逗号分开。 举个例子，有一个web应用，在它之前通过了两个nginx转发，www.linuxidc.com即用户访问该web通过两台nginx。 在第一台nginx中,使用： 1proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 现在的$proxy_add_x_forwarded_for变量的X-Forwarded-For部分是空的，所以只有$remote_addr，而$remote_addr的值是用户的ip，于是赋值以后，X-Forwarded-For变量的值就是用户的真实的ip地址了。 到了第二台nginx，使用：1proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 现在的$proxy_add_x_forwarded_for变量，X-Forwarded-For部分包含的是用户的真实ip，$remote_addr部分的值是上一台nginx的ip地址，于是通过这个赋值以后现在的X-Forwarded-For的值就变成了“用户的真实ip，第一台nginx的ip”，这样就清楚了吧。 服务器获取真实IP代码为： 12345678910111213141516171819202122232425262728293031323334public static String getIpAddress(HttpServletRequest request) &#123; String Xip = request.getHeader("X-Real-IP"); String XFor = request.getHeader("X-Forwarded-For"); if (!Strings.isNullOrEmpty(XFor) &amp;&amp; !"unKnown".equalsIgnoreCase(XFor)) &#123; //多次反向代理后会有多个ip值，第一个ip才是真实ip int index = XFor.indexOf(","); if (index != -1) &#123; return XFor.substring(0, index); &#125; else &#123; return XFor; &#125; &#125; XFor = Xip; if (!Strings.isNullOrEmpty(XFor) &amp;&amp; !"unKnown".equalsIgnoreCase(XFor)) &#123; return XFor; &#125; if (Strings.nullToEmpty(XFor).trim().isEmpty() || "unknown".equalsIgnoreCase(XFor)) &#123; XFor = request.getHeader("Proxy-Client-IP"); &#125; if (Strings.nullToEmpty(XFor).trim().isEmpty() || "unknown".equalsIgnoreCase(XFor)) &#123; XFor = request.getHeader("WL-Proxy-Client-IP"); &#125; if (Strings.nullToEmpty(XFor).trim().isEmpty() || "unknown".equalsIgnoreCase(XFor)) &#123; XFor = request.getHeader("HTTP_CLIENT_IP"); &#125; if (Strings.nullToEmpty(XFor).trim().isEmpty() || "unknown".equalsIgnoreCase(XFor)) &#123; XFor = request.getHeader("HTTP_X_FORWARDED_FOR"); &#125; if (Strings.nullToEmpty(XFor).trim().isEmpty() || "unknown".equalsIgnoreCase(XFor)) &#123; XFor = request.getRemoteAddr(); &#125; return XFor;&#125; 我们来看看各个请求头的含义 X-Real-IPnginx代理一般会加上此请求头。 X-FORWARDED-FOR这是一个Squid开发的字段，只有在通过了HTTP代理或者负载均衡服务器时才会添加该项。 Proxy-Client-IP 和 WL-Proxy-Client-IP这个一般是经过apache http服务器的请求才会有，用apache http做代理时一般会加上Proxy-Client-IP请求头，而WL-Proxy-Client-IP是它的weblogic插件加上的头。 HTTP_CLIENT_IP有些代理服务器会加上此请求头。在网上搜了一下，有一个说法是：123456789101112这是普通的 http header，伪造起来很容易，不要轻易信任用户输入。 curl -H &apos;client-ip: 8.8.8.8&apos; lidian.club/phpinfo.php | grep _SERVER 你就能看到 _SERVER[&quot;HTTP_CLIENT_IP&quot;] 了。 client-ip 和 client-host 是在 NAPT 还没普及的年代，企业内网假设的 http 透明代理，传给服务器的 header，只有极少数厂家用过，从来不是标准，也从来没成为过事实标准。 （大家最熟悉的事实标准就是 x-forwarded-for） 后来出现的 web proxy 也没见用过这个 header。 TCP/IP Illustrated Vol 3 没有讲过这个 header，网上的传言不可信。 可考的最早痕迹出现在2005年，日本一部 Perl/CGI 秘籍（9784798010779，270页）通过 client-ip 与 via 两个 header 屏蔽代理用户访问。 HTTP_X_FORWARDED_FOR简称XFF头，它代表客户端，也就是HTTP的请求端真实的IP，只有在通过了HTTP 代理(比如APACHE代理)或者负载均衡服务器时才会添加该项。它不是RFC中定义的标准请求头信息，在squid缓存代理服务器开发文档中可以找到该项的详细介绍。如果有该条信息, 说明您使用了代理服务器，地址就是后面的数值。可以伪造。标准格式如下：X-Forwarded-For: client1, proxy1, proxy2 总结以上就是我在处理客户端真实IP的方法，如果你有什么意见或者建议，可以在下方留言。]]></content>
      <tags>
        <tag>Java</tag>
        <tag>nginx</tag>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java中List的sort源码解读]]></title>
    <url>%2F2018%2F11%2F02%2Fjava%E4%B8%ADList%E7%9A%84sort%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[最近看了一些排序相关的文章，因此比较好奇，Java中的排序是如何做的。本片文章介绍的是JDK1.8，List中的sort方法。 先来看看List中的sort是怎么写的：12345678910@SuppressWarnings(&#123;"unchecked", "rawtypes"&#125;)default void sort(Comparator&lt;? super E&gt; c) &#123; Object[] a = this.toArray(); Arrays.sort(a, (Comparator) c); ListIterator&lt;E&gt; i = this.listIterator(); for (Object e : a) &#123; i.next(); i.set((E) e); &#125;&#125; 首先，你需要传入一个比较器作为参数，这个好理解，毕竟你肯定要定一个比较标准。然后就是将list转换成一个数组，再对这个数组进行排序，排序完之后，再利用iterator重新改变list。 接着，我们再来看看Arrays.sort：123456789101112131415161718192021222324public static &lt;T&gt; void sort(T[] a, Comparator&lt;? super T&gt; c) &#123; if (c == null) &#123; sort(a); &#125; else &#123; if (LegacyMergeSort.userRequested) legacyMergeSort(a, c); else TimSort.sort(a, 0, a.length, c, null, 0, 0); &#125;&#125;public static void sort(Object[] a) &#123; if (LegacyMergeSort.userRequested) legacyMergeSort(a); else ComparableTimSort.sort(a, 0, a.length, null, 0, 0);&#125;static final class LegacyMergeSort &#123; private static final boolean userRequested = java.security.AccessController.doPrivileged( new sun.security.action.GetBooleanAction( "java.util.Arrays.useLegacyMergeSort")).booleanValue();&#125; 这样可以看出，其实排序的核心就是TimSort，LegacyMergeSort大致意思是表明如果版本很旧的话，就用这个，新版本是不会采用这种排序方式的。 我们再来看看TimSort的实现：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849private static final int MIN_MERGE = 32;static &lt;T&gt; void sort(T[] a, int lo, int hi, Comparator&lt;? super T&gt; c, T[] work, int workBase, int workLen) &#123; assert c != null &amp;&amp; a != null &amp;&amp; lo &gt;= 0 &amp;&amp; lo &lt;= hi &amp;&amp; hi &lt;= a.length; int nRemaining = hi - lo; if (nRemaining &lt; 2) return; // Arrays of size 0 and 1 are always sorted // If array is small, do a "mini-TimSort" with no merges if (nRemaining &lt; MIN_MERGE) &#123; // 获得最长的递增序列 int initRunLen = countRunAndMakeAscending(a, lo, hi, c); binarySort(a, lo, hi, lo + initRunLen, c); return; &#125; /** * March over the array once, left to right, finding natural runs, * extending short natural runs to minRun elements, and merging runs * to maintain stack invariant. */ TimSort&lt;T&gt; ts = new TimSort&lt;&gt;(a, c, work, workBase, workLen); int minRun = minRunLength(nRemaining); do &#123; // Identify next run int runLen = countRunAndMakeAscending(a, lo, hi, c); // If run is short, extend to min(minRun, nRemaining) if (runLen &lt; minRun) &#123; int force = nRemaining &lt;= minRun ? nRemaining : minRun; binarySort(a, lo, lo + force, lo + runLen, c); runLen = force; &#125; // Push run onto pending-run stack, and maybe merge ts.pushRun(lo, runLen); ts.mergeCollapse(); // Advance to find next run lo += runLen; nRemaining -= runLen; &#125; while (nRemaining != 0); // Merge all remaining runs to complete sort assert lo == hi; ts.mergeForceCollapse(); assert ts.stackSize == 1;&#125; 如果小于2个，代表不再不需要排序；如果小于32个，则采用优化的二分排序。怎么优化的呢？首先获得最长的递增序列： 123456789101112131415161718192021private static &lt;T&gt; int countRunAndMakeAscending(T[] a, int lo, int hi, Comparator&lt;? super T&gt; c) &#123; assert lo &lt; hi; int runHi = lo + 1; if (runHi == hi) return 1; // Find end of run, and reverse range if descending if (c.compare(a[runHi++], a[lo]) &lt; 0) &#123; // Descending // 一开始是递减序列，就找出最长递减序列的最后一个下标 while (runHi &lt; hi &amp;&amp; c.compare(a[runHi], a[runHi - 1]) &lt; 0) runHi++; // 逆转前面的递减序列 reverseRange(a, lo, runHi); &#125; else &#123; // Ascending while (runHi &lt; hi &amp;&amp; c.compare(a[runHi], a[runHi - 1]) &gt;= 0) runHi++; &#125; return runHi - lo;&#125; 接着进行二分排序：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748private static &lt;T&gt; void binarySort(T[] a, int lo, int hi, int start, Comparator&lt;? super T&gt; c) &#123; assert lo &lt;= start &amp;&amp; start &lt;= hi; if (start == lo) start++; for ( ; start &lt; hi; start++) &#123; T pivot = a[start]; // Set left (and right) to the index where a[start] (pivot) belongs int left = lo; int right = start; assert left &lt;= right; /* * Invariants: * pivot &gt;= all in [lo, left). * pivot &lt; all in [right, start). */ // start位置是递增序列后的第一个数的位置 // 从前面的递增序列中找出start位置的数应该处于的位置 while (left &lt; right) &#123; // &gt;&gt;&gt; 无符号右移 int mid = (left + right) &gt;&gt;&gt; 1; if (c.compare(pivot, a[mid]) &lt; 0) right = mid; else left = mid + 1; &#125; assert left == right; /* * The invariants still hold: pivot &gt;= all in [lo, left) and * pivot &lt; all in [left, start), so pivot belongs at left. Note * that if there are elements equal to pivot, left points to the * first slot after them -- that's why this sort is stable. * Slide elements over to make room for pivot. */ int n = start - left; // The number of elements to move // Switch is just an optimization for arraycopy in default case // 比pivot大的数往后移动一位 switch (n) &#123; case 2: a[left + 2] = a[left + 1]; case 1: a[left + 1] = a[left]; break; default: System.arraycopy(a, left, a, left + 1, n); &#125; a[left] = pivot; &#125;&#125; 好了，待排序数量小于32个的讲完了，现在来说说大于等于32个情况。首先，获得一个叫minRun的东西，这是个啥含义呢：1234567891011int minRun = minRunLength(nRemaining);private static int minRunLength(int n) &#123; assert n &gt;= 0; int r = 0; // Becomes 1 if any 1 bits are shifted off while (n &gt;= MIN_MERGE) &#123; // 这里我没搞懂的是为什么不直接将(n &amp; 1)赋值给r，而要做一次逻辑或。 r |= (n &amp; 1); n &gt;&gt;= 1; &#125; return n + r;&#125; 各种位运算符，MIN_MERGE默认为32，如果n小于此值，那么返回n本身。否则会将n不断地右移，直到小于MIN_MERGE，同时记录一个r值，r代表最后一次移位n时，n最低位是0还是1。其实看注释比较容易理解： 1234Returns the minimum acceptable run length for an array of the specified length. Natural runs shorter than this will be extended with binarySort.Roughly speaking, the computation is: If n &lt; MIN_MERGE, return n (it&apos;s too small to bother with fancy stuff).Else if n is an exact power of 2, return MIN_MERGE/2.Else return an int k, MIN_MERGE/2 &lt;= k &lt;= MIN_MERGE, such that n/k is close to, but strictly less than, an exact power of 2. For the rationale, see listsort.txt. 返回结果其实就是用于接下来的合并排序中。 接下来就是一个while循环1234567891011121314151617181920212223do &#123; // Identify next run // 获得一个最长递增序列 int runLen = countRunAndMakeAscending(a, lo, hi, c); // If run is short, extend to min(minRun, nRemaining) // 如果最长递增序列 if (runLen &lt; minRun) &#123; int force = nRemaining &lt;= minRun ? nRemaining : minRun; binarySort(a, lo, lo + force, lo + runLen, c); runLen = force; &#125; // Push run onto pending-run stack, and maybe merge // lo——runLen为将要被归并的范围 ts.pushRun(lo, runLen); // 归并 ts.mergeCollapse(); // Advance to find next run lo += runLen; nRemaining -= runLen;&#125; while (nRemaining != 0); 这样，假设你的每次归并排序的两个序列为r1和r2，r1肯定是有序的，r2也已经被排成递增序列了，因此这样的归并排序就比较特殊了。 为什么要用归并排序呢，因为归并排序的时间复杂度永远为O(nlogn)，空间复杂度为O(n)，以空间换取时间。 好了，以上就是针对Java中的排序做的一次总结，但具体的归并代码还没有分析，其实我自己也没有完全研究透，为什么minRun的取值是这样的，这也和TimSort中的stackLen有关，有兴趣的小伙伴可以在下方留言，我们可以一起探讨。]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DDL-脏数据层的实现]]></title>
    <url>%2F2018%2F10%2F31%2FDDL-%E8%84%8F%E6%95%B0%E6%8D%AE%E5%B1%82%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[在我们的项目中，经常会有一些数据会涉及到频繁更改。如果每次都从数据库中读取再修改，这样不仅浪费时间，而且还更加危险。那此时我们究竟该如何解决这个问题呢？此时，DDL(脏数据层)就出现了。 首先说一下为什么操作不能保证原子性就会危险，因为这时就很有可能出现同时修改的情况，最终的结果极有可能并不是你所希望的（除非这些操作都是幂等性，但这种情况应该比较少）。如果是利用数据库中的锁，一来我在项目中用的比较少，二来也增加了维护难度。当然，有人说可以利用CAS，那针对一些复杂的情况（比如类里面属性的修改会有一些相关性，你的一次更改需要涉及几个属性等），可能你还是需要单独设计一套系统，而且还会有经典的ABA问题。如果你是利用CAS解决的，希望能够在下方评论区告知，就当互相学习。 那现在来说说DDL层具体是什么。DDL全称是Dirty Data Layer，即脏数据层。针对那些在系统运行经常会更改的domain类，我们将其再做一次封装，组成一个类似map的形式。单独由一组线程来管理这些map，每当有数据改动时，我们就往这个map中添加内容，而我们的线程则定期向数据库中写入内容。这样做的好处，首先是让你的每一次操作都没有IO的参与，提高了相应速度，而且定时提交意味着你可以把原本的几次提交变成为1次，减少了和数据库的交互。当然，缺点也是存在的，如果你的系统是分布式，那么你的这个DDL层的实现可能就没有那么方便，因为这些数据你可能需要存储在类似Redis这种共享缓存中，因此每次的拿和取就需要封装一下（这个应该算是小问题，因为原本就算你用的是本地缓存，所有操作依旧是需要封装的，只不过你的IO消耗由原本的数据库变成了共享缓存）。接下来，我就针对本地缓存的情况来具体实现一个DDL。 定义操作这是我定义出的一些操作：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118public interface IDirtyEntity &#123; //region manage content /** * 获取entity的内容。 */ Object getContent(); /** * 获取entity的内容。 获取的内容是复制的对象，属性值是调用该方法时的属性值。 */ Object copyContent(); //endregion //region persisting flag /** * 是否正在进行持久化 */ boolean isPersisting(); /** * 设置正在持久化标志 */ void setPersistingFlag(); /** * 清除正在持久化标志 */ void clearPersistingFlag(); //endregion //region persist state /** * 设置为脏数据状态 */ void setDirtyState(); /** * 清除脏数据状态 */ void clearDirtyState(); /** * 当前持久化状态。 * * @see PersistState */ PersistState currentPersistState(); //endregion //region get/set field /** * 获取属性值。 */ Object getField(String fieldName); /** * 设置属性值。 */ void setField(String fieldName, Object value); /** * 设置多个属性的值。 */ void setFields(List&lt;EntityField&gt; fields); /** * 增加int类型属性的值。 */ void addInt(String fieldName, int delta); /** * 增加long类型属性的值。 */ void addLong(String fieldName, long delta); //endregion //region manage dirty field /** * 标记脏数据字段 */ void addDirtyField(String fieldName); /** * 获取修改过的属性。 */ List&lt;EntityField&gt; getAndClearDirtyFields(); //endregion //region wrapper implement /** * 返回id的属性名。 */ String getIdFieldName(); /** * 返回id */ String getId(); /** * 返回DATA的class */ Class getDataClass(); //endregion&#125; 分类DDL解决的是数据频繁更改的问题，其实这里的更改说的并不准确，并不仅仅只是update，还有insert。用过mongodb的应该清楚有一种叫upsert的操作，就是找到就修改，找不到就添加。我们这里就需要将我们的数据分成两类：Detachable(可拆分的)、Nondetachable(不可拆分的)。 可拆分的，就意味着你针对这个数据的修改最小可以精确到其中的一个属性，项目中大多数都属于这种情况。 不可拆分的，即每次都是以一个整体添加，比如一次交易，每次添加都是一个整体，不可能说你先提交买方，再提交卖方，后面还会修改买方。这种类型大多都是一条记录，整体存入数据库。 因此，我们来定义一下这两种结构：可拆分的类型：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183import com.google.common.base.Preconditions;import com.google.common.base.Strings;import java.util.List;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.cglib.beans.BeanCopier;import org.springframework.cglib.beans.BeanMap;public abstract class DetachableDirtyEntityAdapter implements IDirtyEntity &#123; private static final Logger log = LoggerFactory.getLogger(DetachableDirtyEntityAdapter.class); /** * 数据属性的map引用 */ private BeanMap beanMap; private final BeanCopier beanCopier; public DetachableDirtyEntityAdapter(Object content, BeanCopier beanCopier) &#123; Preconditions.checkNotNull(content); Preconditions.checkNotNull(beanCopier); this.content = newEmptyContentInstance(); this.beanCopier = beanCopier; this.beanCopier.copy(content, this.content, null); this.beanMap = BeanMap.create(this.content); &#125; //region manage content /** * 数据的内容。 */ private Object content; @Override public Object getContent() &#123; return content; &#125; private Object newEmptyContentInstance() &#123; Class cls = getDataClass(); try &#123; return cls.newInstance(); &#125; catch (Exception e) &#123; log.error("initiate &#123;&#125; failed: &#123;&#125;", cls.getSimpleName(), e.getMessage()); return null; &#125; &#125; @Override public synchronized Object copyContent() &#123; Object copy = newEmptyContentInstance(); beanCopier.copy(this.content, copy, null); return copy; &#125; //endregion //region persisting flag private volatile boolean persisting = false; @Override public boolean isPersisting() &#123; return persisting; &#125; @Override public void setPersistingFlag() &#123; this.persisting = true; &#125; @Override public void clearPersistingFlag() &#123; this.persisting = false; &#125; //endregion //region persist state @Override public void setDirtyState() &#123; throw new UnsupportedOperationException(); &#125; @Override public void clearDirtyState() &#123; throw new UnsupportedOperationException(); &#125; @Override public synchronized PersistState currentPersistState() &#123; int dirtySize = dirtyFieldNames.size(); if (dirtySize == 0) &#123; return PersistState.PERSISTED; &#125; else &#123; return PersistState.DIRTY; &#125; &#125; //endregion //region get/set field @Override public synchronized Object getField(String fieldName) &#123; Preconditions.checkArgument(!Strings.isNullOrEmpty(fieldName)); return beanMap.get(fieldName); &#125; @Override public synchronized void setField(String fieldName, Object value) &#123; Preconditions.checkArgument(!Strings.isNullOrEmpty(fieldName)); beanMap.put(fieldName, value); dirtyFieldNames.add(fieldName); &#125; @Override public synchronized void setFields(List&lt;EntityField&gt; fields) &#123; Preconditions.checkNotNull(fields); for (EntityField f : fields) &#123; beanMap.put(f.getName(), f.getValue()); dirtyFieldNames.add(f.getName()); &#125; &#125; @Override public synchronized void addInt(String fieldName, int delta) &#123; Preconditions.checkArgument(!Strings.isNullOrEmpty(fieldName)); int origin = (int) beanMap.get(fieldName); beanMap.put(fieldName, origin + delta); dirtyFieldNames.add(fieldName); &#125; @Override public synchronized void addLong(String fieldName, long delta) &#123; Preconditions.checkArgument(!Strings.isNullOrEmpty(fieldName)); long origin = (long) beanMap.get(fieldName); beanMap.put(fieldName, origin + delta); dirtyFieldNames.add(fieldName); &#125; //endregion //region manage dirty fields /** * 当前entity的包含脏数据的属性名列表。 */ private final HashSet&lt;String&gt; dirtyFieldNames = new HashSet&lt;&gt;(16); @Override public void addDirtyField(String fieldName) &#123; Preconditions.checkArgument(!Strings.isNullOrEmpty(fieldName)); dirtyFieldNames.add(fieldName); &#125; @Override public synchronized List&lt;EntityField&gt; getAndClearDirtyFields() &#123; ArrayList&lt;EntityField&gt; list = new ArrayList&lt;&gt;(); for (String f : dirtyFieldNames) &#123; list.add(new EntityField(f, beanMap.get(f))); &#125; // 清空dirtyFieldNames, 记录上一次持久化的事件 dirtyFieldNames.clear(); return list; &#125; //endregion&#125; 不可拆分的类型：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161import com.google.common.base.Preconditions;import com.google.common.base.Strings;import java.util.ArrayList;import java.util.HashSet;import java.util.List;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.cglib.beans.BeanCopier;import org.springframework.cglib.beans.BeanMap;public abstract class NonDetachableDirtyEntityAdapter implements IDirtyEntity &#123; private static final Logger log = LoggerFactory.getLogger(NonDetachableDirtyEntityAdapter.class); /** * 数据属性的map引用 */ private BeanMap beanMap; private final BeanCopier beanCopier; public NonDetachableDirtyEntityAdapter(Object content, BeanCopier beanCopier) &#123; Preconditions.checkNotNull(content); Preconditions.checkNotNull(beanCopier); this.content = newEmptyContentInstance(); this.beanCopier = beanCopier; this.beanCopier.copy(content, this.content, null); this.beanMap = BeanMap.create(this.content); &#125; //region manage content /** * 数据的内容。 */ private Object content; @Override public Object getContent() &#123; return content; &#125; private Object newEmptyContentInstance() &#123; Class cls = getDataClass(); try &#123; return cls.newInstance(); &#125; catch (Exception e) &#123; log.error("initiate &#123;&#125; failed: &#123;&#125;", cls.getSimpleName(), e.getMessage()); return null; &#125; &#125; @Override public synchronized Object copyContent() &#123; Object copy = newEmptyContentInstance(); beanCopier.copy(this.content, copy, null); return copy; &#125; //endregion //region persisting flag private volatile boolean persisting = false; @Override public boolean isPersisting() &#123; return persisting; &#125; @Override public void setPersistingFlag() &#123; this.persisting = true; &#125; @Override public void clearPersistingFlag() &#123; this.persisting = false; &#125; //endregion //region persist state private volatile PersistState persistState = PersistState.DIRTY; @Override public void setDirtyState() &#123; persistState = PersistState.DIRTY; &#125; @Override public void clearDirtyState() &#123; persistState = PersistState.PERSISTED; &#125; @Override public PersistState currentPersistState() &#123; return persistState; &#125; //endregion //region get/set field @Override public synchronized Object getField(String fieldName) &#123; Preconditions.checkArgument(!Strings.isNullOrEmpty(fieldName)); return beanMap.get(fieldName); &#125; @Override public synchronized void setField(String fieldName, Object value) &#123; Preconditions.checkArgument(!Strings.isNullOrEmpty(fieldName)); beanMap.put(fieldName, value); &#125; @Override public synchronized void setFields(List&lt;EntityField&gt; fields) &#123; Preconditions.checkNotNull(fields); for (EntityField f : fields) &#123; beanMap.put(f.getName(), f.getValue()); &#125; &#125; @Override public synchronized void addInt(String fieldName, int delta) &#123; Preconditions.checkArgument(!Strings.isNullOrEmpty(fieldName)); int origin = (int) beanMap.get(fieldName); beanMap.put(fieldName, origin + delta); &#125; @Override public synchronized void addLong(String fieldName, long delta) &#123; Preconditions.checkArgument(!Strings.isNullOrEmpty(fieldName)); long origin = (long) beanMap.get(fieldName); beanMap.put(fieldName, origin + delta); &#125; //endregion //region manage dirty fields @Override public void addDirtyField(String fieldName) &#123; throw new UnsupportedOperationException(); &#125; @Override public synchronized List&lt;EntityField&gt; getAndClearDirtyFields() &#123; throw new UnsupportedOperationException(); &#125; //endregion&#125; 两种类型最大的不同在于真正往数据库中存储时，前者是可以单独字段存储，后者是整体存储，因此最后和DirtyField相关的操作便需要注意，NondetachableDirtyEntityAdapter不需要记录DirtyFields。 针对原本类中属性的复制和存储，我这儿用的是spring提供的BeanCopier，如果你有什么更高效的工具，欢迎在下方留言。（我一直在找一种深度克隆高效的组件，试过kryo，但只有在实现序列化接口的前提下，其效率才能和正常的set/get大概相差10倍，如果有好的组件，希望一并告知）。 以上就是DDL的准备工作，其实后面的工作就是将具体的类做一个封装，再封装针对该类的所有操作，然后另写一个线程组执行往数据库的写入操作。这个工作其实针对各个项目都有其特殊的地方，LZ在这儿就不具体展示了，有兴趣的话大家可以在下方留言。]]></content>
      <categories>
        <category>DDL</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[log4j日志不输出的问题]]></title>
    <url>%2F2018%2F10%2F24%2Flog4j%E6%97%A5%E5%BF%97%E4%B8%8D%E8%BE%93%E5%87%BA%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[今天服务器上报错，想先去看一下日志进行排查，结果发现日志很久都没有输出过了。从上午排查到下午，刚刚解决，因此记录一下，但现在也只是知其然，并不知其所以然，所以如果大家有什么想法请在下方评论。 先说一下环境，服务器是linux，项目是运行在tomcat下的Spring项目，日志用的是log4j。 首先，从10月13号开始便没有新的日志文件了。假设日志名为log.txt（如果你设置了DailyRollingFileAppender，那么你当天的日志文件就是log.txt），先备份该文件到其他目录下，然后删除该文件，重新启动tomcat。这是为了确认你的log4j配置是否有问题，因为这是最容易出错的地方。很遗憾，我不是这里出的问题，因为项目重启后，日志文件又重新生成了，但很奇怪的是，日志文件是空的，其大小为0. 感觉自己碰上了很神奇的问题，因此我在自己的本地进行调试，启动项目后发现，正常的项目启动日志是有的：115:13:48:0253 INFO [RMI TCP Connection(3)-127.0.0.1] -Root WebApplicationContext: initialization completed in 18479 ms 但我自己的一些日志输出是不显示的，比如：12private static final Logger log = LoggerFactory.getLogger(MyDomain.class);log.info("show info log"); show info log这句话就不打印，现在证明，我的日志配置没有问题，服务器也找到了我的日志文件，但应该是我自己的Logger是不对应正确的日志输出的，因为我的console(控制台)有显示。 接下来，我就是开始看源码了。先是LoggerFactory.getLogger(Class&lt;?&gt; clazz)方法：123456789101112public static Logger getLogger(Class&lt;?&gt; clazz) &#123; Logger logger = getLogger(clazz.getName()); if (DETECT_LOGGER_NAME_MISMATCH) &#123; Class&lt;?&gt; autoComputedCallingClass = Util.getCallingClass(); if (autoComputedCallingClass != null &amp;&amp; nonMatchingClasses(clazz, autoComputedCallingClass)) &#123; Util.report(String.format("Detected logger name mismatch. Given name: \"%s\"; computed name: \"%s\".", logger.getName(), autoComputedCallingClass.getName())); Util.report("See " + LOGGER_NAME_MISMATCH_URL + " for an explanation"); &#125; &#125; return logger;&#125; 好吧，没什么用，看不出我的logger变成了，继续看getLogger(String name)方法：1234public static Logger getLogger(String name) &#123; ILoggerFactory iLoggerFactory = getILoggerFactory(); return iLoggerFactory.getLogger(name);&#125; 这时我在return iLoggerFactory.getLogger(name);这行打了断点，我看到了这样的东西： 为什么我的iLoggerFactory是用的logback中的实现？其实也是怪我自己大意，我其实依赖了一个基于Spring Boot的项目(虽然我只是用了里面的一些domain类，但因为设计不当，还没有把这些domain类单独提成一个_项目)，而Spring Boot中一般默认就依赖的logback。通过gradle查看项目的依赖树，也证实了我的这一猜想(./gradlew 子项目名称:dependencies):1234567891011| +--- org.springframework.boot:spring-boot-starter-web:2.0.2.RELEASE| | +--- org.springframework.boot:spring-boot-starter:2.0.2.RELEASE| | | +--- org.springframework.boot:spring-boot:2.0.2.RELEASE| | | | +--- org.springframework:spring-core:5.0.6.RELEASE (*)| | | | \--- org.springframework:spring-context:5.0.6.RELEASE (*)| | | +--- org.springframework.boot:spring-boot-autoconfigure:2.0.2.RELEASE| | | | \--- org.springframework.boot:spring-boot:2.0.2.RELEASE (*)| | | +--- org.springframework.boot:spring-boot-starter-logging:2.0.2.RELEASE| | | | +--- ch.qos.logback:logback-classic:1.2.3| | | | | +--- ch.qos.logback:logback-core:1.2.3| | | | | \--- org.slf4j:slf4j-api:1.7.25 接下来就好办了，你排除掉ch.qos.logback的依赖就可以了，在你的build.gradle中增加：123configurations &#123; compile.exclude group: &apos;ch.qos.logback&apos;&#125; 这个时候你再重新调试一下看看： 完美，现在是log4j中的实现，得到了我想要的操作。当然了，既然我知道之前项目中的slf4j是logback实现了，那么我自然也可以换成logback的配置，但这就需要我将项目换成用Spring Boot启动，这个改动有点大，如果以后有必要的话，我再将这个exclude删除，换成Spring Boot的形式。 这次Spring Boot帮我们默认启用的是logback，那么有没有什么简单方法可以知道呢？如果你的项目出现了以下的日志输出，说明你的项目当前有不止一个SLF4J的实现组件：12345SLF4J: Class path contains multiple SLF4J bindings.SLF4J: Found binding in [jar:file:/project.war/WEB-INF/lib/logback-classic-1.2.3.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: Found binding in [jar:file:/project.war/WEB-INF/lib/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.SLF4J: Actual binding is of type [ch.qos.logback.classic.util.ContextSelectorStaticBinder] 因为在org.slf4j.LoggerFactory的bind方法中有关于这方面的输出：123456789101112131415161718192021222324252627282930313233343536373839404142434445private final static void bind() &#123; try &#123; Set&lt;URL&gt; staticLoggerBinderPathSet = null; // skip check under android, see also // http://jira.qos.ch/browse/SLF4J-328 if (!isAndroid()) &#123; // 查找你的当前项目有几个slf4j的实现 staticLoggerBinderPathSet = findPossibleStaticLoggerBinderPathSet(); // 如果多余一个就打印 reportMultipleBindingAmbiguity(staticLoggerBinderPathSet); &#125; // the next line does the binding // 这个是具体选了哪一个实现（重点关注） StaticLoggerBinder.getSingleton(); INITIALIZATION_STATE = SUCCESSFUL_INITIALIZATION; reportActualBinding(staticLoggerBinderPathSet); fixSubstituteLoggers(); replayEvents(); // release all resources in SUBST_FACTORY SUBST_FACTORY.clear(); &#125; catch (NoClassDefFoundError ncde) &#123; String msg = ncde.getMessage(); if (messageContainsOrgSlf4jImplStaticLoggerBinder(msg)) &#123; INITIALIZATION_STATE = NOP_FALLBACK_INITIALIZATION; Util.report("Failed to load class \"org.slf4j.impl.StaticLoggerBinder\"."); Util.report("Defaulting to no-operation (NOP) logger implementation"); Util.report("See " + NO_STATICLOGGERBINDER_URL + " for further details."); &#125; else &#123; failedBinding(ncde); throw ncde; &#125; &#125; catch (java.lang.NoSuchMethodError nsme) &#123; String msg = nsme.getMessage(); if (msg != null &amp;&amp; msg.contains("org.slf4j.impl.StaticLoggerBinder.getSingleton()")) &#123; INITIALIZATION_STATE = FAILED_INITIALIZATION; Util.report("slf4j-api 1.6.x (or later) is incompatible with this binding."); Util.report("Your binding is version 1.5.5 or earlier."); Util.report("Upgrade your binding to version 1.6.x."); &#125; throw nsme; &#125; catch (Exception e) &#123; failedBinding(e); throw new IllegalStateException("Unexpected initialization failure", e); &#125;&#125; 特别要注意的是StaticLoggerBinder.getSingleton();这行代码，StaticLoggerBinder在logback-classic和slf4j-log4j12这两个jar包各有一个，因此，Spring boot是自动选择logback-classic（虽然我在本地运行的时候还是默认进入的slf4j-log4j12，但是会提醒我Source code does not match the bytecode，因此我判断依旧进的是logback-classic），所以只要把logback给exclude掉，就解决了这个问题。 现在看问题，更加关注源代码，因为这可以让我们更加快速定位问题，并且也能据此大致猜出其解决方案。希望大家能一起看看源代码，如果你有什么发现，可以在下方留言，我将和你一起讨论。]]></content>
      <tags>
        <tag>log4j</tag>
        <tag>Spring Boot</tag>
        <tag>logback</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty 心跳相关(1)]]></title>
    <url>%2F2018%2F10%2F23%2FNetty-%E5%BF%83%E8%B7%B3%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[无论是B/S还是C/S架构，如果你用的是长连接，那么心跳是必不可少的。Netty提供了对心跳机制的天然支持，今天结合例子特地学习了一下。 首先，我们来设想一下何时需要发送心跳。假设你做的是一款棋牌类小游戏，那么当玩家登陆游戏后肯定是先进入大厅，再选择一张合适的桌子正式开始游戏。此时玩家的客户端与服务器建立的这一次session（会话）应该是长久保持着，如果服务器端保存着大量的session，那么整个服务器就会越来越卡，最终整个服务都会挂掉。 为了预防这种情况，我们需要清理掉一些已经不用的或者理论上不会再用的session，比如：在手机上，如果我们在游戏中，突然接到一个电话或者退回桌面，这个时候我们的游戏客户端理论上就不会再主动向我们发送任何消息。这时候，心跳就派上用场了。 心跳，是为了证明自己还活着。因此，这里的心跳，说白了就是客户端向服务器端发送一次请求，服务器端相应，这样客户端就知道了服务器端是alive(活着的)；服务器端向客户端发送一次心跳，客户端相应，这样服务器端就知道了客户端是alive。 知道了心跳的大致概念，那现在我们就需要知道Netty中是如何实现心跳，这就引出了两个类：IdleStateHandler、ChannelInboundHandlerAdapter IdleStateHandler大致作用 当连接的空闲时间（无论是读或者是写）太长时，都会触发IdleStateEvent事件。你可以写一个类继承ChannelInboundHandlerAdapter，重写userEventTriggered方法，来处理这类空闲事件。 知道了其大致作用，那么接下来就看看我们到底该如何使用了。 IdleStateHandler有3个构造方法，主要针对这4个属性，分别是：1234private final boolean observeOutput;// 是否考虑出站时较慢的情况。默认值是false（一般不考虑）。private final long readerIdleTimeNanos; // 读事件空闲时间，0 代表禁用事件private final long writerIdleTimeNanos;// 写事件空闲时间，0 代表禁用事件private final long allIdleTimeNanos; //读或写空闲时间，0 代表禁用事件 上面的三个时间，默认是秒，你也可以在构造的时候指定。 当你在pipeline中加入了该handler之后： pipeline.addLast(new IdleStateHandler(30, 90, 0)); // 这个代表只考虑读空闲30秒或写空闲90秒的情况 则会先调用handlerAdded方法：1234567891011@Overridepublic void handlerAdded(ChannelHandlerContext ctx) throws Exception &#123; if (ctx.channel().isActive() &amp;&amp; ctx.channel().isRegistered()) &#123; // channelActive() event has been fired already, which means this.channelActive() will // not be invoked. We have to initialize here instead. initialize(ctx); &#125; else &#123; // channelActive() event has not been fired yet. this.channelActive() will be invoked // and initialization will occur there. &#125;&#125; 如果channel正常，则调用initialize方法：1234567891011121314151617181920212223242526272829private byte state; // 0 - none, 1 - initialized, 2 - destroyedprivate void initialize(ChannelHandlerContext ctx) &#123; // Avoid the case where destroy() is called before scheduling timeouts. // See: https://github.com/netty/netty/issues/143 switch (state) &#123; case 1: // 避免重复添加 case 2: // 如果处于destoryed状态，则不需要添加 return; &#125; state = 1; initOutputChanged(ctx); lastReadTime = lastWriteTime = ticksInNanos(); // 当前时间 // 添加相应的定时调度任务 if (readerIdleTimeNanos &gt; 0) &#123; // readerIdleTimeNanos时间后，执行ReaderIdleTimeoutTask里面的方法 readerIdleTimeout = schedule(ctx, new ReaderIdleTimeoutTask(ctx), readerIdleTimeNanos, TimeUnit.NANOSECONDS); &#125; if (writerIdleTimeNanos &gt; 0) &#123; writerIdleTimeout = schedule(ctx, new WriterIdleTimeoutTask(ctx), writerIdleTimeNanos, TimeUnit.NANOSECONDS); &#125; if (allIdleTimeNanos &gt; 0) &#123; allIdleTimeout = schedule(ctx, new AllIdleTimeoutTask(ctx), allIdleTimeNanos, TimeUnit.NANOSECONDS); &#125;&#125; ReaderIdleTimeoutTask、WriterIdleTimeoutTask、AllIdleTimeoutTask均继承自类AbstractIdleTask12345678910111213141516171819private abstract static class AbstractIdleTask implements Runnable &#123; private final ChannelHandlerContext ctx; AbstractIdleTask(ChannelHandlerContext ctx) &#123; this.ctx = ctx; &#125; @Override public void run() &#123; if (!ctx.channel().isOpen()) &#123; return; &#125; run(ctx); &#125; // 子类需要实现的方法 protected abstract void run(ChannelHandlerContext ctx);&#125; 以ReaderIdleTimeoutTask为例：12345678910111213141516171819202122232425262728293031323334private final class ReaderIdleTimeoutTask extends AbstractIdleTask &#123; ReaderIdleTimeoutTask(ChannelHandlerContext ctx) &#123; super(ctx); &#125; @Override protected void run(ChannelHandlerContext ctx) &#123; long nextDelay = readerIdleTimeNanos; if (!reading) &#123; // 如果不在读(channelRead时会被置为true，cahnnelReadComplete时会被置为false) nextDelay -= ticksInNanos() - lastReadTime; &#125; if (nextDelay &lt;= 0) &#123; // 说明读空闲时间达到或超过预设时间 // Reader is idle - set a new timeout and notify the callback. readerIdleTimeout = schedule(ctx, this, readerIdleTimeNanos, TimeUnit.NANOSECONDS); // firstReaderIdleEvent，是否是第一次读空闲事件(该标志位会在下一次channelRead触发时改成true，所以应该理解在一次读取完成后，这个读空闲事件是不是第一次) boolean first = firstReaderIdleEvent; firstReaderIdleEvent = false; try &#123; // 生成一个IdleStateEvent对象 IdleStateEvent event = newIdleStateEvent(IdleState.READER_IDLE, first); // 找到下一个ChannelInboundHandler类（或其子类）的handler，触发其userEventTrigger(可以参考AbstractChannelHandlerContext的fireUserEventTriggered方法) channelIdle(ctx, event); &#125; catch (Throwable t) &#123; ctx.fireExceptionCaught(t); &#125; &#125; else &#123; // 要么正在读，要么读空闲时间小于预设时间 // Read occurred before the timeout - set a new timeout with shorter delay. readerIdleTimeout = schedule(ctx, this, nextDelay, TimeUnit.NANOSECONDS); &#125; &#125;&#125; schedule方法可以理解为将定时调度事件放进一个队列当中（我是在AbstractScheduledEventExecutor里找到的scheduledTaskQueue().add(task);，但这里面的代码我还没看明白，有兴趣的你可以自己研究，研究完后如果有空可在下方评论）。channelIdle(ctx, event)方法时找到下一个ChannelInboundHandler类（或其子类）的handler，因此你写的继承自ChannelInboundHandler的handler，一定要添加在IdleStateHandler的后面，比如：12pipeline.addLast(new IdleStateHandler(30, 90, 0));pipeline.addLast(heartbeatHandler); ChannelInboundHandler它就很简单了，因为上面说了，channelIdle会调用ChannelInboundHandler的userEventTrigger，所以你只要自己写一个类继承ChannelInboundHandler，并重写它的userEventTrigger方法。比如：1234567891011121314151617181920212223242526272829303132// 用Sharable是因为我的每一个pipeline中用的都是同样的handler@Sharablepublic class NettyHeartbeatHandler extends ChannelInboundHandlerAdapter &#123; private final IHeartbeatFactory factory; public NettyHeartbeatHandler(IHeartbeatFactory factory) &#123; Preconditions.checkNotNull(factory); this.factory = factory; &#125; @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123; if (!(evt instanceof IdleStateEvent)) &#123; super.userEventTriggered(ctx, evt); return; &#125; IdleStateEvent event = (IdleStateEvent) evt; if (event.state() == IdleState.READER_IDLE) &#123; // 如果是读空闲，则关闭当前会话 ctx.close(); // 此时会触发下一个ChannelOutboundHandler的close方法，你可以在自己写的handler中进行断线操作 &#125; else if (event.state() == IdleState.WRITER_IDLE) &#123; // 如果是写空闲，则向客户端发送心跳请求包，如果客户端不返回心跳相应包，则说明客户端断线，下一次就将触发读空闲事件。这也是为了向客户端证明服务器端alive ctx.writeAndFlush( new BinaryWebSocketFrame( Unpooled.copiedBuffer(factory.getHeartbeatRequest().toByteArray()) ) ); &#125; &#125;&#125; 因此，以上就是关于用Netty实现心跳的简单介绍。其中带大家重点看了服务器端应该在什么情况下发起一次心跳请求，应该是长久没有收到消息时（可能是有业务含义的消息或者是一个心跳包）。如果大家有什么想法可以在下方评论。]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gitalk Error: Validation Failed]]></title>
    <url>%2F2018%2F09%2F30%2Fgitalk%20Error%20Validation%20Failed%2F</url>
    <content type="text"><![CDATA[我现在博客的评论系统用的是gitalk，网上教程有很多，我参考的是这份教程。 当我按照网上的说法搭好后，确实是可以利用issue进行评论了，但我在新发表文章时，竟然报错了： 当时我心里一凉，难道和gitment一样，gitalk也凉了？后来上网查了一下，发现是github现在要求issue的label name不能超过50。（奥，现在我才知道，原来gitalk应该是利用label进行筛选，取得当前评论所属的issus。但后来看了一下gitalk的源代码和github关于issue的api，issue的查找应该和你的number有关，而gitalk是当你没有number时就用id代替，看的有点晕。PS：本人在前端方面纯属小白） 好了，那就想想有什么办法可以保证名字的长度可以不超过50吧。没错，就是md5,加密过后都是32位长度，且唯一。当然了，这个也是在gitalk的issue里查到的，接下来就来看看具体应该怎么做吧。 找到js版的md5算法首推的自然是别人已经造好的成熟的轮子，JavaScript-MD5这个应该是可以的，亲测有效。 你只要在你的主题(比如我的就是next)下的source\js\src目录中创放入md5.js.min文件即可。 修改gitalk.swig文件原本你的文件内容应该是：12345678910111213141516&#123;% if page.comments &amp;&amp; theme.gitalk.enable %&#125; &lt;link rel=&quot;stylesheet&quot; href=&quot;https://unpkg.com/gitalk/dist/gitalk.css&quot;&gt; &lt;script src=&quot;https://unpkg.com/gitalk/dist/gitalk.min.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot;&gt; var gitalk = new Gitalk(&#123; clientID: &apos;&#123;&#123; theme.gitalk.ClientID &#125;&#125;&apos;, clientSecret: &apos;&#123;&#123; theme.gitalk.ClientSecret &#125;&#125;&apos;, repo: &apos;&#123;&#123; theme.gitalk.repo &#125;&#125;&apos;, owner: &apos;&#123;&#123; theme.gitalk.githubID &#125;&#125;&apos;, admin: [&apos;&#123;&#123; theme.gitalk.adminUser &#125;&#125;&apos;], id: location.pathname, distractionFreeMode: &apos;&#123;&#123; theme.gitalk.distractionFreeMode &#125;&#125;&apos; &#125;) gitalk.render(&apos;gitalk-container&apos;) &lt;/script&gt;&#123;% endif %&#125; 现在改成即可(修改了第4行和第12行)1234567891011121314151617&#123;% if page.comments &amp;&amp; theme.gitalk.enable %&#125; &lt;link rel=&quot;stylesheet&quot; href=&quot;https://unpkg.com/gitalk/dist/gitalk.css&quot;&gt; &lt;script src=&quot;https://unpkg.com/gitalk/dist/gitalk.min.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;/js/src/md5.min.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot;&gt; var gitalk = new Gitalk(&#123; clientID: &apos;&#123;&#123; theme.gitalk.ClientID &#125;&#125;&apos;, clientSecret: &apos;&#123;&#123; theme.gitalk.ClientSecret &#125;&#125;&apos;, repo: &apos;&#123;&#123; theme.gitalk.repo &#125;&#125;&apos;, owner: &apos;&#123;&#123; theme.gitalk.githubID &#125;&#125;&apos;, admin: [&apos;&#123;&#123; theme.gitalk.adminUser &#125;&#125;&apos;], id: md5(location.pathname), distractionFreeMode: &apos;&#123;&#123; theme.gitalk.distractionFreeMode &#125;&#125;&apos; &#125;) gitalk.render(&apos;gitalk-container&apos;) &lt;/script&gt;&#123;% endif %&#125; 然后重新发布就ok了，gitalk又可以正确创建issue了，你又可以继续评论了。 需要注意的问题因为gitalk关联issue是通过number，你没有number的时候，它会直接利用你的id，而id的这个生成条件又被你修改了，因此你之前评论是无法和你的文章关联上了。如果对js稍微感兴趣的话，应该可以顺着这个思路往下能解决。博主有空也会试试，就当研究研究js，大家要是有成功的案例，可以在通过评论告知，毕竟这也是造福大家。附上gitalk源码地址。]]></content>
      <categories>
        <category>解决问题</category>
      </categories>
      <tags>
        <tag>gitalk</tag>
        <tag>Error</tag>
        <tag>Validation Failed</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos6安装shadowsocks及配置]]></title>
    <url>%2F2018%2F09%2F30%2FCentos6%E5%AE%89%E8%A3%85shadowsocks%E5%8F%8A%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[买下搬瓦工的服务器，很多人首先会希望配置多个端口方便使用，这时候就需要安装shadowsocks来解决。现在我来介绍一下Centos6系统下shadowsocks的安装及配置过程。 这篇文章原是我在CSDN上发表的一篇博客，但在去年年底时莫名其妙被删除了，因此在这里，我把文章搬运过来，也是方便自己查看里面的一些命令。 这是一个搬瓦工的购买教程网站 安装python、pip、shadowsocks安装python： yum install python-setuptools 安装wget yum install wget 安装pip：（先下载再安装）1234wget https://pypi.python.org/packages/source/p/pip/pip-1.3.1.tar.gz --no-check-certificatetar -xzvf pip-1.3.1.tar.gzcd pip-1.3.1python setup.py install 安装shadowsocks pip install shadowsocks 配置shadowsocks首先创建配置文件/etc/shadowsocks.json touch /etc/shadowsocks.json 创建并编辑shadowsocks.json vi /etc/shadowsocks.json 现在要决定你是否需要开多端口，因为开出多个端口，每个端口的速度影响不大，但如果用同一个端口，速度会有所影响。 shadowsocks.json内容为：123456789101112&#123; &quot;server&quot;:&quot;你的IP地址&quot;, &quot;local_address&quot;: &quot;127.0.0.1&quot;, &quot;local_port&quot;:1080, &quot;port_password&quot;:&#123; &quot;端口号1&quot;:&quot;密码1&quot;, &quot;端口号2&quot;:&quot;密码2&quot; &#125;, &quot;timeout&quot;:600, &quot;method&quot;:&quot;rc4-md5&quot;, &quot;fast_open&quot;: false&#125; 对应你本地的shadowsocks配置为： 这时可以在Centos上运行shadowsocks服务： ssserver -c /etc/shadowsocks.json -d start 此时理论上你就可以科学上网了。 停止shadowsocks服务命令： ssserver -c /etc/shadowsocks.json -d stop 可能遇到的问题当你设置好配置文件并且启动之后，发现本地并不能上外网，其实可以通过shadowsocks的更新PAC功能查看是否可以连接外网： 如果更新失败，则代表无法连接外网，这时候请看一下你的服务器上设置的端口是否开启： netstat -ntlp 我开启了443、7788、7789、7790四个端口，如果你发现此处没有你的端口号，代表端口未打开 此时你需要先关闭shadowsocks，使用关闭命令，然后打开你所需要的端口。 利用iptables打开端口命令: /sbin/iptables -I INPUT -p tcp --dport 端口号 -j ACCEPT 保存你刚刚添加的规则: /etc/rc.d/init.d/iptables save 查看打开的端口： /etc/init.d/iptables status 现在这里会显示出你刚刚打开的端口。 现在开启你服务器上的shadowsocks，再用查看端口命令，应该就显示出你的端口已经打开了。 资源下载shadowsocks相关下载包安卓版本官方下载电脑版Windows 7及之前的版本电脑版Windows 8及之后的版本iOS教程]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初章]]></title>
    <url>%2F2018%2F09%2F29%2F%E5%88%9D%E7%AB%A0%2F</url>
    <content type="text"><![CDATA[第一次使用hexo写博客，希望能有一个不错的开始。]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
</search>
